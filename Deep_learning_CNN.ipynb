{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwz7oeF4pbMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39cf8e7-7216-4a22-8137-a1c4461a4c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/FilledHoles.zip\n",
            "   creating: /content/NAT/\n",
            " extracting: /content/NAT/J0012-0607.png  \n",
            " extracting: /content/NAT/J0017+0827.png  \n",
            " extracting: /content/NAT/J0020+0004.png  \n",
            " extracting: /content/NAT/J0020-1121.png  \n",
            " extracting: /content/NAT/J0023+0717.png  \n",
            " extracting: /content/NAT/J0041-0922.png  \n",
            " extracting: /content/NAT/J0041-0925.png  \n",
            " extracting: /content/NAT/J0047+1034.png  \n",
            " extracting: /content/NAT/J0054+0302.png  \n",
            " extracting: /content/NAT/J0056-0119.png  \n",
            " extracting: /content/NAT/J0056-0120.png  \n",
            " extracting: /content/NAT/J0104-0024.png  \n",
            " extracting: /content/NAT/J0111+1141.png  \n",
            " extracting: /content/NAT/J0119-1003.png  \n",
            " extracting: /content/NAT/J0132+0115.png  \n",
            " extracting: /content/NAT/J0140+0223.png  \n",
            " extracting: /content/NAT/J0148+0000.png  \n",
            " extracting: /content/NAT/J0148+0142.png  \n",
            " extracting: /content/NAT/J0150-0818.png  \n",
            " extracting: /content/NAT/J0210-0633.png  \n",
            " extracting: /content/NAT/J0212-0155.png  \n",
            " extracting: /content/NAT/J0212-0820.png  \n",
            " extracting: /content/NAT/J0216-0245.png  \n",
            " extracting: /content/NAT/J0223+0640.png  \n",
            " extracting: /content/NAT/J0231+0531.png  \n",
            " extracting: /content/NAT/J0256-0542.png  \n",
            " extracting: /content/NAT/J0311+0108.png  \n",
            " extracting: /content/NAT/J0317-0816.png  \n",
            " extracting: /content/NAT/J0323-0814.png  \n",
            " extracting: /content/NAT/J0335+0420.png  \n",
            " extracting: /content/NAT/J0337+0421.png  \n",
            " extracting: /content/NAT/J0340-0111.png  \n",
            " extracting: /content/NAT/J0349-0648.png  \n",
            " extracting: /content/NAT/J0356+0013.png  \n",
            " extracting: /content/NAT/J0703+5147.png  \n",
            " extracting: /content/NAT/J0704+6318.png  \n",
            " extracting: /content/NAT/J0709+4331.png  \n",
            " extracting: /content/NAT/J0709+5100.png  \n",
            " extracting: /content/NAT/J0714+3634.png  \n",
            " extracting: /content/NAT/J0714+4016.png  \n",
            " extracting: /content/NAT/J0718+4820.png  \n",
            " extracting: /content/NAT/J0720+3617.png  \n",
            " extracting: /content/NAT/J0729+5949.png  \n",
            " extracting: /content/NAT/J0731+3251.png  \n",
            " extracting: /content/NAT/J0732+6150.png  \n",
            " extracting: /content/NAT/J0734+3611.png  \n",
            " extracting: /content/NAT/J0735+3619.png  \n",
            " extracting: /content/NAT/J0736+2411.png  \n",
            " extracting: /content/NAT/J0738+3846.png  \n",
            " extracting: /content/NAT/J0739+3947.png  \n",
            " extracting: /content/NAT/J0741+1631.png  \n",
            " extracting: /content/NAT/J0741+1741.png  \n",
            " extracting: /content/NAT/J0743+5203.png  \n",
            " extracting: /content/NAT/J0744+2138.png  \n",
            " extracting: /content/NAT/J0745+3235.png  \n",
            " extracting: /content/NAT/J0749+5202.png  \n",
            " extracting: /content/NAT/J0754+3951.png  \n",
            " extracting: /content/NAT/J0756+6030.png  \n",
            " extracting: /content/NAT/J0802+3904.png  \n",
            " extracting: /content/NAT/J0802+6345.png  \n",
            " extracting: /content/NAT/J0803+3951.png  \n",
            " extracting: /content/NAT/J0808+0550.png  \n",
            " extracting: /content/NAT/J0809+0934.png  \n",
            " extracting: /content/NAT/J0811+3810.png  \n",
            " extracting: /content/NAT/J0817+5442.png  \n",
            " extracting: /content/NAT/J0819+2522.png  \n",
            " extracting: /content/NAT/J0819+5746.png  \n",
            " extracting: /content/NAT/J0819+5804.png  \n",
            " extracting: /content/NAT/J0820+1642.png  \n",
            " extracting: /content/NAT/J0824+5200.png  \n",
            " extracting: /content/NAT/J0825+4817.png  \n",
            " extracting: /content/NAT/J0826+1531.png  \n",
            " extracting: /content/NAT/J0826+3023.png  \n",
            " extracting: /content/NAT/J0827+0816.png  \n",
            " extracting: /content/NAT/J0828+2436.png  \n",
            " extracting: /content/NAT/J0829+6322.png  \n",
            " extracting: /content/NAT/J0830+2155.png  \n",
            " extracting: /content/NAT/J0830+3616.png  \n",
            " extracting: /content/NAT/J0834+3945.png  \n",
            " extracting: /content/NAT/J0839+5949.png  \n",
            " extracting: /content/NAT/J0841+6112.png  \n",
            " extracting: /content/NAT/J0842+0900.png  \n",
            " extracting: /content/NAT/J0844+2538.png  \n",
            " extracting: /content/NAT/J0846+2024.png  \n",
            " extracting: /content/NAT/J0850+1349.png  \n",
            " extracting: /content/NAT/J0851+0851.png  \n",
            " extracting: /content/NAT/J0851+1615.png  \n",
            " extracting: /content/NAT/J0857+1703.png  \n",
            " extracting: /content/NAT/J0858+1620.png  \n",
            " extracting: /content/NAT/J0858-0107.png  \n",
            " extracting: /content/NAT/J0859+0314.png  \n",
            " extracting: /content/NAT/J0901+0259.png  \n",
            " extracting: /content/NAT/J0902+3505.png  \n",
            " extracting: /content/NAT/J0903+4509.png  \n",
            " extracting: /content/NAT/J0906+4419.png  \n",
            " extracting: /content/NAT/J0909+3106.png  \n",
            " extracting: /content/NAT/J0912+1642.png  \n",
            " extracting: /content/NAT/J0912-0440.png  \n",
            " extracting: /content/NAT/J0914+0824.png  \n",
            " extracting: /content/NAT/J0916+1729.png  \n",
            " extracting: /content/NAT/J0916+3818.png  \n",
            " extracting: /content/NAT/J0918+3021.png  \n",
            " extracting: /content/NAT/J0919-0129.png  \n",
            " extracting: /content/NAT/J0920+4039.png  \n",
            " extracting: /content/NAT/J0922-0724.png  \n",
            " extracting: /content/NAT/J0927+5423.png  \n",
            " extracting: /content/NAT/J0928+4854.png  \n",
            " extracting: /content/NAT/J0931+2012.png  \n",
            " extracting: /content/NAT/J0933+1341.png  \n",
            " extracting: /content/NAT/J0935+2355.png  \n",
            " extracting: /content/NAT/J0936+0340.png  \n",
            " extracting: /content/NAT/J0936-0455.png  \n",
            " extracting: /content/NAT/J0940+2530.png  \n",
            " extracting: /content/NAT/J0942+1522.png  \n",
            " extracting: /content/NAT/J0942+1523.png  \n",
            " extracting: /content/NAT/J0943-0507.png  \n",
            " extracting: /content/NAT/J0944-0616.png  \n",
            " extracting: /content/NAT/J0951+1224.png  \n",
            " extracting: /content/NAT/J0951+1801.png  \n",
            " extracting: /content/NAT/J0952-0449.png  \n",
            " extracting: /content/NAT/J0957+0327.png  \n",
            " extracting: /content/NAT/J0959+0117.png  \n",
            " extracting: /content/NAT/J0959+2447.png  \n",
            " extracting: /content/NAT/J1000+2047.png  \n",
            " extracting: /content/NAT/J1005+2210.png  \n",
            " extracting: /content/NAT/J1005+3000.png  \n",
            " extracting: /content/NAT/J1009+4432.png  \n",
            " extracting: /content/NAT/J1009+4433.png  \n",
            " extracting: /content/NAT/J1010+2145.png  \n",
            " extracting: /content/NAT/J1011-0607.png  \n",
            " extracting: /content/NAT/J1013+5532.png  \n",
            " extracting: /content/NAT/J1014+0038.png  \n",
            " extracting: /content/NAT/J1015+2627.png  \n",
            " extracting: /content/NAT/J1016+0930.png  \n",
            " extracting: /content/NAT/J1016+4708.png  \n",
            " extracting: /content/NAT/J1017+6352.png  \n",
            " extracting: /content/NAT/J1022+1653.png  \n",
            " extracting: /content/NAT/J1022+3758.png  \n",
            " extracting: /content/NAT/J1022+4216.png  \n",
            " extracting: /content/NAT/J1022-0420.png  \n",
            " extracting: /content/NAT/J1023+0851.png  \n",
            " extracting: /content/NAT/J1025+0401.png  \n",
            " extracting: /content/NAT/J1027+0722.png  \n",
            " extracting: /content/NAT/J1028+0307.png  \n",
            " extracting: /content/NAT/J1028+1702.png  \n",
            " extracting: /content/NAT/J1032+0514.png  \n",
            " extracting: /content/NAT/J1032+3502.png  \n",
            " extracting: /content/NAT/J1035+5907.png  \n",
            " extracting: /content/NAT/J1037+3625.png  \n",
            " extracting: /content/NAT/J1039+5537.png  \n",
            " extracting: /content/NAT/J1040+1548.png  \n",
            " extracting: /content/NAT/J1041+2336.png  \n",
            " extracting: /content/NAT/J1041+3355.png  \n",
            " extracting: /content/NAT/J1043+0847.png  \n",
            " extracting: /content/NAT/J1043+0947.png  \n",
            " extracting: /content/NAT/J1043-0553.png  \n",
            " extracting: /content/NAT/J1045+2351.png  \n",
            " extracting: /content/NAT/J1046+0902.png  \n",
            " extracting: /content/NAT/J1046+1210.png  \n",
            " extracting: /content/NAT/J1046+1631.png  \n",
            " extracting: /content/NAT/J1047+1516.png  \n",
            " extracting: /content/NAT/J1048+1857.png  \n",
            " extracting: /content/NAT/J1051+0503.png  \n",
            " extracting: /content/NAT/J1051+5807.png  \n",
            " extracting: /content/NAT/J1052+1145.png  \n",
            " extracting: /content/NAT/J1052+5327.png  \n",
            " extracting: /content/NAT/J1054-0209.png  \n",
            " extracting: /content/NAT/J1055+1432.png  \n",
            " extracting: /content/NAT/J1056+1128.png  \n",
            " extracting: /content/NAT/J1102-0613.png  \n",
            " extracting: /content/NAT/J1104+4726.png  \n",
            " extracting: /content/NAT/J1105+1235.png  \n",
            " extracting: /content/NAT/J1107+3219.png  \n",
            " extracting: /content/NAT/J1107+4420.png  \n",
            " extracting: /content/NAT/J1109+3252.png  \n",
            " extracting: /content/NAT/J1110+1159.png  \n",
            " extracting: /content/NAT/J1111+4050.png  \n",
            " extracting: /content/NAT/J1119+3750.png  \n",
            " extracting: /content/NAT/J1122+2124.png  \n",
            " extracting: /content/NAT/J1124+2857.png  \n",
            " extracting: /content/NAT/J1127+5302.png  \n",
            " extracting: /content/NAT/J1129+2533.png  \n",
            " extracting: /content/NAT/J1130+0052.png  \n",
            " extracting: /content/NAT/J1130+2434.png  \n",
            " extracting: /content/NAT/J1131+0128.png  \n",
            " extracting: /content/NAT/J1131+2125.png  \n",
            " extracting: /content/NAT/J1131+2126.png  \n",
            " extracting: /content/NAT/J1131+3908.png  \n",
            " extracting: /content/NAT/J1132+1344.png  \n",
            " extracting: /content/NAT/J1132+5459.png  \n",
            " extracting: /content/NAT/J1137+3000.png  \n",
            " extracting: /content/NAT/J1138+3343.png  \n",
            " extracting: /content/NAT/J1143+1641.png  \n",
            " extracting: /content/NAT/J1143+3648.png  \n",
            " extracting: /content/NAT/J1143+6007.png  \n",
            " extracting: /content/NAT/J1144+3710.png  \n",
            " extracting: /content/NAT/J1145+1529.png  \n",
            " extracting: /content/NAT/J1147+4805.png  \n",
            " extracting: /content/NAT/J1149+4911.png  \n",
            " extracting: /content/NAT/J1154+1009.png  \n",
            " extracting: /content/NAT/J1155+1059.png  \n",
            " extracting: /content/NAT/J1155+2126.png  \n",
            " extracting: /content/NAT/J1157+1945.png  \n",
            " extracting: /content/NAT/J1200-0201.png  \n",
            " extracting: /content/NAT/J1201-0703.png  \n",
            " extracting: /content/NAT/J1202+1216.png  \n",
            " extracting: /content/NAT/J1204+2013.png  \n",
            " extracting: /content/NAT/J1206+0346.png  \n",
            " extracting: /content/NAT/J1207+4805.png  \n",
            " extracting: /content/NAT/J1208+3425.png  \n",
            " extracting: /content/NAT/J1209+5715.png  \n",
            " extracting: /content/NAT/J1210+5616.png  \n",
            " extracting: /content/NAT/J1211+0125.png  \n",
            " extracting: /content/NAT/J1211+0707.png  \n",
            " extracting: /content/NAT/J1212+1813.png  \n",
            " extracting: /content/NAT/J1215+3243.png  \n",
            " extracting: /content/NAT/J1217+0336.png  \n",
            " extracting: /content/NAT/J1217+0340.png  \n",
            " extracting: /content/NAT/J1220+0203.png  \n",
            " extracting: /content/NAT/J1222-0449.png  \n",
            " extracting: /content/NAT/J1223+6115.png  \n",
            " extracting: /content/NAT/J1225+1253.png  \n",
            " extracting: /content/NAT/J1227+4928.png  \n",
            " extracting: /content/NAT/J1230-0752.png  \n",
            " extracting: /content/NAT/J1231+3850.png  \n",
            " extracting: /content/NAT/J1234+4012.png  \n",
            " extracting: /content/NAT/J1235+0741.png  \n",
            " extracting: /content/NAT/J1235+5314.png  \n",
            " extracting: /content/NAT/J1237+1858.png  \n",
            " extracting: /content/NAT/J1239+1423.png  \n",
            " extracting: /content/NAT/J1240+1832.png  \n",
            " extracting: /content/NAT/J1241+6056.png  \n",
            " extracting: /content/NAT/J1242+0929.png  \n",
            " extracting: /content/NAT/J1242+5022.png  \n",
            " extracting: /content/NAT/J1243-0726.png  \n",
            " extracting: /content/NAT/J1246+3005.png  \n",
            " extracting: /content/NAT/J1247+0119.png  \n",
            " extracting: /content/NAT/J1247-0249.png  \n",
            " extracting: /content/NAT/J1249+0713.png  \n",
            " extracting: /content/NAT/J1253+2210.png  \n",
            " extracting: /content/NAT/J1254+1757.png  \n",
            " extracting: /content/NAT/J1256+0126.png  \n",
            " extracting: /content/NAT/J1257+4854.png  \n",
            " extracting: /content/NAT/J1258+1110.png  \n",
            " extracting: /content/NAT/J1258+4431.png  \n",
            " extracting: /content/NAT/J1259+0946.png  \n",
            " extracting: /content/NAT/J1259+4906.png  \n",
            " extracting: /content/NAT/J1303+3150.png  \n",
            " extracting: /content/NAT/J1306+4633.png  \n",
            " extracting: /content/NAT/J1307-0631.png  \n",
            " extracting: /content/NAT/J1308+5311.png  \n",
            " extracting: /content/NAT/J1311+1922.png  \n",
            " extracting: /content/NAT/J1313+0220.png  \n",
            " extracting: /content/NAT/J1313+0733.png  \n",
            " extracting: /content/NAT/J1313+1745.png  \n",
            " extracting: /content/NAT/J1317+1910.png  \n",
            " extracting: /content/NAT/J1317+3144.png  \n",
            " extracting: /content/NAT/J1318+5126.png  \n",
            " extracting: /content/NAT/J1319+5807.png  \n",
            " extracting: /content/NAT/J1322+1132.png  \n",
            " extracting: /content/NAT/J1322+5810.png  \n",
            " extracting: /content/NAT/J1325+0527.png  \n",
            " extracting: /content/NAT/J1325+5544.png  \n",
            " extracting: /content/NAT/J1327-0440.png  \n",
            " extracting: /content/NAT/J1328+1436.png  \n",
            " extracting: /content/NAT/J1329+5246.png  \n",
            " extracting: /content/NAT/J1330+0649.png  \n",
            " extracting: /content/NAT/J1330+1904.png  \n",
            " extracting: /content/NAT/J1334+1728.png  \n",
            " extracting: /content/NAT/J1334+2537.png  \n",
            " extracting: /content/NAT/J1336+4035.png  \n",
            " extracting: /content/NAT/J1339+1620.png  \n",
            " extracting: /content/NAT/J1341+2622.png  \n",
            " extracting: /content/NAT/J1341+5344.png  \n",
            " extracting: /content/NAT/J1341+5406.png  \n",
            " extracting: /content/NAT/J1342+1226.png  \n",
            " extracting: /content/NAT/J1342-0334.png  \n",
            " extracting: /content/NAT/J1344+1134.png  \n",
            " extracting: /content/NAT/J1344+2425.png  \n",
            " extracting: /content/NAT/J1345+0812.png  \n",
            " extracting: /content/NAT/J1347+5022.png  \n",
            " extracting: /content/NAT/J1348+3726.png  \n",
            " extracting: /content/NAT/J1349+4207.png  \n",
            " extracting: /content/NAT/J1349+4828.png  \n",
            " extracting: /content/NAT/J1351+0023.png  \n",
            " extracting: /content/NAT/J1351-0549.png  \n",
            " extracting: /content/NAT/J1353+0942.png  \n",
            " extracting: /content/NAT/J1353+3305.png  \n",
            " extracting: /content/NAT/J1357+0732.png  \n",
            " extracting: /content/NAT/J1358+0352.png  \n",
            " extracting: /content/NAT/J1359+4443.png  \n",
            " extracting: /content/NAT/J1359-0102.png  \n",
            " extracting: /content/NAT/J1400+2829.png  \n",
            " extracting: /content/NAT/J1403+0610.png  \n",
            " extracting: /content/NAT/J1403+2349.png  \n",
            " extracting: /content/NAT/J1407+4257.png  \n",
            " extracting: /content/NAT/J1409+4347.png  \n",
            " extracting: /content/NAT/J1418+0515.png  \n",
            " extracting: /content/NAT/J1418+3211.png  \n",
            " extracting: /content/NAT/J1419+2008.png  \n",
            " extracting: /content/NAT/J1421+6100.png  \n",
            " extracting: /content/NAT/J1421-0431.png  \n",
            " extracting: /content/NAT/J1425+1210.png  \n",
            " extracting: /content/NAT/J1428+3953.png  \n",
            " extracting: /content/NAT/J1429+1300.png  \n",
            " extracting: /content/NAT/J1430+2059.png  \n",
            " extracting: /content/NAT/J1431+5518.png  \n",
            " extracting: /content/NAT/J1432+1247.png  \n",
            " extracting: /content/NAT/J1434+1514.png  \n",
            " extracting: /content/NAT/J1434-0215.png  \n",
            " extracting: /content/NAT/J1435+4758.png  \n",
            " extracting: /content/NAT/J1436+4748.png  \n",
            " extracting: /content/NAT/J1439+2848.png  \n",
            " extracting: /content/NAT/J1439+4931.png  \n",
            " extracting: /content/NAT/J1441+1610.png  \n",
            " extracting: /content/NAT/J1441+1840.png  \n",
            " extracting: /content/NAT/J1444+5406.png  \n",
            " extracting: /content/NAT/J1446+3151.png  \n",
            " extracting: /content/NAT/J1450+4222.png  \n",
            " extracting: /content/NAT/J1451+1622.png  \n",
            " extracting: /content/NAT/J1451+3121.png  \n",
            " extracting: /content/NAT/J1452+0733.png  \n",
            " extracting: /content/NAT/J1452+5022.png  \n",
            " extracting: /content/NAT/J1456+0704.png  \n",
            " extracting: /content/NAT/J1458+1006.png  \n",
            " extracting: /content/NAT/J1500+1241.png  \n",
            " extracting: /content/NAT/J1500+2218.png  \n",
            " extracting: /content/NAT/J1500-0317.png  \n",
            " extracting: /content/NAT/J1502+4255.png  \n",
            " extracting: /content/NAT/J1504+4448.png  \n",
            " extracting: /content/NAT/J1505+1546.png  \n",
            " extracting: /content/NAT/J1506+3428.png  \n",
            " extracting: /content/NAT/J1506+5311.png  \n",
            " extracting: /content/NAT/J1510+5146.png  \n",
            " extracting: /content/NAT/J1514+1016.png  \n",
            " extracting: /content/NAT/J1514+1017.png  \n",
            " extracting: /content/NAT/J1520+2337.png  \n",
            " extracting: /content/NAT/J1523+3610.png  \n",
            " extracting: /content/NAT/J1524+0957.png  \n",
            " extracting: /content/NAT/J1524+6202.png  \n",
            " extracting: /content/NAT/J1526+0438.png  \n",
            " extracting: /content/NAT/J1530+3210.png  \n",
            " extracting: /content/NAT/J1530-0703.png  \n",
            " extracting: /content/NAT/J1535+3423.png  \n",
            " extracting: /content/NAT/J1536-0205.png  \n",
            " extracting: /content/NAT/J1539+1805.png  \n",
            " extracting: /content/NAT/J1539+1833.png  \n",
            " extracting: /content/NAT/J1539+3044.png  \n",
            " extracting: /content/NAT/J1541+0301.png  \n",
            " extracting: /content/NAT/J1541+1422.png  \n",
            " extracting: /content/NAT/J1544+2838.png  \n",
            " extracting: /content/NAT/J1544+6042.png  \n",
            " extracting: /content/NAT/J1545-0237.png  \n",
            " extracting: /content/NAT/J1550+1516.png  \n",
            " extracting: /content/NAT/J1551+4025.png  \n",
            " extracting: /content/NAT/J1554-0220.png  \n",
            " extracting: /content/NAT/J1555+0326.png  \n",
            " extracting: /content/NAT/J1555+0446.png  \n",
            " extracting: /content/NAT/J1555+4531.png  \n",
            " extracting: /content/NAT/J1558+5857.png  \n",
            " extracting: /content/NAT/J1600+0958.png  \n",
            " extracting: /content/NAT/J1600+2300.png  \n",
            " extracting: /content/NAT/J1602+0956.png  \n",
            " extracting: /content/NAT/J1603+3133.png  \n",
            " extracting: /content/NAT/J1606+5353.png  \n",
            " extracting: /content/NAT/J1609+0334.png  \n",
            " extracting: /content/NAT/J1609+6144.png  \n",
            " extracting: /content/NAT/J1610+1203.png  \n",
            " extracting: /content/NAT/J1610+2531.png  \n",
            " extracting: /content/NAT/J1611+0415.png  \n",
            " extracting: /content/NAT/J1612+2747.png  \n",
            " extracting: /content/NAT/J1613+1921.png  \n",
            " extracting: /content/NAT/J1613+2937.png  \n",
            " extracting: /content/NAT/J1614+5900.png  \n",
            " extracting: /content/NAT/J1614+6215.png  \n",
            " extracting: /content/NAT/J1616+0906.png  \n",
            " extracting: /content/NAT/J1616+4226.png  \n",
            " extracting: /content/NAT/J1616+5620.png  \n",
            " extracting: /content/NAT/J1620+4228.png  \n",
            " extracting: /content/NAT/J1623+1110.png  \n",
            " extracting: /content/NAT/J1623+4618.png  \n",
            " extracting: /content/NAT/J1624+4641.png  \n",
            " extracting: /content/NAT/J1625+0932.png  \n",
            " extracting: /content/NAT/J1634+0626.png  \n",
            " extracting: /content/NAT/J1640+4634.png  \n",
            " extracting: /content/NAT/J1643+1406.png  \n",
            " extracting: /content/NAT/J1650+3303.png  \n",
            " extracting: /content/NAT/J1651+4229.png  \n",
            " extracting: /content/NAT/J1652+3055.png  \n",
            " extracting: /content/NAT/J1657+4319.png  \n",
            " extracting: /content/NAT/J1700+4442.png  \n",
            " extracting: /content/NAT/J1703+4139.png  \n",
            " extracting: /content/NAT/J1704+2452.png  \n",
            " extracting: /content/NAT/J1710+4022.png  \n",
            " extracting: /content/NAT/J1710+4239.png  \n",
            " extracting: /content/NAT/J1712+2910.png  \n",
            " extracting: /content/NAT/J1713+6347.png  \n",
            " extracting: /content/NAT/J1716+2918.png  \n",
            " extracting: /content/NAT/J1717+3735.png  \n",
            " extracting: /content/NAT/J1721+4725.png  \n",
            " extracting: /content/NAT/J1721+4726.png  \n",
            " extracting: /content/NAT/J1725+4949.png  \n",
            " extracting: /content/NAT/J1726+4530.png  \n",
            " extracting: /content/NAT/J1728+3651.png  \n",
            " extracting: /content/NAT/J1728+4045.png  \n",
            " extracting: /content/NAT/J1730+5923.png  \n",
            " extracting: /content/NAT/J1733+4229.png  \n",
            " extracting: /content/NAT/J2058+0930.png  \n",
            " extracting: /content/NAT/J2102-0145.png  \n",
            " extracting: /content/NAT/J2126-0710.png  \n",
            " extracting: /content/NAT/J2137-0134.png  \n",
            " extracting: /content/NAT/J2139-0742.png  \n",
            " extracting: /content/NAT/J2152+0907.png  \n",
            " extracting: /content/NAT/J2154+0037.png  \n",
            " extracting: /content/NAT/J2155+0846.png  \n",
            " extracting: /content/NAT/J2155+1231.png  \n",
            " extracting: /content/NAT/J2157-0747.png  \n",
            " extracting: /content/NAT/J2157-0750.png  \n",
            " extracting: /content/NAT/J2159-0542.png  \n",
            " extracting: /content/NAT/J2204+1118.png  \n",
            " extracting: /content/NAT/J2222+1435.png  \n",
            " extracting: /content/NAT/J2224+0126.png  \n",
            " extracting: /content/NAT/J2234+0552.png  \n",
            " extracting: /content/NAT/J2239-0322.png  \n",
            " extracting: /content/NAT/J2239-0932.png  \n",
            " extracting: /content/NAT/J2254-0010.png  \n",
            " extracting: /content/NAT/J2304-0952.png  \n",
            " extracting: /content/NAT/J2310+1441.png  \n",
            " extracting: /content/NAT/J2310-0326.png  \n",
            " extracting: /content/NAT/J2312-0015.png  \n",
            " extracting: /content/NAT/J2332+1016.png  \n",
            " extracting: /content/NAT/J2332-0744.png  \n",
            " extracting: /content/NAT/J2346-0154.png  \n",
            " extracting: /content/NAT/J2348+1157.png  \n",
            "   creating: /content/WAT/\n",
            " extracting: /content/WAT/J0001-0826.png  \n",
            " extracting: /content/WAT/J0003+0028.png  \n",
            " extracting: /content/WAT/J0007+0536.png  \n",
            " extracting: /content/WAT/J0015-0048.png  \n",
            " extracting: /content/WAT/J0017-0149.png  \n",
            " extracting: /content/WAT/J0020-0950.png  \n",
            " extracting: /content/WAT/J0027+0224.png  \n",
            " extracting: /content/WAT/J0034+1140.png  \n",
            " extracting: /content/WAT/J0035-0834.png  \n",
            " extracting: /content/WAT/J0040+0126.png  \n",
            " extracting: /content/WAT/J0041-0651.png  \n",
            " extracting: /content/WAT/J0043-1039.png  \n",
            " extracting: /content/WAT/J0044+1026.png  \n",
            " extracting: /content/WAT/J0045-0701.png  \n",
            " extracting: /content/WAT/J0046-0805.png  \n",
            " extracting: /content/WAT/J0050+0515.png  \n",
            " extracting: /content/WAT/J0057-0100.png  \n",
            " extracting: /content/WAT/J0057-0336.png  \n",
            " extracting: /content/WAT/J0103+0041.png  \n",
            " extracting: /content/WAT/J0112-0950.png  \n",
            " extracting: /content/WAT/J0114+0029.png  \n",
            " extracting: /content/WAT/J0120+0021.png  \n",
            " extracting: /content/WAT/J0129+0046.png  \n",
            " extracting: /content/WAT/J0131+0033.png  \n",
            " extracting: /content/WAT/J0133+0055.png  \n",
            " extracting: /content/WAT/J0133-0824.png  \n",
            " extracting: /content/WAT/J0158-0215.png  \n",
            " extracting: /content/WAT/J0159-0119.png  \n",
            " extracting: /content/WAT/J0204+0415.png  \n",
            " extracting: /content/WAT/J0212-0450.png  \n",
            " extracting: /content/WAT/J0220-0104.png  \n",
            " extracting: /content/WAT/J0223-0857.png  \n",
            " extracting: /content/WAT/J0224+0659.png  \n",
            " extracting: /content/WAT/J0229+0429.png  \n",
            " extracting: /content/WAT/J0230+0108.png  \n",
            " extracting: /content/WAT/J0233-0321.png  \n",
            " extracting: /content/WAT/J0242-0544.png  \n",
            " extracting: /content/WAT/J0245-0648.png  \n",
            " extracting: /content/WAT/J0248-0113.png  \n",
            " extracting: /content/WAT/J0257-0359.png  \n",
            " extracting: /content/WAT/J0308-0607.png  \n",
            " extracting: /content/WAT/J0312-0633.png  \n",
            " extracting: /content/WAT/J0313-0631.png  \n",
            " extracting: /content/WAT/J0315+0507.png  \n",
            " extracting: /content/WAT/J0318-0810.png  \n",
            " extracting: /content/WAT/J0320+0059.png  \n",
            " extracting: /content/WAT/J0331-0730.png  \n",
            " extracting: /content/WAT/J0332+0024.png  \n",
            " extracting: /content/WAT/J0334+0102.png  \n",
            " extracting: /content/WAT/J0335-0719.png  \n",
            " extracting: /content/WAT/J0700+4946.png  \n",
            " extracting: /content/WAT/J0703+6014.png  \n",
            " extracting: /content/WAT/J0704+6228.png  \n",
            " extracting: /content/WAT/J0707+4449.png  \n",
            " extracting: /content/WAT/J0707+5927.png  \n",
            " extracting: /content/WAT/J0714+5100.png  \n",
            " extracting: /content/WAT/J0715+4829.png  \n",
            " extracting: /content/WAT/J0717+4405.png  \n",
            " extracting: /content/WAT/J0719+5519.png  \n",
            " extracting: /content/WAT/J0721+3639.png  \n",
            " extracting: /content/WAT/J0721+5312.png  \n",
            " extracting: /content/WAT/J0721+5314.png  \n",
            " extracting: /content/WAT/J0722+4129.png  \n",
            " extracting: /content/WAT/J0723+3323.png  \n",
            " extracting: /content/WAT/J0724+3639.png  \n",
            " extracting: /content/WAT/J0724+5010.png  \n",
            " extracting: /content/WAT/J0726+3102.png  \n",
            " extracting: /content/WAT/J0726+4039.png  \n",
            " extracting: /content/WAT/J0727+3109.png  \n",
            " extracting: /content/WAT/J0732+3744.png  \n",
            " extracting: /content/WAT/J0733+4213.png  \n",
            " extracting: /content/WAT/J0734+2933.png  \n",
            " extracting: /content/WAT/J0736+1857.png  \n",
            " extracting: /content/WAT/J0736+2412.png  \n",
            " extracting: /content/WAT/J0741+1632.png  \n",
            " extracting: /content/WAT/J0741+2620.png  \n",
            " extracting: /content/WAT/J0744+1658.png  \n",
            " extracting: /content/WAT/J0744+4353.png  \n",
            " extracting: /content/WAT/J0745+3528.png  \n",
            " extracting: /content/WAT/J0747+3726.png  \n",
            " extracting: /content/WAT/J0748+2324.png  \n",
            " extracting: /content/WAT/J0748+4849.png  \n",
            " extracting: /content/WAT/J0750+1741.png  \n",
            " extracting: /content/WAT/J0750+5841.png  \n",
            " extracting: /content/WAT/J0750+5856.png  \n",
            " extracting: /content/WAT/J0751+2452.png  \n",
            " extracting: /content/WAT/J0752+3750.png  \n",
            " extracting: /content/WAT/J0755+1909.png  \n",
            " extracting: /content/WAT/J0757+3640.png  \n",
            " extracting: /content/WAT/J0757+5824.png  \n",
            " extracting: /content/WAT/J0800+1329.png  \n",
            " extracting: /content/WAT/J0801+1349.png  \n",
            " extracting: /content/WAT/J0803+1050.png  \n",
            " extracting: /content/WAT/J0803+2440.png  \n",
            " extracting: /content/WAT/J0804+1922.png  \n",
            " extracting: /content/WAT/J0805+1614.png  \n",
            " extracting: /content/WAT/J0806+1906.png  \n",
            " extracting: /content/WAT/J0806+4513.png  \n",
            " extracting: /content/WAT/J0807+1416.png  \n",
            " extracting: /content/WAT/J0808+3933.png  \n",
            " extracting: /content/WAT/J0811+1029.png  \n",
            " extracting: /content/WAT/J0811+2847.png  \n",
            " extracting: /content/WAT/J0814+2615.png  \n",
            " extracting: /content/WAT/J0814+3833.png  \n",
            " extracting: /content/WAT/J0814+4300.png  \n",
            " extracting: /content/WAT/J0815+3840.png  \n",
            " extracting: /content/WAT/J0815+4908.png  \n",
            " extracting: /content/WAT/J0816+4133.png  \n",
            " extracting: /content/WAT/J0816+5716.png  \n",
            " extracting: /content/WAT/J0818+2332.png  \n",
            " extracting: /content/WAT/J0818+3858.png  \n",
            " extracting: /content/WAT/J0818+4956.png  \n",
            " extracting: /content/WAT/J0818+5437.png  \n",
            " extracting: /content/WAT/J0819+1849.png  \n",
            " extracting: /content/WAT/J0819+3332.png  \n",
            " extracting: /content/WAT/J0819+5745.png  \n",
            " extracting: /content/WAT/J0820+0834.png  \n",
            " extracting: /content/WAT/J0820+3034.png  \n",
            " extracting: /content/WAT/J0822+1435.png  \n",
            " extracting: /content/WAT/J0826+0359.png  \n",
            " extracting: /content/WAT/J0826+1851.png  \n",
            " extracting: /content/WAT/J0827+1600.png  \n",
            " extracting: /content/WAT/J0827+4635.png  \n",
            " extracting: /content/WAT/J0828+3228.png  \n",
            " extracting: /content/WAT/J0830+0836.png  \n",
            " extracting: /content/WAT/J0831+1459.png  \n",
            " extracting: /content/WAT/J0831+2234.png  \n",
            " extracting: /content/WAT/J0831+2239.png  \n",
            " extracting: /content/WAT/J0831+3914.png  \n",
            " extracting: /content/WAT/J0831+6104.png  \n",
            " extracting: /content/WAT/J0833+1027.png  \n",
            " extracting: /content/WAT/J0833+4940.png  \n",
            " extracting: /content/WAT/J0834+0019.png  \n",
            " extracting: /content/WAT/J0837+6020.png  \n",
            " extracting: /content/WAT/J0839+0609.png  \n",
            " extracting: /content/WAT/J0839+2850.png  \n",
            " extracting: /content/WAT/J0840+2949.png  \n",
            " extracting: /content/WAT/J0840+3826.png  \n",
            " extracting: /content/WAT/J0841+1235.png  \n",
            " extracting: /content/WAT/J0841+4451.png  \n",
            " extracting: /content/WAT/J0841+5258.png  \n",
            " extracting: /content/WAT/J0841-0202.png  \n",
            " extracting: /content/WAT/J0842+3856.png  \n",
            " extracting: /content/WAT/J0842+4156.png  \n",
            " extracting: /content/WAT/J0844+2129.png  \n",
            " extracting: /content/WAT/J0844+2606.png  \n",
            " extracting: /content/WAT/J0844+3158.png  \n",
            " extracting: /content/WAT/J0847+0847.png  \n",
            " extracting: /content/WAT/J0847+3147.png  \n",
            " extracting: /content/WAT/J0849+2822.png  \n",
            " extracting: /content/WAT/J0850+2909.png  \n",
            " extracting: /content/WAT/J0851+0827.png  \n",
            " extracting: /content/WAT/J0851+2720.png  \n",
            " extracting: /content/WAT/J0851+6227.png  \n",
            " extracting: /content/WAT/J0852+1544.png  \n",
            " extracting: /content/WAT/J0852+2450.png  \n",
            " extracting: /content/WAT/J0852+5315.png  \n",
            " extracting: /content/WAT/J0852+5639.png  \n",
            " extracting: /content/WAT/J0853+2323.png  \n",
            " extracting: /content/WAT/J0855+3454.png  \n",
            " extracting: /content/WAT/J0856+2152.png  \n",
            " extracting: /content/WAT/J0856+4829.png  \n",
            " extracting: /content/WAT/J0856+4951.png  \n",
            " extracting: /content/WAT/J0858+4700.png  \n",
            " extracting: /content/WAT/J0858+5740.png  \n",
            " extracting: /content/WAT/J0859+0901.png  \n",
            " extracting: /content/WAT/J0859-0251.png  \n",
            " extracting: /content/WAT/J0900+1614.png  \n",
            " extracting: /content/WAT/J0900+5056.png  \n",
            " extracting: /content/WAT/J0902+1819.png  \n",
            " extracting: /content/WAT/J0902+2045.png  \n",
            " extracting: /content/WAT/J0903+3230.png  \n",
            " extracting: /content/WAT/J0904+5834.png  \n",
            " extracting: /content/WAT/J0907+0234.png  \n",
            " extracting: /content/WAT/J0907+3137.png  \n",
            " extracting: /content/WAT/J0907+4922.png  \n",
            " extracting: /content/WAT/J0908+1605.png  \n",
            " extracting: /content/WAT/J0908+3437.png  \n",
            " extracting: /content/WAT/J0910+1835.png  \n",
            " extracting: /content/WAT/J0910+3841.png  \n",
            " extracting: /content/WAT/J0911+0732.png  \n",
            " extracting: /content/WAT/J0912+0534.png  \n",
            " extracting: /content/WAT/J0912+0944.png  \n",
            " extracting: /content/WAT/J0912+1119.png  \n",
            " extracting: /content/WAT/J0912+1339.png  \n",
            " extracting: /content/WAT/J0912+1559.png  \n",
            " extracting: /content/WAT/J0912+1600.png  \n",
            " extracting: /content/WAT/J0913+0317.png  \n",
            " extracting: /content/WAT/J0913+1227.png  \n",
            " extracting: /content/WAT/J0913+1826.png  \n",
            " extracting: /content/WAT/J0913+5208.png  \n",
            " extracting: /content/WAT/J0914+3000.png  \n",
            " extracting: /content/WAT/J0914+5822.png  \n",
            " extracting: /content/WAT/J0915+0833.png  \n",
            " extracting: /content/WAT/J0916+0525.png  \n",
            " extracting: /content/WAT/J0916+0808.png  \n",
            " extracting: /content/WAT/J0916+5844.png  \n",
            " extracting: /content/WAT/J0917+0245.png  \n",
            " extracting: /content/WAT/J0917+0350.png  \n",
            " extracting: /content/WAT/J0917+4322.png  \n",
            " extracting: /content/WAT/J0917+5509.png  \n",
            " extracting: /content/WAT/J0919+3609.png  \n",
            " extracting: /content/WAT/J0921+1259.png  \n",
            " extracting: /content/WAT/J0922+1223.png  \n",
            " extracting: /content/WAT/J0923+0759.png  \n",
            " extracting: /content/WAT/J0923+5706.png  \n",
            " extracting: /content/WAT/J0924+0627.png  \n",
            " extracting: /content/WAT/J0924+2326.png  \n",
            " extracting: /content/WAT/J0924-0524.png  \n",
            " extracting: /content/WAT/J0925+3627.png  \n",
            " extracting: /content/WAT/J0925-0557.png  \n",
            " extracting: /content/WAT/J0926+0309.png  \n",
            " extracting: /content/WAT/J0926+1059.png  \n",
            " extracting: /content/WAT/J0926+1651.png  \n",
            " extracting: /content/WAT/J0926+2122.png  \n",
            " extracting: /content/WAT/J0926+3247.png  \n",
            " extracting: /content/WAT/J0927+4109.png  \n",
            " extracting: /content/WAT/J0928-0507.png  \n",
            " extracting: /content/WAT/J0930+6422.png  \n",
            " extracting: /content/WAT/J0932+5533.png  \n",
            " extracting: /content/WAT/J0933+0600.png  \n",
            " extracting: /content/WAT/J0933+4519.png  \n",
            " extracting: /content/WAT/J0934+1829.png  \n",
            " extracting: /content/WAT/J0935-0325.png  \n",
            " extracting: /content/WAT/J0936-0627.png  \n",
            " extracting: /content/WAT/J0937+0245.png  \n",
            " extracting: /content/WAT/J0937+5800.png  \n",
            " extracting: /content/WAT/J0939+2319.png  \n",
            " extracting: /content/WAT/J0939+2320.png  \n",
            " extracting: /content/WAT/J0939+6208.png  \n",
            " extracting: /content/WAT/J0940+1131.png  \n",
            " extracting: /content/WAT/J0940+1510.png  \n",
            " extracting: /content/WAT/J0940+4826.png  \n",
            " extracting: /content/WAT/J0941+0814.png  \n",
            " extracting: /content/WAT/J0941+3923.png  \n",
            " extracting: /content/WAT/J0941+5751.png  \n",
            " extracting: /content/WAT/J0943+0611.png  \n",
            " extracting: /content/WAT/J0944+0247.png  \n",
            " extracting: /content/WAT/J0944-0234.png  \n",
            " extracting: /content/WAT/J0946+3604.png  \n",
            " extracting: /content/WAT/J0946-0705.png  \n",
            " extracting: /content/WAT/J0947+3403.png  \n",
            " extracting: /content/WAT/J0947+5250.png  \n",
            " extracting: /content/WAT/J0949+2915.png  \n",
            " extracting: /content/WAT/J0950+4344.png  \n",
            " extracting: /content/WAT/J0950-0437.png  \n",
            " extracting: /content/WAT/J0951+1022.png  \n",
            " extracting: /content/WAT/J0954+4304.png  \n",
            " extracting: /content/WAT/J0954+6241.png  \n",
            " extracting: /content/WAT/J0955+1102.png  \n",
            " extracting: /content/WAT/J0955-0247.png  \n",
            " extracting: /content/WAT/J0956+1835.png  \n",
            " extracting: /content/WAT/J0956+2338.png  \n",
            " extracting: /content/WAT/J0957+1906.png  \n",
            " extracting: /content/WAT/J0957+1938.png  \n",
            " extracting: /content/WAT/J0957-0644.png  \n",
            " extracting: /content/WAT/J0957-0645.png  \n",
            " extracting: /content/WAT/J0958+1916.png  \n",
            " extracting: /content/WAT/J0959+2158.png  \n",
            " extracting: /content/WAT/J0959+3005.png  \n",
            " extracting: /content/WAT/J0959+5641.png  \n",
            " extracting: /content/WAT/J0959+5751.png  \n",
            " extracting: /content/WAT/J0959-0454.png  \n",
            " extracting: /content/WAT/J1000+2635.png  \n",
            " extracting: /content/WAT/J1001+4902.png  \n",
            " extracting: /content/WAT/J1002+4756.png  \n",
            " extracting: /content/WAT/J1003+1016.png  \n",
            " extracting: /content/WAT/J1003+1020.png  \n",
            " extracting: /content/WAT/J1003+1121.png  \n",
            " extracting: /content/WAT/J1003+3730.png  \n",
            " extracting: /content/WAT/J1004+4353.png  \n",
            " extracting: /content/WAT/J1005+2315.png  \n",
            " extracting: /content/WAT/J1005+6022.png  \n",
            " extracting: /content/WAT/J1007+1550.png  \n",
            " extracting: /content/WAT/J1007+2904.png  \n",
            " extracting: /content/WAT/J1008+0142.png  \n",
            " extracting: /content/WAT/J1009+0337.png  \n",
            " extracting: /content/WAT/J1010-0601.png  \n",
            " extracting: /content/WAT/J1012+0841.png  \n",
            " extracting: /content/WAT/J1012+3639.png  \n",
            " extracting: /content/WAT/J1014+3426.png  \n",
            " extracting: /content/WAT/J1015+1221.png  \n",
            " extracting: /content/WAT/J1016+2400.png  \n",
            " extracting: /content/WAT/J1018+0348.png  \n",
            " extracting: /content/WAT/J1018+6352.png  \n",
            " extracting: /content/WAT/J1019+0019.png  \n",
            " extracting: /content/WAT/J1019+1403.png  \n",
            " extracting: /content/WAT/J1020+1714.png  \n",
            " extracting: /content/WAT/J1020+4828.png  \n",
            " extracting: /content/WAT/J1021+0024.png  \n",
            " extracting: /content/WAT/J1022+5006.png  \n",
            " extracting: /content/WAT/J1023+0428.png  \n",
            " extracting: /content/WAT/J1023+3246.png  \n",
            " extracting: /content/WAT/J1026+3259.png  \n",
            " extracting: /content/WAT/J1031-0640.png  \n",
            " extracting: /content/WAT/J1032+0144.png  \n",
            " extracting: /content/WAT/J1032+3045.png  \n",
            " extracting: /content/WAT/J1032+3151.png  \n",
            " extracting: /content/WAT/J1032+5505.png  \n",
            " extracting: /content/WAT/J1033+0755.png  \n",
            " extracting: /content/WAT/J1033+1923.png  \n",
            " extracting: /content/WAT/J1034+0736.png  \n",
            " extracting: /content/WAT/J1035+3406.png  \n",
            " extracting: /content/WAT/J1035+4255.png  \n",
            " extracting: /content/WAT/J1036+0006.png  \n",
            " extracting: /content/WAT/J1036+3835.png  \n",
            " extracting: /content/WAT/J1038+0117.png  \n",
            " extracting: /content/WAT/J1038+4148.png  \n",
            " extracting: /content/WAT/J1038+5752.png  \n",
            " extracting: /content/WAT/J1039+3338.png  \n",
            " extracting: /content/WAT/J1041+5648.png  \n",
            " extracting: /content/WAT/J1042+0237.png  \n",
            " extracting: /content/WAT/J1042+1446.png  \n",
            " extracting: /content/WAT/J1045+5250.png  \n",
            " extracting: /content/WAT/J1045+5620.png  \n",
            " extracting: /content/WAT/J1046+0538.png  \n",
            " extracting: /content/WAT/J1046+3144.png  \n",
            " extracting: /content/WAT/J1046+5434.png  \n",
            " extracting: /content/WAT/J1047-0059.png  \n",
            " extracting: /content/WAT/J1048+3532.png  \n",
            " extracting: /content/WAT/J1049+0059.png  \n",
            " extracting: /content/WAT/J1050+0432.png  \n",
            " extracting: /content/WAT/J1050+3040.png  \n",
            " extracting: /content/WAT/J1051+0051.png  \n",
            " extracting: /content/WAT/J1051+1825.png  \n",
            " extracting: /content/WAT/J1051+5041.png  \n",
            " extracting: /content/WAT/J1051+5523.png  \n",
            " extracting: /content/WAT/J1053+4302.png  \n",
            " extracting: /content/WAT/J1054+5425.png  \n",
            " extracting: /content/WAT/J1056+0255.png  \n",
            " extracting: /content/WAT/J1057+2304.png  \n",
            " extracting: /content/WAT/J1057+4749.png  \n",
            " extracting: /content/WAT/J1058+0136.png  \n",
            " extracting: /content/WAT/J1101+5603.png  \n",
            " extracting: /content/WAT/J1102+2907.png  \n",
            " extracting: /content/WAT/J1103+0356.png  \n",
            " extracting: /content/WAT/J1105+0737.png  \n",
            " extracting: /content/WAT/J1105+4105.png  \n",
            " extracting: /content/WAT/J1105+4800.png  \n",
            " extracting: /content/WAT/J1105+5943.png  \n",
            " extracting: /content/WAT/J1105-0003.png  \n",
            " extracting: /content/WAT/J1108+2610.png  \n",
            " extracting: /content/WAT/J1111+4049.png  \n",
            " extracting: /content/WAT/J1112+0150.png  \n",
            " extracting: /content/WAT/J1112+0346.png  \n",
            " extracting: /content/WAT/J1112+2347.png  \n",
            " extracting: /content/WAT/J1112+5151.png  \n",
            " extracting: /content/WAT/J1113+2056.png  \n",
            " extracting: /content/WAT/J1113+4952.png  \n",
            " extracting: /content/WAT/J1114+3625.png  \n",
            " extracting: /content/WAT/J1114+4611.png  \n",
            " extracting: /content/WAT/J1115+0613.png  \n",
            " extracting: /content/WAT/J1115+4729.png  \n",
            " extracting: /content/WAT/J1115+4834.png  \n",
            " extracting: /content/WAT/J1116+4516.png  \n",
            " extracting: /content/WAT/J1116-0435.png  \n",
            " extracting: /content/WAT/J1118+2754.png  \n",
            " extracting: /content/WAT/J1118+3115.png  \n",
            " extracting: /content/WAT/J1118-0556.png  \n",
            " extracting: /content/WAT/J1119+5516.png  \n",
            " extracting: /content/WAT/J1119+6317.png  \n",
            " extracting: /content/WAT/J1120+2912.png  \n",
            " extracting: /content/WAT/J1120+5308.png  \n",
            " extracting: /content/WAT/J1121+5421.png  \n",
            " extracting: /content/WAT/J1123-0700.png  \n",
            " extracting: /content/WAT/J1124+5546.png  \n",
            " extracting: /content/WAT/J1125+0314.png  \n",
            " extracting: /content/WAT/J1125+3618.png  \n",
            " extracting: /content/WAT/J1125+5827.png  \n",
            " extracting: /content/WAT/J1126+1624.png  \n",
            " extracting: /content/WAT/J1126+2638.png  \n",
            " extracting: /content/WAT/J1126+4003.png  \n",
            " extracting: /content/WAT/J1126+4541.png  \n",
            " extracting: /content/WAT/J1126+5925.png  \n",
            " extracting: /content/WAT/J1127+0007.png  \n",
            " extracting: /content/WAT/J1127+5533.png  \n",
            " extracting: /content/WAT/J1128+4251.png  \n",
            " extracting: /content/WAT/J1129+0550.png  \n",
            " extracting: /content/WAT/J1129+2101.png  \n",
            " extracting: /content/WAT/J1130+2524.png  \n",
            " extracting: /content/WAT/J1130+5457.png  \n",
            " extracting: /content/WAT/J1131+0435.png  \n",
            " extracting: /content/WAT/J1131+4408.png  \n",
            " extracting: /content/WAT/J1131-0600.png  \n",
            " extracting: /content/WAT/J1132+1349.png  \n",
            " extracting: /content/WAT/J1132+2002.png  \n",
            " extracting: /content/WAT/J1132+6311.png  \n",
            " extracting: /content/WAT/J1138+1554.png  \n",
            " extracting: /content/WAT/J1138+2012.png  \n",
            " extracting: /content/WAT/J1138+2039.png  \n",
            " extracting: /content/WAT/J1138+4329.png  \n",
            " extracting: /content/WAT/J1138+4339.png  \n",
            " extracting: /content/WAT/J1139+1652.png  \n",
            " extracting: /content/WAT/J1141+0544.png  \n",
            " extracting: /content/WAT/J1142+1101.png  \n",
            " extracting: /content/WAT/J1143+0729.png  \n",
            " extracting: /content/WAT/J1143+1510.png  \n",
            " extracting: /content/WAT/J1143+1525.png  \n",
            " extracting: /content/WAT/J1144+5833.png  \n",
            " extracting: /content/WAT/J1144-0114.png  \n",
            " extracting: /content/WAT/J1145-0757.png  \n",
            " extracting: /content/WAT/J1146-0504.png  \n",
            " extracting: /content/WAT/J1147+4917.png  \n",
            " extracting: /content/WAT/J1147+5421.png  \n",
            " extracting: /content/WAT/J1147+5548.png  \n",
            " extracting: /content/WAT/J1148+2153.png  \n",
            " extracting: /content/WAT/J1148+2332.png  \n",
            " extracting: /content/WAT/J1148+4119.png  \n",
            " extracting: /content/WAT/J1149+3136.png  \n",
            " extracting: /content/WAT/J1149-0144.png  \n",
            " extracting: /content/WAT/J1150+5728.png  \n",
            " extracting: /content/WAT/J1152+3405.png  \n",
            " extracting: /content/WAT/J1154+3635.png  \n",
            " extracting: /content/WAT/J1154+4949.png  \n",
            " extracting: /content/WAT/J1155+5755.png  \n",
            " extracting: /content/WAT/J1155-0125.png  \n",
            " extracting: /content/WAT/J1156+3432.png  \n",
            " extracting: /content/WAT/J1158+0037.png  \n",
            " extracting: /content/WAT/J1158+0946.png  \n",
            " extracting: /content/WAT/J1158+2117.png  \n",
            " extracting: /content/WAT/J1159-0127.png  \n",
            " extracting: /content/WAT/J1200+2942.png  \n",
            " extracting: /content/WAT/J1201+0618.png  \n",
            " extracting: /content/WAT/J1201+3257.png  \n",
            " extracting: /content/WAT/J1202+5802.png  \n",
            " extracting: /content/WAT/J1204+0358.png  \n",
            " extracting: /content/WAT/J1204+3144.png  \n",
            " extracting: /content/WAT/J1204+3757.png  \n",
            " extracting: /content/WAT/J1204+4559.png  \n",
            " extracting: /content/WAT/J1204+4832.png  \n",
            " extracting: /content/WAT/J1204+4834.png  \n",
            " extracting: /content/WAT/J1205+3204.png  \n",
            " extracting: /content/WAT/J1206+0347.png  \n",
            " extracting: /content/WAT/J1206+3152.png  \n",
            " extracting: /content/WAT/J1208+4403.png  \n",
            " extracting: /content/WAT/J1208+5458.png  \n",
            " extracting: /content/WAT/J1209+2420.png  \n",
            " extracting: /content/WAT/J1209+3708.png  \n",
            " extracting: /content/WAT/J1209+3938.png  \n",
            " extracting: /content/WAT/J1210+4812.png  \n",
            " extracting: /content/WAT/J1211+0607.png  \n",
            " extracting: /content/WAT/J1213+3229.png  \n",
            " extracting: /content/WAT/J1213+5612.png  \n",
            " extracting: /content/WAT/J1213-0327.png  \n",
            " extracting: /content/WAT/J1214+0528.png  \n",
            " extracting: /content/WAT/J1216+0342.png  \n",
            " extracting: /content/WAT/J1219+0014.png  \n",
            " extracting: /content/WAT/J1220+0750.png  \n",
            " extracting: /content/WAT/J1220+4759.png  \n",
            " extracting: /content/WAT/J1220+5334.png  \n",
            " extracting: /content/WAT/J1221+5150.png  \n",
            " extracting: /content/WAT/J1221-0108.png  \n",
            " extracting: /content/WAT/J1221-0113.png  \n",
            " extracting: /content/WAT/J1223+2234.png  \n",
            " extracting: /content/WAT/J1224+3518.png  \n",
            " extracting: /content/WAT/J1224+4905.png  \n",
            " extracting: /content/WAT/J1224+5419.png  \n",
            " extracting: /content/WAT/J1228+2643.png  \n",
            " extracting: /content/WAT/J1230+1144.png  \n",
            " extracting: /content/WAT/J1231+4915.png  \n",
            " extracting: /content/WAT/J1232+3130.png  \n",
            " extracting: /content/WAT/J1233+1928.png  \n",
            " extracting: /content/WAT/J1233+3559.png  \n",
            " extracting: /content/WAT/J1235+2444.png  \n",
            " extracting: /content/WAT/J1235+3521.png  \n",
            " extracting: /content/WAT/J1235+5625.png  \n",
            " extracting: /content/WAT/J1236+1638.png  \n",
            " extracting: /content/WAT/J1236+5525.png  \n",
            " extracting: /content/WAT/J1237+2013.png  \n",
            " extracting: /content/WAT/J1238+4838.png  \n",
            " extracting: /content/WAT/J1239+1711.png  \n",
            " extracting: /content/WAT/J1241+1407.png  \n",
            " extracting: /content/WAT/J1241+2734.png  \n",
            " extracting: /content/WAT/J1241+3823.png  \n",
            " extracting: /content/WAT/J1242+3232.png  \n",
            " extracting: /content/WAT/J1242+4041.png  \n",
            " extracting: /content/WAT/J1242+5021.png  \n",
            " extracting: /content/WAT/J1246+5453.png  \n",
            " extracting: /content/WAT/J1247+4042.png  \n",
            " extracting: /content/WAT/J1247+4852.png  \n",
            " extracting: /content/WAT/J1249+0143.png  \n",
            " extracting: /content/WAT/J1249+0144.png  \n",
            " extracting: /content/WAT/J1249+3038.png  \n",
            " extracting: /content/WAT/J1249+4954.png  \n",
            " extracting: /content/WAT/J1250+0839.png  \n",
            " extracting: /content/WAT/J1250+1133.png  \n",
            " extracting: /content/WAT/J1250-0132.png  \n",
            " extracting: /content/WAT/J1251-0123.png  \n",
            " extracting: /content/WAT/J1252+1552.png  \n",
            " extracting: /content/WAT/J1253+0604.png  \n",
            " extracting: /content/WAT/J1254+6134.png  \n",
            " extracting: /content/WAT/J1255+0152.png  \n",
            " extracting: /content/WAT/J1256+0125.png  \n",
            " extracting: /content/WAT/J1256+0619.png  \n",
            " extracting: /content/WAT/J1258+3651.png  \n",
            " extracting: /content/WAT/J1259+4617.png  \n",
            " extracting: /content/WAT/J1300+2916.png  \n",
            " extracting: /content/WAT/J1301+0013.png  \n",
            " extracting: /content/WAT/J1301-0649.png  \n",
            " extracting: /content/WAT/J1303+4743.png  \n",
            " extracting: /content/WAT/J1303+5220.png  \n",
            " extracting: /content/WAT/J1304+1040.png  \n",
            " extracting: /content/WAT/J1304+2015.png  \n",
            " extracting: /content/WAT/J1306+3338.png  \n",
            " extracting: /content/WAT/J1306+5144.png  \n",
            " extracting: /content/WAT/J1306-0539.png  \n",
            " extracting: /content/WAT/J1307+5650.png  \n",
            " extracting: /content/WAT/J1307+5651.png  \n",
            " extracting: /content/WAT/J1308+0829.png  \n",
            " extracting: /content/WAT/J1308+1751.png  \n",
            " extracting: /content/WAT/J1309+1029.png  \n",
            " extracting: /content/WAT/J1309+1938.png  \n",
            " extracting: /content/WAT/J1310+2418.png  \n",
            " extracting: /content/WAT/J1311-0120.png  \n",
            " extracting: /content/WAT/J1314+6219.png  \n",
            " extracting: /content/WAT/J1315+0612.png  \n",
            " extracting: /content/WAT/J1315+4841.png  \n",
            " extracting: /content/WAT/J1318+3421.png  \n",
            " extracting: /content/WAT/J1319+5443.png  \n",
            " extracting: /content/WAT/J1319-0055.png  \n",
            " extracting: /content/WAT/J1320+0430.png  \n",
            " extracting: /content/WAT/J1320+2834.png  \n",
            " extracting: /content/WAT/J1320-0341.png  \n",
            " extracting: /content/WAT/J1321-0637.png  \n",
            " extracting: /content/WAT/J1323+1055.png  \n",
            " extracting: /content/WAT/J1325+3419.png  \n",
            " extracting: /content/WAT/J1325+5617.png  \n",
            " extracting: /content/WAT/J1325+5736.png  \n",
            " extracting: /content/WAT/J1326+0311.png  \n",
            " extracting: /content/WAT/J1327+0007.png  \n",
            " extracting: /content/WAT/J1329-0511.png  \n",
            " extracting: /content/WAT/J1330+3816.png  \n",
            " extracting: /content/WAT/J1330+4730.png  \n",
            " extracting: /content/WAT/J1331-0544.png  \n",
            " extracting: /content/WAT/J1332+0719.png  \n",
            " extracting: /content/WAT/J1333+0932.png  \n",
            " extracting: /content/WAT/J1333+0944.png  \n",
            " extracting: /content/WAT/J1333-0139.png  \n",
            " extracting: /content/WAT/J1333-0657.png  \n",
            " extracting: /content/WAT/J1336+0047.png  \n",
            " extracting: /content/WAT/J1337-0803.png  \n",
            " extracting: /content/WAT/J1338+3851.png  \n",
            " extracting: /content/WAT/J1339-0726.png  \n",
            " extracting: /content/WAT/J1340+5439.png  \n",
            " extracting: /content/WAT/J1340+5550.png  \n",
            " extracting: /content/WAT/J1341-0116.png  \n",
            " extracting: /content/WAT/J1342+4430.png  \n",
            " extracting: /content/WAT/J1343+2928.png  \n",
            " extracting: /content/WAT/J1344+5131.png  \n",
            " extracting: /content/WAT/J1344+5552.png  \n",
            " extracting: /content/WAT/J1345+0855.png  \n",
            " extracting: /content/WAT/J1345+3655.png  \n",
            " extracting: /content/WAT/J1345+5332.png  \n",
            " extracting: /content/WAT/J1345+6110.png  \n",
            " extracting: /content/WAT/J1345-0451.png  \n",
            " extracting: /content/WAT/J1346+5250.png  \n",
            " extracting: /content/WAT/J1347+4103.png  \n",
            " extracting: /content/WAT/J1349+5421.png  \n",
            " extracting: /content/WAT/J1350+3301.png  \n",
            " extracting: /content/WAT/J1351+0712.png  \n",
            " extracting: /content/WAT/J1351+5216.png  \n",
            " extracting: /content/WAT/J1351-0548.png  \n",
            " extracting: /content/WAT/J1353+5506.png  \n",
            " extracting: /content/WAT/J1353-0732.png  \n",
            " extracting: /content/WAT/J1354+0528.png  \n",
            " extracting: /content/WAT/J1355+1758.png  \n",
            " extracting: /content/WAT/J1355+3913.png  \n",
            " extracting: /content/WAT/J1356+3056.png  \n",
            " extracting: /content/WAT/J1356+3126.png  \n",
            " extracting: /content/WAT/J1359+2808.png  \n",
            " extracting: /content/WAT/J1359+4905.png  \n",
            " extracting: /content/WAT/J1401+0740.png  \n",
            " extracting: /content/WAT/J1401+3256.png  \n",
            " extracting: /content/WAT/J1401+5654.png  \n",
            " extracting: /content/WAT/J1406+0211.png  \n",
            " extracting: /content/WAT/J1406+5504.png  \n",
            " extracting: /content/WAT/J1407+2618.png  \n",
            " extracting: /content/WAT/J1408+0511.png  \n",
            " extracting: /content/WAT/J1408+4540.png  \n",
            " extracting: /content/WAT/J1409+4336.png  \n",
            " extracting: /content/WAT/J1410+0516.png  \n",
            " extracting: /content/WAT/J1410+0727.png  \n",
            " extracting: /content/WAT/J1410+5846.png  \n",
            " extracting: /content/WAT/J1410-0636.png  \n",
            " extracting: /content/WAT/J1411+1048.png  \n",
            " extracting: /content/WAT/J1411+4535.png  \n",
            " extracting: /content/WAT/J1411-0731.png  \n",
            " extracting: /content/WAT/J1412+0043.png  \n",
            " extracting: /content/WAT/J1412+0153.png  \n",
            " extracting: /content/WAT/J1412+1400.png  \n",
            " extracting: /content/WAT/J1412+2157.png  \n",
            " extracting: /content/WAT/J1414+0012.png  \n",
            " extracting: /content/WAT/J1414+0143.png  \n",
            " extracting: /content/WAT/J1414+0148.png  \n",
            " extracting: /content/WAT/J1414+5455.png  \n",
            " extracting: /content/WAT/J1415+2326.png  \n",
            " extracting: /content/WAT/J1415-0137.png  \n",
            " extracting: /content/WAT/J1416+0219.png  \n",
            " extracting: /content/WAT/J1416+1202.png  \n",
            " extracting: /content/WAT/J1416+2147.png  \n",
            " extracting: /content/WAT/J1417+0114.png  \n",
            " extracting: /content/WAT/J1417+0608.png  \n",
            " extracting: /content/WAT/J1417+0812.png  \n",
            " extracting: /content/WAT/J1417+2019.png  \n",
            " extracting: /content/WAT/J1419+2338.png  \n",
            " extracting: /content/WAT/J1419+4657.png  \n",
            " extracting: /content/WAT/J1420-0622.png  \n",
            " extracting: /content/WAT/J1421-0743.png  \n",
            " extracting: /content/WAT/J1422+0825.png  \n",
            " extracting: /content/WAT/J1422+1144.png  \n",
            " extracting: /content/WAT/J1424+0025.png  \n",
            " extracting: /content/WAT/J1424+0403.png  \n",
            " extracting: /content/WAT/J1425+5545.png  \n",
            " extracting: /content/WAT/J1426+4102.png  \n",
            " extracting: /content/WAT/J1426+5518.png  \n",
            " extracting: /content/WAT/J1426+5547.png  \n",
            " extracting: /content/WAT/J1428+2353.png  \n",
            " extracting: /content/WAT/J1428+5520.png  \n",
            " extracting: /content/WAT/J1429+2336.png  \n",
            " extracting: /content/WAT/J1429+5443.png  \n",
            " extracting: /content/WAT/J1430+0838.png  \n",
            " extracting: /content/WAT/J1431+4743.png  \n",
            " extracting: /content/WAT/J1432+4436.png  \n",
            " extracting: /content/WAT/J1433+0330.png  \n",
            " extracting: /content/WAT/J1433+1913.png  \n",
            " extracting: /content/WAT/J1434+0137.png  \n",
            " extracting: /content/WAT/J1434+4951.png  \n",
            " extracting: /content/WAT/J1435+5507.png  \n",
            " extracting: /content/WAT/J1435-0240.png  \n",
            " extracting: /content/WAT/J1435-0409.png  \n",
            " extracting: /content/WAT/J1437+1950.png  \n",
            " extracting: /content/WAT/J1437+2034.png  \n",
            " extracting: /content/WAT/J1438+0040.png  \n",
            " extracting: /content/WAT/J1438+0926.png  \n",
            " extracting: /content/WAT/J1438+4753.png  \n",
            " extracting: /content/WAT/J1439+4152.png  \n",
            " extracting: /content/WAT/J1439+5631.png  \n",
            " extracting: /content/WAT/J1440+0328.png  \n",
            " extracting: /content/WAT/J1440+0556.png  \n",
            " extracting: /content/WAT/J1440+1125.png  \n",
            " extracting: /content/WAT/J1440+1342.png  \n",
            " extracting: /content/WAT/J1442+0919.png  \n",
            " extracting: /content/WAT/J1443+1350.png  \n",
            " extracting: /content/WAT/J1443+5201.png  \n",
            " extracting: /content/WAT/J1443-0111.png  \n",
            " extracting: /content/WAT/J1444+1921.png  \n",
            " extracting: /content/WAT/J1444+4720.png  \n",
            " extracting: /content/WAT/J1444-0311.png  \n",
            " extracting: /content/WAT/J1444-0542.png  \n",
            " extracting: /content/WAT/J1445+2951.png  \n",
            " extracting: /content/WAT/J1445+6357.png  \n",
            " extracting: /content/WAT/J1446+1402.png  \n",
            " extracting: /content/WAT/J1446+2141.png  \n",
            " extracting: /content/WAT/J1446+4319.png  \n",
            " extracting: /content/WAT/J1446+4841.png  \n",
            " extracting: /content/WAT/J1447+4602.png  \n",
            " extracting: /content/WAT/J1448+1446.png  \n",
            " extracting: /content/WAT/J1448+5944.png  \n",
            " extracting: /content/WAT/J1449+0258.png  \n",
            " extracting: /content/WAT/J1449+4000.png  \n",
            " extracting: /content/WAT/J1450+1406.png  \n",
            " extracting: /content/WAT/J1450+4418.png  \n",
            " extracting: /content/WAT/J1452+0636.png  \n",
            " extracting: /content/WAT/J1452+1707.png  \n",
            " extracting: /content/WAT/J1453+0549.png  \n",
            " extracting: /content/WAT/J1457+0232.png  \n",
            " extracting: /content/WAT/J1457+3140.png  \n",
            " extracting: /content/WAT/J1459+2754.png  \n",
            " extracting: /content/WAT/J1459+4947.png  \n",
            " extracting: /content/WAT/J1459+5334.png  \n",
            " extracting: /content/WAT/J1501+0752.png  \n",
            " extracting: /content/WAT/J1501+0857.png  \n",
            " extracting: /content/WAT/J1501+0959.png  \n",
            " extracting: /content/WAT/J1501+2134.png  \n",
            " extracting: /content/WAT/J1502+5244.png  \n",
            " extracting: /content/WAT/J1504+1409.png  \n",
            " extracting: /content/WAT/J1505+0253.png  \n",
            " extracting: /content/WAT/J1508+3554.png  \n",
            " extracting: /content/WAT/J1509+0828.png  \n",
            " extracting: /content/WAT/J1510+0544.png  \n",
            " extracting: /content/WAT/J1511+1801.png  \n",
            " extracting: /content/WAT/J1511+3228.png  \n",
            " extracting: /content/WAT/J1511+3633.png  \n",
            " extracting: /content/WAT/J1512+0612.png  \n",
            " extracting: /content/WAT/J1512+1513.png  \n",
            " extracting: /content/WAT/J1512+3018.png  \n",
            " extracting: /content/WAT/J1512+3654.png  \n",
            " extracting: /content/WAT/J1513+0547.png  \n",
            " extracting: /content/WAT/J1515+3756.png  \n",
            " extracting: /content/WAT/J1516+2918.png  \n",
            " extracting: /content/WAT/J1517-0100.png  \n",
            " extracting: /content/WAT/J1519+3623.png  \n",
            " extracting: /content/WAT/J1520+2329.png  \n",
            " extracting: /content/WAT/J1521+5104.png  \n",
            " extracting: /content/WAT/J1523+2836.png  \n",
            " extracting: /content/WAT/J1523+5255.png  \n",
            " extracting: /content/WAT/J1524+1003.png  \n",
            " extracting: /content/WAT/J1524+1321.png  \n",
            " extracting: /content/WAT/J1526+1639.png  \n",
            " extracting: /content/WAT/J1526+3510.png  \n",
            " extracting: /content/WAT/J1526+3841.png  \n",
            " extracting: /content/WAT/J1527+2810.png  \n",
            " extracting: /content/WAT/J1528+0714.png  \n",
            " extracting: /content/WAT/J1529+3042.png  \n",
            " extracting: /content/WAT/J1529-0431.png  \n",
            " extracting: /content/WAT/J1530+4224.png  \n",
            " extracting: /content/WAT/J1531+1031.png  \n",
            " extracting: /content/WAT/J1532+0028.png  \n",
            " extracting: /content/WAT/J1532+4658.png  \n",
            " extracting: /content/WAT/J1533+5700.png  \n",
            " extracting: /content/WAT/J1534+0556.png  \n",
            " extracting: /content/WAT/J1534+2920.png  \n",
            " extracting: /content/WAT/J1535+3840.png  \n",
            " extracting: /content/WAT/J1536+1420.png  \n",
            " extracting: /content/WAT/J1536-0201.png  \n",
            " extracting: /content/WAT/J1537+0623.png  \n",
            " extracting: /content/WAT/J1537+2648.png  \n",
            " extracting: /content/WAT/J1537+4051.png  \n",
            " extracting: /content/WAT/J1538+3557.png  \n",
            " extracting: /content/WAT/J1539+0450.png  \n",
            " extracting: /content/WAT/J1539-0215.png  \n",
            " extracting: /content/WAT/J1539-0544.png  \n",
            " extracting: /content/WAT/J1543+3415.png  \n",
            " extracting: /content/WAT/J1547+1456.png  \n",
            " extracting: /content/WAT/J1547-0046.png  \n",
            " extracting: /content/WAT/J1548+5813.png  \n",
            " extracting: /content/WAT/J1550+0923.png  \n",
            " extracting: /content/WAT/J1550+1200.png  \n",
            " extracting: /content/WAT/J1551+0609.png  \n",
            " extracting: /content/WAT/J1552+3437.png  \n",
            " extracting: /content/WAT/J1553+2348.png  \n",
            " extracting: /content/WAT/J1554+5819.png  \n",
            " extracting: /content/WAT/J1556+0916.png  \n",
            " extracting: /content/WAT/J1559-0143.png  \n",
            " extracting: /content/WAT/J1600+1815.png  \n",
            " extracting: /content/WAT/J1601+3155.png  \n",
            " extracting: /content/WAT/J1604+2355.png  \n",
            " extracting: /content/WAT/J1606+5610.png  \n",
            " extracting: /content/WAT/J1607+4825.png  \n",
            " extracting: /content/WAT/J1608+0141.png  \n",
            " extracting: /content/WAT/J1608+2211.png  \n",
            " extracting: /content/WAT/J1608+3254.png  \n",
            " extracting: /content/WAT/J1609+5844.png  \n",
            " extracting: /content/WAT/J1612+2929.png  \n",
            " extracting: /content/WAT/J1614+0857.png  \n",
            " extracting: /content/WAT/J1615+4711.png  \n",
            " extracting: /content/WAT/J1616+0926.png  \n",
            " extracting: /content/WAT/J1618+1754.png  \n",
            " extracting: /content/WAT/J1618+2958.png  \n",
            " extracting: /content/WAT/J1620+2521.png  \n",
            " extracting: /content/WAT/J1620+4740.png  \n",
            " extracting: /content/WAT/J1621+1140.png  \n",
            " extracting: /content/WAT/J1622+2647.png  \n",
            " extracting: /content/WAT/J1623+1009.png  \n",
            " extracting: /content/WAT/J1625+3026.png  \n",
            " extracting: /content/WAT/J1625+4456.png  \n",
            " extracting: /content/WAT/J1625+4813.png  \n",
            " extracting: /content/WAT/J1628+3933.png  \n",
            " extracting: /content/WAT/J1629+2359.png  \n",
            " extracting: /content/WAT/J1630+2854.png  \n",
            " extracting: /content/WAT/J1631+0531.png  \n",
            " extracting: /content/WAT/J1631+0535.png  \n",
            " extracting: /content/WAT/J1633+1710.png  \n",
            " extracting: /content/WAT/J1634+3415.png  \n",
            " extracting: /content/WAT/J1635+2020.png  \n",
            " extracting: /content/WAT/J1635+4309.png  \n",
            " extracting: /content/WAT/J1635+4310.png  \n",
            " extracting: /content/WAT/J1636+2718.png  \n",
            " extracting: /content/WAT/J1641+1004.png  \n",
            " extracting: /content/WAT/J1641+1325.png  \n",
            " extracting: /content/WAT/J1642+2531.png  \n",
            " extracting: /content/WAT/J1645+1046.png  \n",
            " extracting: /content/WAT/J1645+2720.png  \n",
            " extracting: /content/WAT/J1645+5842.png  \n",
            " extracting: /content/WAT/J1646+2015.png  \n",
            " extracting: /content/WAT/J1646+3627.png  \n",
            " extracting: /content/WAT/J1650+1901.png  \n",
            " extracting: /content/WAT/J1650+3202.png  \n",
            " extracting: /content/WAT/J1651+3500.png  \n",
            " extracting: /content/WAT/J1655+5217.png  \n",
            " extracting: /content/WAT/J1657+2746.png  \n",
            " extracting: /content/WAT/J1658+6256.png  \n",
            " extracting: /content/WAT/J1659+2955.png  \n",
            " extracting: /content/WAT/J1701+4959.png  \n",
            " extracting: /content/WAT/J1701+6413.png  \n",
            " extracting: /content/WAT/J1704+5845.png  \n",
            " extracting: /content/WAT/J1705+5109.png  \n",
            " extracting: /content/WAT/J1706+2006.png  \n",
            " extracting: /content/WAT/J1708+4723.png  \n",
            " extracting: /content/WAT/J1710+3332.png  \n",
            " extracting: /content/WAT/J1711+5628.png  \n",
            " extracting: /content/WAT/J1716+2608.png  \n",
            " extracting: /content/WAT/J1717+3734.png  \n",
            " extracting: /content/WAT/J1718+4202.png  \n",
            " extracting: /content/WAT/J1719+3547.png  \n",
            " extracting: /content/WAT/J1722+3201.png  \n",
            " extracting: /content/WAT/J1723+3558.png  \n",
            " extracting: /content/WAT/J1723+4757.png  \n",
            " extracting: /content/WAT/J1726+5103.png  \n",
            " extracting: /content/WAT/J1727+4030.png  \n",
            " extracting: /content/WAT/J1743+6342.png  \n",
            " extracting: /content/WAT/J2020+0026.png  \n",
            " extracting: /content/WAT/J2031+0107.png  \n",
            " extracting: /content/WAT/J2039-0017.png  \n",
            " extracting: /content/WAT/J2056+0205.png  \n",
            " extracting: /content/WAT/J2127+0042.png  \n",
            " extracting: /content/WAT/J2127-0127.png  \n",
            " extracting: /content/WAT/J2131-0555.png  \n",
            " extracting: /content/WAT/J2138-0545.png  \n",
            " extracting: /content/WAT/J2139+1008.png  \n",
            " extracting: /content/WAT/J2142+1017.png  \n",
            " extracting: /content/WAT/J2142-0549.png  \n",
            " extracting: /content/WAT/J2145-0659.png  \n",
            " extracting: /content/WAT/J2147+1215.png  \n",
            " extracting: /content/WAT/J2148-0825.png  \n",
            " extracting: /content/WAT/J2150-0744.png  \n",
            " extracting: /content/WAT/J2156+0110.png  \n",
            " extracting: /content/WAT/J2157+0037.png  \n",
            " extracting: /content/WAT/J2158-0507.png  \n",
            " extracting: /content/WAT/J2201-0451.png  \n",
            " extracting: /content/WAT/J2202-0101.png  \n",
            " extracting: /content/WAT/J2207-0102.png  \n",
            " extracting: /content/WAT/J2210-0152.png  \n",
            " extracting: /content/WAT/J2213-0854.png  \n",
            " extracting: /content/WAT/J2214-0447.png  \n",
            " extracting: /content/WAT/J2215-0757.png  \n",
            " extracting: /content/WAT/J2218+0230.png  \n",
            " extracting: /content/WAT/J2218-0921.png  \n",
            " extracting: /content/WAT/J2221-0747.png  \n",
            " extracting: /content/WAT/J2224-0023.png  \n",
            " extracting: /content/WAT/J2248+0052.png  \n",
            " extracting: /content/WAT/J2250-0141.png  \n",
            " extracting: /content/WAT/J2301+0037.png  \n",
            " extracting: /content/WAT/J2306-0357.png  \n",
            " extracting: /content/WAT/J2310+0734.png  \n",
            " extracting: /content/WAT/J2312-0919.png  \n",
            " extracting: /content/WAT/J2315-0300.png  \n",
            " extracting: /content/WAT/J2319-0737.png  \n",
            " extracting: /content/WAT/J2320-0433.png  \n",
            " extracting: /content/WAT/J2328+0038.png  \n",
            " extracting: /content/WAT/J2334-0759.png  \n",
            " extracting: /content/WAT/J2337+0043.png  \n",
            " extracting: /content/WAT/J2337-0900.png  \n",
            " extracting: /content/WAT/J2344-0658.png  \n",
            " extracting: /content/WAT/J2348+0043.png  \n",
            " extracting: /content/WAT/J2349-0812.png  \n",
            " extracting: /content/WAT/J2350-0117.png  \n",
            " extracting: /content/WAT/J2356+0119.png  \n",
            "Loaded WAT...\n",
            "Loaded NAT...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1282, 50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gc\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import imutils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from imutils import paths\n",
        "from statistics import mean\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from datetime import datetime as dt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.models import load_model, Sequential\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling1D\n",
        "\n",
        "\n",
        "!unzip '/content/FilledHoles.zip' -d '/content/'\n",
        "\n",
        "# Reading WAT Images\n",
        "imagePaths = list(paths.list_images(r\"/content/WAT\"))\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE)\n",
        "  image = image[24:74,24:74] # Crop images to 50 x 50 pixels\n",
        "  data.append(image)\n",
        "  label = 0\n",
        "  labels.append(label)\n",
        "print(\"Loaded WAT...\")\n",
        "\n",
        "# Reading NAT Images\n",
        "imagePaths = list(paths.list_images(r\"/content/NAT\"))\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE)\n",
        "  image = image[24:74,24:74] # Crop images to 50 x 50 pixels\n",
        "  data.append(image)\n",
        "  label = 1\n",
        "  labels.append(label)\n",
        "print(\"Loaded NAT...\")\n",
        "\n",
        "labels = np.array(labels,dtype='uint8')\n",
        "data = np.array(data,dtype='uint8')\n",
        "\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten Images\n",
        "data = data.reshape((len(data),50*50))\n",
        "data = pd.DataFrame(data)\n",
        "labels = pd.DataFrame(labels)\n",
        "BB = pd.concat([data,labels], axis=1)\n",
        "WAT = BB[0:848]\n",
        "NAT = BB[848:]\n",
        "\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlQa0z1CKo0W",
        "outputId": "a9878e2c-795e-4b42-9652-d00c89e506e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1282, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Choose Number of Samples per Class ; Max is 2000 for a Balanced Dataset\n",
        "samplesize=400\n",
        "\n",
        "# # Balancing the Dataset\n",
        "WAT_s = WAT.sample(n=samplesize,random_state=42)\n",
        "NAT_s = NAT.sample(n=samplesize,random_state=42)\n",
        "Images_s = pd.concat([WAT_s,NAT_s])\n",
        "Images_s = shuffle(Images_s,random_state=42)\n",
        "lbl = Images_s.iloc[:,-1:]\n",
        "Imgs = Images_s.iloc[:,:-1]\n",
        "Imgs = np.array(Imgs)\n",
        "lbl = np.array(lbl)\n",
        "\n",
        "\n",
        "print(\"\\nWAT_s shape:\", WAT_s.shape)\n",
        "print(\"NAT_s shape:\", NAT_s.shape)\n",
        "print(\"\\nImages_s shape:\", Images_s.shape)\n",
        "print(\"\\nLabels (lbl) shape:\", lbl.shape)\n",
        "print(\"First 10 labels:\", lbl[:10])\n",
        "print(\"Label counts:\", np.unique(lbl, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_rP9gAgK16N",
        "outputId": "18fdc400-59a0-4b00-baa9-259904969582"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WAT_s shape: (400, 2501)\n",
            "NAT_s shape: (400, 2501)\n",
            "\n",
            "Images_s shape: (800, 2501)\n",
            "\n",
            "Labels (lbl) shape: (800, 1)\n",
            "First 10 labels: [[1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "Label counts: (array([0, 1], dtype=uint8), array([400, 400]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "lbl = onehot_encoder.fit_transform(lbl)\n",
        "lbl = np.round(lbl).astype(int)\n",
        "lbl = np.array(lbl)\n",
        "\n",
        "print(\"--- After One-Hot Encoding ---\")\n",
        "print(\"New shape of labels (lbl):\", lbl.shape)\n",
        "print(\"First 10 one-hot encoded labels:\\n\", lbl[:10])\n",
        "print(\"Data type of lbl elements:\", lbl.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK8RSpjwL0X5",
        "outputId": "1e2aaa51-5055-48e1-a882-ef8401240bec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- After One-Hot Encoding ---\n",
            "New shape of labels (lbl): (800, 2)\n",
            "First 10 one-hot encoded labels:\n",
            " [[0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]]\n",
            "Data type of lbl elements: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = RepeatedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
        "count=0\n",
        "ConfMat_CNN2D = []\n",
        "print(f\"Total number of folds: {len(list(kf.split(Imgs)))}\")"
      ],
      "metadata": {
        "id": "NlxKHAFyNH5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9249ab8-2e71-48aa-bc31-314a0eb61954"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of folds: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ldzUrZZcdRuu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1rTeuCmj-i_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9076567f-2d87-4b28-a533-91f0bc85c4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4755 - loss: 16.9762\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 127ms/step - accuracy: 0.4756 - loss: 16.8867 - val_accuracy: 0.5300 - val_loss: 9.4778\n",
            "Epoch 2/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5234 - loss: 9.0893\n",
            "Epoch 2: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5233 - loss: 9.0822 - val_accuracy: 0.4700 - val_loss: 7.9866\n",
            "Epoch 3/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5093 - loss: 7.6904\n",
            "Epoch 3: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5094 - loss: 7.6730 - val_accuracy: 0.5100 - val_loss: 6.7972\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5183 - loss: 6.5516\n",
            "Epoch 4: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5184 - loss: 6.5423 - val_accuracy: 0.4200 - val_loss: 5.8321\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5332 - loss: 5.6283\n",
            "Epoch 5: val_accuracy improved from 0.53000 to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5331 - loss: 5.6207 - val_accuracy: 0.5900 - val_loss: 5.0367\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5219 - loss: 4.8722\n",
            "Epoch 6: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5221 - loss: 4.8659 - val_accuracy: 0.4300 - val_loss: 4.3797\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5311 - loss: 4.2399\n",
            "Epoch 7: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5312 - loss: 4.2345 - val_accuracy: 0.4300 - val_loss: 3.8279\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: 3.7103\n",
            "Epoch 8: val_accuracy improved from 0.59000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5321 - loss: 3.7058 - val_accuracy: 0.6400 - val_loss: 3.3586\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5664 - loss: 3.2677\n",
            "Epoch 9: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5651 - loss: 3.2643 - val_accuracy: 0.6100 - val_loss: 2.9847\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5399 - loss: 2.8994\n",
            "Epoch 10: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5396 - loss: 2.8962 - val_accuracy: 0.6000 - val_loss: 2.6494\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5509 - loss: 2.5780\n",
            "Epoch 11: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5507 - loss: 2.5753 - val_accuracy: 0.4300 - val_loss: 2.3757\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5434 - loss: 2.3082\n",
            "Epoch 12: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5441 - loss: 2.3058 - val_accuracy: 0.6200 - val_loss: 2.1065\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 2.0782\n",
            "Epoch 13: val_accuracy improved from 0.64000 to 0.69000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5377 - loss: 2.0760 - val_accuracy: 0.6900 - val_loss: 1.8829\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5980 - loss: 1.8634\n",
            "Epoch 14: val_accuracy did not improve from 0.69000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5981 - loss: 1.8618 - val_accuracy: 0.6700 - val_loss: 1.6958\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5965 - loss: 1.7054\n",
            "Epoch 15: val_accuracy improved from 0.69000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5965 - loss: 1.7039 - val_accuracy: 0.7500 - val_loss: 1.5652\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6494 - loss: 1.5395\n",
            "Epoch 16: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6495 - loss: 1.5383 - val_accuracy: 0.6700 - val_loss: 1.4337\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6764 - loss: 1.3977\n",
            "Epoch 17: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6761 - loss: 1.3970 - val_accuracy: 0.6900 - val_loss: 1.3257\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6853 - loss: 1.3057\n",
            "Epoch 18: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6852 - loss: 1.3046 - val_accuracy: 0.7100 - val_loss: 1.1866\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7067 - loss: 1.1878\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7065 - loss: 1.1873 - val_accuracy: 0.6800 - val_loss: 1.1300\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7159 - loss: 1.1059\n",
            "Epoch 20: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7154 - loss: 1.1058 - val_accuracy: 0.7500 - val_loss: 1.0251\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7106 - loss: 1.0409\n",
            "Epoch 21: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7106 - loss: 1.0404 - val_accuracy: 0.7300 - val_loss: 0.9707\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7224 - loss: 0.9880\n",
            "Epoch 22: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7222 - loss: 0.9878 - val_accuracy: 0.6700 - val_loss: 0.9677\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7190 - loss: 0.9349\n",
            "Epoch 23: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7197 - loss: 0.9339 - val_accuracy: 0.7500 - val_loss: 0.8908\n",
            "Epoch 24/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7295 - loss: 0.8956\n",
            "Epoch 24: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7286 - loss: 0.8957 - val_accuracy: 0.7700 - val_loss: 0.8527\n",
            "Epoch 25/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7268 - loss: 0.8656\n",
            "Epoch 25: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7279 - loss: 0.8635 - val_accuracy: 0.7200 - val_loss: 0.8547\n",
            "Epoch 26/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7397 - loss: 0.8206\n",
            "Epoch 26: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7396 - loss: 0.8206 - val_accuracy: 0.7500 - val_loss: 0.8291\n",
            "Epoch 27/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7437 - loss: 0.7942\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7439 - loss: 0.7933 - val_accuracy: 0.7200 - val_loss: 0.7910\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7295 - loss: 0.7687\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7294 - loss: 0.7688 - val_accuracy: 0.5600 - val_loss: 0.8861\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 0.7708\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7199 - loss: 0.7699 - val_accuracy: 0.7000 - val_loss: 0.7799\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7605 - loss: 0.7137\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7598 - loss: 0.7141 - val_accuracy: 0.7300 - val_loss: 0.7664\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7524 - loss: 0.7102\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7522 - loss: 0.7102 - val_accuracy: 0.7200 - val_loss: 0.7451\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7496 - loss: 0.6998\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7492 - loss: 0.7002 - val_accuracy: 0.7100 - val_loss: 0.7266\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7433 - loss: 0.6953\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7433 - loss: 0.6950 - val_accuracy: 0.6600 - val_loss: 0.7615\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7433 - loss: 0.6845\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7436 - loss: 0.6841 - val_accuracy: 0.7300 - val_loss: 0.7159\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7652 - loss: 0.6562\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7650 - loss: 0.6566 - val_accuracy: 0.7400 - val_loss: 0.7159\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7753 - loss: 0.6405\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7748 - loss: 0.6409 - val_accuracy: 0.6600 - val_loss: 0.7875\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7670 - loss: 0.6398\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7668 - loss: 0.6403 - val_accuracy: 0.7300 - val_loss: 0.6985\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7445 - loss: 0.6633\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7446 - loss: 0.6632 - val_accuracy: 0.7100 - val_loss: 0.7229\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7426 - loss: 0.6599\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7426 - loss: 0.6595 - val_accuracy: 0.7300 - val_loss: 0.7047\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7733 - loss: 0.6153\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7727 - loss: 0.6163 - val_accuracy: 0.7500 - val_loss: 0.7077\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7563 - loss: 0.6499\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7561 - loss: 0.6501 - val_accuracy: 0.6800 - val_loss: 0.7560\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7563 - loss: 0.6384\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7563 - loss: 0.6385 - val_accuracy: 0.7300 - val_loss: 0.6775\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7681 - loss: 0.6110\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7680 - loss: 0.6116 - val_accuracy: 0.7100 - val_loss: 0.7221\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7827 - loss: 0.6011\n",
            "Epoch 44: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7821 - loss: 0.6019 - val_accuracy: 0.7100 - val_loss: 0.7209\n",
            "Epoch 44: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
            "1 / 50\n",
            "\n",
            "--- Fold 2 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4871 - loss: 16.4841\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.4874 - loss: 16.3975 - val_accuracy: 0.5000 - val_loss: 9.2732\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5205 - loss: 8.9015\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5198 - loss: 8.8551 - val_accuracy: 0.5400 - val_loss: 7.7082\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4996 - loss: 7.4001\n",
            "Epoch 3: val_accuracy improved from 0.54000 to 0.66000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5003 - loss: 7.3883 - val_accuracy: 0.6600 - val_loss: 6.4864\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5451 - loss: 6.2425\n",
            "Epoch 4: val_accuracy improved from 0.66000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5453 - loss: 6.2282 - val_accuracy: 0.7100 - val_loss: 5.5024\n",
            "Epoch 5/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5470 - loss: 5.3204\n",
            "Epoch 5: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5499 - loss: 5.2965 - val_accuracy: 0.6500 - val_loss: 4.6931\n",
            "Epoch 6/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5723 - loss: 4.5645\n",
            "Epoch 6: val_accuracy improved from 0.71000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5737 - loss: 4.5387 - val_accuracy: 0.7200 - val_loss: 4.0245\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6109 - loss: 3.9195\n",
            "Epoch 7: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6112 - loss: 3.9142 - val_accuracy: 0.6500 - val_loss: 3.4825\n",
            "Epoch 8/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6330 - loss: 3.4112\n",
            "Epoch 8: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6367 - loss: 3.3949 - val_accuracy: 0.6700 - val_loss: 3.0327\n",
            "Epoch 9/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6603 - loss: 2.9793\n",
            "Epoch 9: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6620 - loss: 2.9707 - val_accuracy: 0.7200 - val_loss: 2.6442\n",
            "Epoch 10/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6884 - loss: 2.6074\n",
            "Epoch 10: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6885 - loss: 2.6006 - val_accuracy: 0.7100 - val_loss: 2.3495\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6785 - loss: 2.3250\n",
            "Epoch 11: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6793 - loss: 2.3209 - val_accuracy: 0.7000 - val_loss: 2.0829\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6911 - loss: 2.0762\n",
            "Epoch 12: val_accuracy improved from 0.72000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6915 - loss: 2.0736 - val_accuracy: 0.7400 - val_loss: 1.9169\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6852 - loss: 1.8684\n",
            "Epoch 13: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6858 - loss: 1.8662 - val_accuracy: 0.7500 - val_loss: 1.7058\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7145 - loss: 1.6771\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7143 - loss: 1.6754 - val_accuracy: 0.6900 - val_loss: 1.5644\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7362 - loss: 1.5023\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7356 - loss: 1.5014 - val_accuracy: 0.7300 - val_loss: 1.4270\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7247 - loss: 1.3850\n",
            "Epoch 16: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7248 - loss: 1.3839 - val_accuracy: 0.7700 - val_loss: 1.3004\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7470 - loss: 1.2719\n",
            "Epoch 17: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7465 - loss: 1.2714 - val_accuracy: 0.6900 - val_loss: 1.2477\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7325 - loss: 1.2022\n",
            "Epoch 18: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7328 - loss: 1.2009 - val_accuracy: 0.6000 - val_loss: 1.2091\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7297 - loss: 1.1088\n",
            "Epoch 19: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7299 - loss: 1.1081 - val_accuracy: 0.6500 - val_loss: 1.1061\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7233 - loss: 1.0447\n",
            "Epoch 20: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7235 - loss: 1.0439 - val_accuracy: 0.6900 - val_loss: 1.0244\n",
            "Epoch 21/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7431 - loss: 0.9844\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7438 - loss: 0.9817 - val_accuracy: 0.7300 - val_loss: 0.9553\n",
            "Epoch 22/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7488 - loss: 0.9158\n",
            "Epoch 22: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7486 - loss: 0.9160 - val_accuracy: 0.6600 - val_loss: 0.9381\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7459 - loss: 0.8890\n",
            "Epoch 23: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7459 - loss: 0.8884 - val_accuracy: 0.6900 - val_loss: 0.8994\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7417 - loss: 0.8607\n",
            "Epoch 24: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7420 - loss: 0.8600 - val_accuracy: 0.7700 - val_loss: 0.8649\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7351 - loss: 0.8434\n",
            "Epoch 25: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7359 - loss: 0.8421 - val_accuracy: 0.7300 - val_loss: 0.8164\n",
            "Epoch 26/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7508 - loss: 0.7954\n",
            "Epoch 26: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7511 - loss: 0.7947 - val_accuracy: 0.7000 - val_loss: 0.8278\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7712 - loss: 0.7508\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7703 - loss: 0.7515 - val_accuracy: 0.7200 - val_loss: 0.7907\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7685 - loss: 0.7245\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7680 - loss: 0.7251 - val_accuracy: 0.6700 - val_loss: 0.7994\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7583 - loss: 0.7245\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7584 - loss: 0.7243 - val_accuracy: 0.7600 - val_loss: 0.7782\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7450 - loss: 0.7217\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7452 - loss: 0.7216 - val_accuracy: 0.7500 - val_loss: 0.7499\n",
            "Epoch 31/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7854 - loss: 0.6714\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7839 - loss: 0.6731 - val_accuracy: 0.7000 - val_loss: 0.7775\n",
            "Epoch 32/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7669 - loss: 0.6881\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7661 - loss: 0.6893 - val_accuracy: 0.7400 - val_loss: 0.7211\n",
            "Epoch 33/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7714 - loss: 0.6695\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7714 - loss: 0.6695 - val_accuracy: 0.7600 - val_loss: 0.7111\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7758 - loss: 0.6684\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7758 - loss: 0.6682 - val_accuracy: 0.7000 - val_loss: 0.7407\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7594 - loss: 0.6836\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7595 - loss: 0.6833 - val_accuracy: 0.7700 - val_loss: 0.6946\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7718 - loss: 0.6577\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7716 - loss: 0.6577 - val_accuracy: 0.6800 - val_loss: 0.7365\n",
            "Epoch 36: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "2 / 50\n",
            "\n",
            "--- Fold 3 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4880 - loss: 19.0404\n",
            "Epoch 1: val_accuracy improved from -inf to 0.58000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 0.4880 - loss: 18.9215 - val_accuracy: 0.5800 - val_loss: 9.4871\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5059 - loss: 9.1343\n",
            "Epoch 2: val_accuracy did not improve from 0.58000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5065 - loss: 9.0903 - val_accuracy: 0.5400 - val_loss: 7.9995\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5248 - loss: 7.6994\n",
            "Epoch 3: val_accuracy did not improve from 0.58000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5245 - loss: 7.6881 - val_accuracy: 0.5000 - val_loss: 6.8198\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5334 - loss: 6.5774\n",
            "Epoch 4: val_accuracy did not improve from 0.58000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5329 - loss: 6.5683 - val_accuracy: 0.5400 - val_loss: 5.8636\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5492 - loss: 5.6636\n",
            "Epoch 5: val_accuracy improved from 0.58000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5489 - loss: 5.6562 - val_accuracy: 0.6000 - val_loss: 5.0805\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5391 - loss: 4.9179\n",
            "Epoch 6: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5391 - loss: 4.9117 - val_accuracy: 0.5200 - val_loss: 4.4344\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5644 - loss: 4.2960\n",
            "Epoch 7: val_accuracy improved from 0.60000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5642 - loss: 4.2909 - val_accuracy: 0.6400 - val_loss: 3.8850\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5895 - loss: 3.7724\n",
            "Epoch 8: val_accuracy improved from 0.64000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5898 - loss: 3.7679 - val_accuracy: 0.7100 - val_loss: 3.4028\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6274 - loss: 3.3228\n",
            "Epoch 9: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6277 - loss: 3.3191 - val_accuracy: 0.5700 - val_loss: 3.0674\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6623 - loss: 2.9497\n",
            "Epoch 10: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6622 - loss: 2.9469 - val_accuracy: 0.7000 - val_loss: 2.7024\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6598 - loss: 2.6430\n",
            "Epoch 11: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6605 - loss: 2.6400 - val_accuracy: 0.5400 - val_loss: 2.5012\n",
            "Epoch 12/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6701 - loss: 2.3848\n",
            "Epoch 12: val_accuracy improved from 0.71000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6690 - loss: 2.3786 - val_accuracy: 0.7200 - val_loss: 2.2110\n",
            "Epoch 13/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7107 - loss: 2.1242\n",
            "Epoch 13: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7104 - loss: 2.1203 - val_accuracy: 0.5800 - val_loss: 2.0212\n",
            "Epoch 14/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6935 - loss: 1.9431\n",
            "Epoch 14: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6931 - loss: 1.9375 - val_accuracy: 0.7100 - val_loss: 1.8190\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7006 - loss: 1.7776\n",
            "Epoch 15: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7008 - loss: 1.7760 - val_accuracy: 0.7100 - val_loss: 1.6731\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7225 - loss: 1.6159\n",
            "Epoch 16: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7226 - loss: 1.6149 - val_accuracy: 0.7000 - val_loss: 1.5628\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7301 - loss: 1.4908\n",
            "Epoch 17: val_accuracy improved from 0.72000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7297 - loss: 1.4899 - val_accuracy: 0.7300 - val_loss: 1.4173\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7346 - loss: 1.3727\n",
            "Epoch 18: val_accuracy improved from 0.73000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7340 - loss: 1.3726 - val_accuracy: 0.7500 - val_loss: 1.3374\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7243 - loss: 1.2863\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7242 - loss: 1.2858 - val_accuracy: 0.6800 - val_loss: 1.2607\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7413 - loss: 1.2124\n",
            "Epoch 20: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7411 - loss: 1.2117 - val_accuracy: 0.7700 - val_loss: 1.1687\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7529 - loss: 1.1207\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7521 - loss: 1.1211 - val_accuracy: 0.7100 - val_loss: 1.0990\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7409 - loss: 1.0639\n",
            "Epoch 22: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7408 - loss: 1.0636 - val_accuracy: 0.7400 - val_loss: 1.0660\n",
            "Epoch 23/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7471 - loss: 1.0043\n",
            "Epoch 23: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7471 - loss: 1.0041 - val_accuracy: 0.7000 - val_loss: 1.0323\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7346 - loss: 0.9718\n",
            "Epoch 24: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 0.9717 - val_accuracy: 0.6800 - val_loss: 0.9845\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7377 - loss: 0.9232\n",
            "Epoch 25: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7377 - loss: 0.9232 - val_accuracy: 0.7700 - val_loss: 0.9080\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7411 - loss: 0.9020\n",
            "Epoch 26: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 0.9014 - val_accuracy: 0.7000 - val_loss: 0.9181\n",
            "Epoch 27/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7390 - loss: 0.8637\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7391 - loss: 0.8635 - val_accuracy: 0.6700 - val_loss: 0.9089\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7329 - loss: 0.8510\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7335 - loss: 0.8500 - val_accuracy: 0.6300 - val_loss: 0.8833\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7432 - loss: 0.8067\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7433 - loss: 0.8063 - val_accuracy: 0.5900 - val_loss: 0.9077\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7325 - loss: 0.8007\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7325 - loss: 0.8005 - val_accuracy: 0.5500 - val_loss: 0.8993\n",
            "Epoch 31/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7567 - loss: 0.7707\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7552 - loss: 0.7706 - val_accuracy: 0.7500 - val_loss: 0.8138\n",
            "Epoch 32/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7521 - loss: 0.7384\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7517 - loss: 0.7383 - val_accuracy: 0.6800 - val_loss: 0.8023\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7534 - loss: 0.7251\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7532 - loss: 0.7252 - val_accuracy: 0.7200 - val_loss: 0.7808\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7596 - loss: 0.7065\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7594 - loss: 0.7068 - val_accuracy: 0.7300 - val_loss: 0.7698\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7595 - loss: 0.6967\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7594 - loss: 0.6968 - val_accuracy: 0.7500 - val_loss: 0.7425\n",
            "Epoch 36/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7639 - loss: 0.6888\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7635 - loss: 0.6890 - val_accuracy: 0.6900 - val_loss: 0.7734\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7691 - loss: 0.6737\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.6743 - val_accuracy: 0.7400 - val_loss: 0.7311\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.6831\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7542 - loss: 0.6833 - val_accuracy: 0.7300 - val_loss: 0.7155\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7591 - loss: 0.6645\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7592 - loss: 0.6643 - val_accuracy: 0.7500 - val_loss: 0.7076\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7730 - loss: 0.6574\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7728 - loss: 0.6576 - val_accuracy: 0.7000 - val_loss: 0.7527\n",
            "Epoch 40: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
            "3 / 50\n",
            "\n",
            "--- Fold 4 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4860 - loss: 15.6943\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 0.4862 - loss: 15.6156 - val_accuracy: 0.5000 - val_loss: 8.9206\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5296 - loss: 8.4792\n",
            "Epoch 2: val_accuracy did not improve from 0.50000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5279 - loss: 8.4454 - val_accuracy: 0.4800 - val_loss: 7.1975\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4916 - loss: 6.8727\n",
            "Epoch 3: val_accuracy did not improve from 0.50000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4920 - loss: 6.8606 - val_accuracy: 0.4700 - val_loss: 5.9409\n",
            "Epoch 4/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5162 - loss: 5.7017\n",
            "Epoch 4: val_accuracy improved from 0.50000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5160 - loss: 5.6828 - val_accuracy: 0.5400 - val_loss: 4.9747\n",
            "Epoch 5/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5405 - loss: 4.7835\n",
            "Epoch 5: val_accuracy improved from 0.54000 to 0.63000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5410 - loss: 4.7724 - val_accuracy: 0.6300 - val_loss: 4.2128\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5485 - loss: 4.0572\n",
            "Epoch 6: val_accuracy did not improve from 0.63000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5490 - loss: 4.0513 - val_accuracy: 0.6300 - val_loss: 3.5973\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5544 - loss: 3.4830\n",
            "Epoch 7: val_accuracy did not improve from 0.63000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5546 - loss: 3.4782 - val_accuracy: 0.5600 - val_loss: 3.1040\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5543 - loss: 3.0200\n",
            "Epoch 8: val_accuracy improved from 0.63000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5551 - loss: 3.0159 - val_accuracy: 0.7000 - val_loss: 2.6858\n",
            "Epoch 9/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5979 - loss: 2.6189\n",
            "Epoch 9: val_accuracy improved from 0.70000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5982 - loss: 2.6172 - val_accuracy: 0.7100 - val_loss: 2.3243\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6301 - loss: 2.2914\n",
            "Epoch 10: val_accuracy improved from 0.71000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6301 - loss: 2.2890 - val_accuracy: 0.7300 - val_loss: 2.0456\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6260 - loss: 2.0498\n",
            "Epoch 11: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6269 - loss: 2.0461 - val_accuracy: 0.6600 - val_loss: 1.8535\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6770 - loss: 1.8088\n",
            "Epoch 12: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6769 - loss: 1.8069 - val_accuracy: 0.7000 - val_loss: 1.6317\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7098 - loss: 1.6070\n",
            "Epoch 13: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7094 - loss: 1.6060 - val_accuracy: 0.7400 - val_loss: 1.4667\n",
            "Epoch 14/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7048 - loss: 1.4717\n",
            "Epoch 14: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7037 - loss: 1.4687 - val_accuracy: 0.6800 - val_loss: 1.3644\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7130 - loss: 1.3358\n",
            "Epoch 15: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7135 - loss: 1.3345 - val_accuracy: 0.5900 - val_loss: 1.3006\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7059 - loss: 1.2438\n",
            "Epoch 16: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7063 - loss: 1.2424 - val_accuracy: 0.6900 - val_loss: 1.1646\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7372 - loss: 1.1315\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 1.1308 - val_accuracy: 0.7300 - val_loss: 1.0995\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7404 - loss: 1.0569\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7405 - loss: 1.0562 - val_accuracy: 0.6400 - val_loss: 1.0593\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7181 - loss: 1.0073\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7180 - loss: 1.0070 - val_accuracy: 0.7300 - val_loss: 0.9728\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7383 - loss: 0.9446\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7379 - loss: 0.9442 - val_accuracy: 0.7300 - val_loss: 0.9365\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.9017\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7312 - loss: 0.9010 - val_accuracy: 0.7200 - val_loss: 0.9005\n",
            "Epoch 22/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7463 - loss: 0.8477\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7460 - loss: 0.8475 - val_accuracy: 0.7400 - val_loss: 0.8794\n",
            "Epoch 23/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7374 - loss: 0.8306\n",
            "Epoch 23: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7370 - loss: 0.8298 - val_accuracy: 0.7200 - val_loss: 0.8274\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7403 - loss: 0.7928\n",
            "Epoch 24: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7405 - loss: 0.7924 - val_accuracy: 0.7000 - val_loss: 0.8104\n",
            "Epoch 25/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7582 - loss: 0.7644\n",
            "Epoch 25: val_accuracy improved from 0.74000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7577 - loss: 0.7638 - val_accuracy: 0.7600 - val_loss: 0.7559\n",
            "Epoch 26/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7618 - loss: 0.7258\n",
            "Epoch 26: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7606 - loss: 0.7271 - val_accuracy: 0.7000 - val_loss: 0.7800\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7601 - loss: 0.7199\n",
            "Epoch 27: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7598 - loss: 0.7198 - val_accuracy: 0.7100 - val_loss: 0.7598\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7686 - loss: 0.6967\n",
            "Epoch 28: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7679 - loss: 0.6969 - val_accuracy: 0.7200 - val_loss: 0.7519\n",
            "Epoch 29/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7742 - loss: 0.6793\n",
            "Epoch 29: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7740 - loss: 0.6795 - val_accuracy: 0.7600 - val_loss: 0.7173\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7800 - loss: 0.6696\n",
            "Epoch 30: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7794 - loss: 0.6700 - val_accuracy: 0.7600 - val_loss: 0.7518\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7701 - loss: 0.6767\n",
            "Epoch 31: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7697 - loss: 0.6766 - val_accuracy: 0.7000 - val_loss: 0.7124\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7590 - loss: 0.6544\n",
            "Epoch 32: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7593 - loss: 0.6545 - val_accuracy: 0.7000 - val_loss: 0.7131\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7568 - loss: 0.6639\n",
            "Epoch 33: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7570 - loss: 0.6636 - val_accuracy: 0.7400 - val_loss: 0.7017\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7646 - loss: 0.6415\n",
            "Epoch 34: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7645 - loss: 0.6417 - val_accuracy: 0.7500 - val_loss: 0.6950\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7771 - loss: 0.6338\n",
            "Epoch 35: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7772 - loss: 0.6339 - val_accuracy: 0.7700 - val_loss: 0.7195\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7757 - loss: 0.6301\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7756 - loss: 0.6301 - val_accuracy: 0.7500 - val_loss: 0.6956\n",
            "Epoch 37/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7652 - loss: 0.6237\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7651 - loss: 0.6242 - val_accuracy: 0.7300 - val_loss: 0.7229\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7785 - loss: 0.6172\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7780 - loss: 0.6179 - val_accuracy: 0.5600 - val_loss: 0.8374\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7392 - loss: 0.6629\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7395 - loss: 0.6628 - val_accuracy: 0.7300 - val_loss: 0.6999\n",
            "Epoch 40/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7801 - loss: 0.6289\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7780 - loss: 0.6306 - val_accuracy: 0.6700 - val_loss: 0.7172\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7862 - loss: 0.6139\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7858 - loss: 0.6142 - val_accuracy: 0.7200 - val_loss: 0.7063\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7918 - loss: 0.5994\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7913 - loss: 0.6001 - val_accuracy: 0.7100 - val_loss: 0.7384\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7700 - loss: 0.6161\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7698 - loss: 0.6165 - val_accuracy: 0.7100 - val_loss: 0.7194\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7764 - loss: 0.6253\n",
            "Epoch 44: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7764 - loss: 0.6251 - val_accuracy: 0.7100 - val_loss: 0.7057\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7877 - loss: 0.5997\n",
            "Epoch 45: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7871 - loss: 0.6002 - val_accuracy: 0.7100 - val_loss: 0.7331\n",
            "Epoch 46/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7811 - loss: 0.6148\n",
            "Epoch 46: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7804 - loss: 0.6159 - val_accuracy: 0.6400 - val_loss: 0.8090\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7895 - loss: 0.5974\n",
            "Epoch 47: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7882 - loss: 0.5989 - val_accuracy: 0.7500 - val_loss: 0.6871\n",
            "Epoch 48/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7870 - loss: 0.6054\n",
            "Epoch 48: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7865 - loss: 0.6068 - val_accuracy: 0.7100 - val_loss: 0.7283\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7913 - loss: 0.6071\n",
            "Epoch 49: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7910 - loss: 0.6075 - val_accuracy: 0.6300 - val_loss: 0.8205\n",
            "Epoch 50/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7886 - loss: 0.6041\n",
            "Epoch 50: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7883 - loss: 0.6044 - val_accuracy: 0.7400 - val_loss: 0.6989\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "4 / 50\n",
            "\n",
            "--- Fold 5 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5252 - loss: 19.1327\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 138ms/step - accuracy: 0.5250 - loss: 19.0116 - val_accuracy: 0.4700 - val_loss: 9.3493\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5157 - loss: 8.9957\n",
            "Epoch 2: val_accuracy improved from 0.47000 to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5151 - loss: 8.9604 - val_accuracy: 0.5900 - val_loss: 7.9071\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5105 - loss: 7.6222\n",
            "Epoch 3: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5103 - loss: 7.6114 - val_accuracy: 0.4700 - val_loss: 6.7786\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5239 - loss: 6.5517\n",
            "Epoch 4: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5232 - loss: 6.5384 - val_accuracy: 0.5300 - val_loss: 5.8618\n",
            "Epoch 5/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5256 - loss: 5.6951\n",
            "Epoch 5: val_accuracy improved from 0.59000 to 0.63000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5260 - loss: 5.6654 - val_accuracy: 0.6300 - val_loss: 5.1016\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5269 - loss: 4.9529\n",
            "Epoch 6: val_accuracy improved from 0.63000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5275 - loss: 4.9468 - val_accuracy: 0.7300 - val_loss: 4.4537\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5757 - loss: 4.3439\n",
            "Epoch 7: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5757 - loss: 4.3388 - val_accuracy: 0.6700 - val_loss: 3.8971\n",
            "Epoch 8/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5863 - loss: 3.8326\n",
            "Epoch 8: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5867 - loss: 3.8304 - val_accuracy: 0.7400 - val_loss: 3.3984\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6098 - loss: 3.3944\n",
            "Epoch 9: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6103 - loss: 3.3905 - val_accuracy: 0.7400 - val_loss: 3.0458\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6647 - loss: 3.0165\n",
            "Epoch 10: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6640 - loss: 3.0138 - val_accuracy: 0.7400 - val_loss: 2.6902\n",
            "Epoch 11/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6750 - loss: 2.6856\n",
            "Epoch 11: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6749 - loss: 2.6846 - val_accuracy: 0.6800 - val_loss: 2.4596\n",
            "Epoch 12/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6788 - loss: 2.4320\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6770 - loss: 2.4268 - val_accuracy: 0.7200 - val_loss: 2.2000\n",
            "Epoch 13/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6665 - loss: 2.2117\n",
            "Epoch 13: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6661 - loss: 2.2083 - val_accuracy: 0.7500 - val_loss: 1.9814\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6948 - loss: 1.9930\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6948 - loss: 1.9916 - val_accuracy: 0.7100 - val_loss: 1.8441\n",
            "Epoch 15/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7043 - loss: 1.8265\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7042 - loss: 1.8258 - val_accuracy: 0.6800 - val_loss: 1.7099\n",
            "Epoch 16/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7039 - loss: 1.6672\n",
            "Epoch 16: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7039 - loss: 1.6666 - val_accuracy: 0.7700 - val_loss: 1.5414\n",
            "Epoch 17/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7065 - loss: 1.5548\n",
            "Epoch 17: val_accuracy improved from 0.77000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7064 - loss: 1.5543 - val_accuracy: 0.7800 - val_loss: 1.3804\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7061 - loss: 1.4377\n",
            "Epoch 18: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7063 - loss: 1.4367 - val_accuracy: 0.7600 - val_loss: 1.2903\n",
            "Epoch 19/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7089 - loss: 1.3491\n",
            "Epoch 19: val_accuracy improved from 0.78000 to 0.85000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7103 - loss: 1.3429 - val_accuracy: 0.8500 - val_loss: 1.1772\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7175 - loss: 1.2484\n",
            "Epoch 20: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7175 - loss: 1.2479 - val_accuracy: 0.7400 - val_loss: 1.1526\n",
            "Epoch 21/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7442 - loss: 1.1598\n",
            "Epoch 21: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7395 - loss: 1.1611 - val_accuracy: 0.6200 - val_loss: 1.1580\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7160 - loss: 1.1152\n",
            "Epoch 22: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7160 - loss: 1.1145 - val_accuracy: 0.8500 - val_loss: 0.9995\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7146 - loss: 1.0630\n",
            "Epoch 23: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7146 - loss: 1.0626 - val_accuracy: 0.8300 - val_loss: 0.9463\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7402 - loss: 0.9792\n",
            "Epoch 24: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7397 - loss: 0.9794 - val_accuracy: 0.7900 - val_loss: 0.9075\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7285 - loss: 0.9512\n",
            "Epoch 25: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7285 - loss: 0.9512 - val_accuracy: 0.8000 - val_loss: 0.8361\n",
            "Epoch 26/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7203 - loss: 0.9136\n",
            "Epoch 26: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7203 - loss: 0.9136 - val_accuracy: 0.7600 - val_loss: 0.8425\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7196 - loss: 0.8938\n",
            "Epoch 27: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7197 - loss: 0.8935 - val_accuracy: 0.7700 - val_loss: 0.8200\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.8606\n",
            "Epoch 28: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7332 - loss: 0.8603 - val_accuracy: 0.7800 - val_loss: 0.7824\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7335 - loss: 0.8250\n",
            "Epoch 29: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.8250 - val_accuracy: 0.7900 - val_loss: 0.7624\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7353 - loss: 0.8131\n",
            "Epoch 30: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7355 - loss: 0.8127 - val_accuracy: 0.8100 - val_loss: 0.7225\n",
            "Epoch 31/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7459 - loss: 0.7619\n",
            "Epoch 31: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7453 - loss: 0.7636 - val_accuracy: 0.6300 - val_loss: 0.8295\n",
            "Epoch 32/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7361 - loss: 0.7741\n",
            "Epoch 32: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7357 - loss: 0.7730 - val_accuracy: 0.8100 - val_loss: 0.6766\n",
            "Epoch 33/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7442 - loss: 0.7405\n",
            "Epoch 33: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7439 - loss: 0.7401 - val_accuracy: 0.7800 - val_loss: 0.7103\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7369 - loss: 0.7475\n",
            "Epoch 34: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7374 - loss: 0.7469 - val_accuracy: 0.7300 - val_loss: 0.7228\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7592 - loss: 0.7120\n",
            "Epoch 35: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7590 - loss: 0.7123 - val_accuracy: 0.7600 - val_loss: 0.7054\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7438 - loss: 0.7216\n",
            "Epoch 36: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7436 - loss: 0.7216 - val_accuracy: 0.8100 - val_loss: 0.6548\n",
            "Epoch 37/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7455 - loss: 0.7080\n",
            "Epoch 37: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7454 - loss: 0.7080 - val_accuracy: 0.8500 - val_loss: 0.6515\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7446 - loss: 0.6910\n",
            "Epoch 38: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7445 - loss: 0.6913 - val_accuracy: 0.7100 - val_loss: 0.7037\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7557 - loss: 0.6787\n",
            "Epoch 39: val_accuracy did not improve from 0.85000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7554 - loss: 0.6789 - val_accuracy: 0.7000 - val_loss: 0.7101\n",
            "Epoch 39: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "5 / 50\n",
            "\n",
            "--- Fold 6 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5009 - loss: 20.4554\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.5010 - loss: 20.3150 - val_accuracy: 0.4700 - val_loss: 9.2681\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5131 - loss: 8.9002\n",
            "Epoch 2: val_accuracy improved from 0.47000 to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5130 - loss: 8.8714 - val_accuracy: 0.5700 - val_loss: 7.8055\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5084 - loss: 7.5227\n",
            "Epoch 3: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5087 - loss: 7.5120 - val_accuracy: 0.5400 - val_loss: 6.6993\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5542 - loss: 6.4731\n",
            "Epoch 4: val_accuracy improved from 0.57000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5536 - loss: 6.4647 - val_accuracy: 0.6700 - val_loss: 5.8138\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5512 - loss: 5.6293\n",
            "Epoch 5: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5507 - loss: 5.6224 - val_accuracy: 0.5200 - val_loss: 5.0896\n",
            "Epoch 6/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5580 - loss: 4.9408\n",
            "Epoch 6: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5571 - loss: 4.9291 - val_accuracy: 0.6600 - val_loss: 4.4846\n",
            "Epoch 7/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5382 - loss: 4.3701\n",
            "Epoch 7: val_accuracy improved from 0.67000 to 0.69000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5394 - loss: 4.3551 - val_accuracy: 0.6900 - val_loss: 3.9777\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5511 - loss: 3.8716\n",
            "Epoch 8: val_accuracy improved from 0.69000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5517 - loss: 3.8674 - val_accuracy: 0.7000 - val_loss: 3.5317\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5852 - loss: 3.4528\n",
            "Epoch 9: val_accuracy improved from 0.70000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5850 - loss: 3.4494 - val_accuracy: 0.7600 - val_loss: 3.1528\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5937 - loss: 3.0926\n",
            "Epoch 10: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5947 - loss: 3.0892 - val_accuracy: 0.7100 - val_loss: 2.8097\n",
            "Epoch 11/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6459 - loss: 2.7795\n",
            "Epoch 11: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6462 - loss: 2.7694 - val_accuracy: 0.7500 - val_loss: 2.5249\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6590 - loss: 2.5087\n",
            "Epoch 12: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6588 - loss: 2.5068 - val_accuracy: 0.7000 - val_loss: 2.3128\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6747 - loss: 2.2728\n",
            "Epoch 13: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6747 - loss: 2.2711 - val_accuracy: 0.7700 - val_loss: 2.1046\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6900 - loss: 2.0754\n",
            "Epoch 14: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6900 - loss: 2.0736 - val_accuracy: 0.7400 - val_loss: 1.9129\n",
            "Epoch 15/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7133 - loss: 1.8923\n",
            "Epoch 15: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7121 - loss: 1.8911 - val_accuracy: 0.7500 - val_loss: 1.7418\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7104 - loss: 1.7426\n",
            "Epoch 16: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7102 - loss: 1.7415 - val_accuracy: 0.7500 - val_loss: 1.6650\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6966 - loss: 1.6275\n",
            "Epoch 17: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6963 - loss: 1.6266 - val_accuracy: 0.6800 - val_loss: 1.5699\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7066 - loss: 1.5062\n",
            "Epoch 18: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7065 - loss: 1.5053 - val_accuracy: 0.7600 - val_loss: 1.3975\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7070 - loss: 1.4120\n",
            "Epoch 19: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7067 - loss: 1.4106 - val_accuracy: 0.7400 - val_loss: 1.3176\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7204 - loss: 1.2963\n",
            "Epoch 20: val_accuracy improved from 0.77000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 1.2963 - val_accuracy: 0.7900 - val_loss: 1.2352\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7249 - loss: 1.2261\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7248 - loss: 1.2255 - val_accuracy: 0.7500 - val_loss: 1.1479\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7202 - loss: 1.1569\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7200 - loss: 1.1566 - val_accuracy: 0.7000 - val_loss: 1.1353\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7093 - loss: 1.1098\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7097 - loss: 1.1090 - val_accuracy: 0.7300 - val_loss: 1.0496\n",
            "Epoch 24/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7339 - loss: 1.0360\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7331 - loss: 1.0361 - val_accuracy: 0.7400 - val_loss: 1.0233\n",
            "Epoch 25/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7095 - loss: 1.0168\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7114 - loss: 1.0135 - val_accuracy: 0.7700 - val_loss: 0.9393\n",
            "Epoch 26/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7361 - loss: 0.9629\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7357 - loss: 0.9625 - val_accuracy: 0.7400 - val_loss: 0.9005\n",
            "Epoch 27/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7146 - loss: 0.9429\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7154 - loss: 0.9409 - val_accuracy: 0.7400 - val_loss: 0.8818\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7387 - loss: 0.8943\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7383 - loss: 0.8943 - val_accuracy: 0.7500 - val_loss: 0.8875\n",
            "Epoch 29/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7432 - loss: 0.8528\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7430 - loss: 0.8521 - val_accuracy: 0.7900 - val_loss: 0.8402\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7374 - loss: 0.8291\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7371 - loss: 0.8294 - val_accuracy: 0.7800 - val_loss: 0.8065\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7334 - loss: 0.8220\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7338 - loss: 0.8212 - val_accuracy: 0.6600 - val_loss: 0.8378\n",
            "Epoch 32/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7467 - loss: 0.7756\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7464 - loss: 0.7759 - val_accuracy: 0.7700 - val_loss: 0.7595\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7420 - loss: 0.7784\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7422 - loss: 0.7779 - val_accuracy: 0.7100 - val_loss: 0.7569\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7546 - loss: 0.7410\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7543 - loss: 0.7414 - val_accuracy: 0.7500 - val_loss: 0.7362\n",
            "Epoch 35/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7452 - loss: 0.7376\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7451 - loss: 0.7376 - val_accuracy: 0.6700 - val_loss: 0.7811\n",
            "Epoch 36/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7368 - loss: 0.7206\n",
            "Epoch 36: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7369 - loss: 0.7213 - val_accuracy: 0.6400 - val_loss: 0.7776\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7469 - loss: 0.7248\n",
            "Epoch 37: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7468 - loss: 0.7247 - val_accuracy: 0.7600 - val_loss: 0.6783\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7394 - loss: 0.7043\n",
            "Epoch 38: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7393 - loss: 0.7044 - val_accuracy: 0.7700 - val_loss: 0.6818\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7497 - loss: 0.7085\n",
            "Epoch 39: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7493 - loss: 0.7083 - val_accuracy: 0.6800 - val_loss: 0.7207\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7381 - loss: 0.7028\n",
            "Epoch 40: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7382 - loss: 0.7024 - val_accuracy: 0.7300 - val_loss: 0.6885\n",
            "Epoch 40: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
            "6 / 50\n",
            "\n",
            "--- Fold 7 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4887 - loss: 17.4437\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.4890 - loss: 17.3450 - val_accuracy: 0.4900 - val_loss: 9.3456\n",
            "Epoch 2/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5293 - loss: 8.9352\n",
            "Epoch 2: val_accuracy did not improve from 0.49000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5293 - loss: 8.9278 - val_accuracy: 0.4800 - val_loss: 7.7890\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5188 - loss: 7.4773\n",
            "Epoch 3: val_accuracy did not improve from 0.49000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5190 - loss: 7.4655 - val_accuracy: 0.4800 - val_loss: 6.5674\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5288 - loss: 6.3189\n",
            "Epoch 4: val_accuracy did not improve from 0.49000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5278 - loss: 6.3048 - val_accuracy: 0.4800 - val_loss: 5.5866\n",
            "Epoch 5/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5308 - loss: 5.3978\n",
            "Epoch 5: val_accuracy did not improve from 0.49000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5304 - loss: 5.3745 - val_accuracy: 0.4800 - val_loss: 4.7934\n",
            "Epoch 6/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5347 - loss: 4.6346\n",
            "Epoch 6: val_accuracy improved from 0.49000 to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5351 - loss: 4.6186 - val_accuracy: 0.5300 - val_loss: 4.1413\n",
            "Epoch 7/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5481 - loss: 4.0124\n",
            "Epoch 7: val_accuracy improved from 0.53000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5489 - loss: 3.9993 - val_accuracy: 0.6000 - val_loss: 3.6026\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5420 - loss: 3.4939\n",
            "Epoch 8: val_accuracy improved from 0.60000 to 0.63000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5429 - loss: 3.4894 - val_accuracy: 0.6300 - val_loss: 3.1248\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6281 - loss: 3.0515\n",
            "Epoch 9: val_accuracy improved from 0.63000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6279 - loss: 3.0479 - val_accuracy: 0.7400 - val_loss: 2.7039\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6509 - loss: 2.6775\n",
            "Epoch 10: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6509 - loss: 2.6749 - val_accuracy: 0.7300 - val_loss: 2.4342\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6981 - loss: 2.3692\n",
            "Epoch 11: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6976 - loss: 2.3668 - val_accuracy: 0.7000 - val_loss: 2.1625\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7269 - loss: 2.0967\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7260 - loss: 2.0953 - val_accuracy: 0.7000 - val_loss: 1.9230\n",
            "Epoch 13/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6922 - loss: 1.9122\n",
            "Epoch 13: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6923 - loss: 1.9113 - val_accuracy: 0.7100 - val_loss: 1.7450\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7213 - loss: 1.7252\n",
            "Epoch 14: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7212 - loss: 1.7237 - val_accuracy: 0.7000 - val_loss: 1.5916\n",
            "Epoch 15/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7088 - loss: 1.5727\n",
            "Epoch 15: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7070 - loss: 1.5705 - val_accuracy: 0.6900 - val_loss: 1.4924\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7207 - loss: 1.4489\n",
            "Epoch 16: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7206 - loss: 1.4478 - val_accuracy: 0.7100 - val_loss: 1.3837\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7231 - loss: 1.3267\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7229 - loss: 1.3260 - val_accuracy: 0.7400 - val_loss: 1.2409\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7358 - loss: 1.2276\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7357 - loss: 1.2268 - val_accuracy: 0.7300 - val_loss: 1.1645\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7392 - loss: 1.1383\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7390 - loss: 1.1377 - val_accuracy: 0.7300 - val_loss: 1.0991\n",
            "Epoch 20/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7134 - loss: 1.0956\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7121 - loss: 1.0949 - val_accuracy: 0.6600 - val_loss: 1.0944\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7250 - loss: 1.0350\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7251 - loss: 1.0342 - val_accuracy: 0.6800 - val_loss: 1.0193\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7311 - loss: 0.9799\n",
            "Epoch 22: val_accuracy improved from 0.74000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7314 - loss: 0.9792 - val_accuracy: 0.7600 - val_loss: 0.9183\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7215 - loss: 0.9287\n",
            "Epoch 23: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7212 - loss: 0.9285 - val_accuracy: 0.6800 - val_loss: 0.9190\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7138 - loss: 0.8995\n",
            "Epoch 24: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7141 - loss: 0.8988 - val_accuracy: 0.7300 - val_loss: 0.8516\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7293 - loss: 0.8596\n",
            "Epoch 25: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7296 - loss: 0.8590 - val_accuracy: 0.7400 - val_loss: 0.8415\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7395 - loss: 0.8131\n",
            "Epoch 26: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7397 - loss: 0.8124 - val_accuracy: 0.6500 - val_loss: 0.8829\n",
            "Epoch 27/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7310 - loss: 0.7817\n",
            "Epoch 27: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7313 - loss: 0.7817 - val_accuracy: 0.7400 - val_loss: 0.7962\n",
            "Epoch 28/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7376 - loss: 0.7791\n",
            "Epoch 28: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7369 - loss: 0.7797 - val_accuracy: 0.7500 - val_loss: 0.7568\n",
            "Epoch 29/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7401 - loss: 0.7507\n",
            "Epoch 29: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7402 - loss: 0.7512 - val_accuracy: 0.7200 - val_loss: 0.7578\n",
            "Epoch 30/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7364 - loss: 0.7471\n",
            "Epoch 30: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7374 - loss: 0.7451 - val_accuracy: 0.7200 - val_loss: 0.7550\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7499 - loss: 0.7066\n",
            "Epoch 31: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7495 - loss: 0.7068 - val_accuracy: 0.7700 - val_loss: 0.7256\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7477 - loss: 0.6982\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7476 - loss: 0.6985 - val_accuracy: 0.5700 - val_loss: 0.8541\n",
            "Epoch 33/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7485 - loss: 0.6960\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7485 - loss: 0.6960 - val_accuracy: 0.6900 - val_loss: 0.7449\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7500 - loss: 0.6906\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7501 - loss: 0.6903 - val_accuracy: 0.6900 - val_loss: 0.7402\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7467 - loss: 0.6786\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7470 - loss: 0.6783 - val_accuracy: 0.6200 - val_loss: 0.8313\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - loss: 0.6803\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7494 - loss: 0.6801 - val_accuracy: 0.6600 - val_loss: 0.7760\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7719 - loss: 0.6468\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7717 - loss: 0.6470 - val_accuracy: 0.6600 - val_loss: 0.7403\n",
            "Epoch 38/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7742 - loss: 0.6408\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7740 - loss: 0.6411 - val_accuracy: 0.7300 - val_loss: 0.7103\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7245 - loss: 0.6948\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7253 - loss: 0.6939 - val_accuracy: 0.7400 - val_loss: 0.7033\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7732 - loss: 0.6318\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7728 - loss: 0.6326 - val_accuracy: 0.6900 - val_loss: 0.7577\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7624 - loss: 0.6511\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7625 - loss: 0.6507 - val_accuracy: 0.6600 - val_loss: 0.7846\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7709 - loss: 0.6300\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7709 - loss: 0.6303 - val_accuracy: 0.7400 - val_loss: 0.6794\n",
            "Epoch 43/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7868 - loss: 0.6228\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7860 - loss: 0.6235 - val_accuracy: 0.6600 - val_loss: 0.7563\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7671 - loss: 0.6359\n",
            "Epoch 44: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7673 - loss: 0.6356 - val_accuracy: 0.7400 - val_loss: 0.7009\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.6274\n",
            "Epoch 45: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7815 - loss: 0.6280 - val_accuracy: 0.7200 - val_loss: 0.7158\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7744 - loss: 0.6251\n",
            "Epoch 46: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7743 - loss: 0.6254 - val_accuracy: 0.7000 - val_loss: 0.7231\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7870 - loss: 0.6090\n",
            "Epoch 47: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7868 - loss: 0.6094 - val_accuracy: 0.5800 - val_loss: 0.8615\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7764 - loss: 0.6374\n",
            "Epoch 48: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7764 - loss: 0.6373 - val_accuracy: 0.7300 - val_loss: 0.7246\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7812 - loss: 0.6150\n",
            "Epoch 49: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7810 - loss: 0.6155 - val_accuracy: 0.7300 - val_loss: 0.7177\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7780 - loss: 0.6258\n",
            "Epoch 50: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7777 - loss: 0.6261 - val_accuracy: 0.7400 - val_loss: 0.6944\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
            "7 / 50\n",
            "\n",
            "--- Fold 8 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5053 - loss: 15.2712\n",
            "Epoch 1: val_accuracy improved from -inf to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 0.5053 - loss: 15.2018 - val_accuracy: 0.5400 - val_loss: 9.2100\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5043 - loss: 8.8306\n",
            "Epoch 2: val_accuracy improved from 0.54000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5053 - loss: 8.7915 - val_accuracy: 0.5500 - val_loss: 7.6296\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5036 - loss: 7.3231\n",
            "Epoch 3: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5037 - loss: 7.3113 - val_accuracy: 0.4700 - val_loss: 6.4100\n",
            "Epoch 4/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5054 - loss: 6.1575\n",
            "Epoch 4: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5058 - loss: 6.1529 - val_accuracy: 0.5500 - val_loss: 5.4371\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5058 - loss: 5.2393\n",
            "Epoch 5: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5061 - loss: 5.2318 - val_accuracy: 0.4600 - val_loss: 4.6535\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5315 - loss: 4.4897\n",
            "Epoch 6: val_accuracy improved from 0.55000 to 0.66000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5320 - loss: 4.4835 - val_accuracy: 0.6600 - val_loss: 4.0025\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5446 - loss: 3.8773\n",
            "Epoch 7: val_accuracy improved from 0.66000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5441 - loss: 3.8723 - val_accuracy: 0.6700 - val_loss: 3.4792\n",
            "Epoch 8/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5799 - loss: 3.3710\n",
            "Epoch 8: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5804 - loss: 3.3644 - val_accuracy: 0.6400 - val_loss: 3.0304\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6335 - loss: 2.9275\n",
            "Epoch 9: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6332 - loss: 2.9241 - val_accuracy: 0.4900 - val_loss: 2.7171\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 2.6031\n",
            "Epoch 10: val_accuracy improved from 0.67000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6160 - loss: 2.5999 - val_accuracy: 0.7200 - val_loss: 2.3179\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6782 - loss: 2.2680\n",
            "Epoch 11: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6776 - loss: 2.2663 - val_accuracy: 0.4500 - val_loss: 2.1969\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5841 - loss: 2.1121\n",
            "Epoch 12: val_accuracy improved from 0.72000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5864 - loss: 2.1087 - val_accuracy: 0.7300 - val_loss: 1.8344\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6943 - loss: 1.8184\n",
            "Epoch 13: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6947 - loss: 1.8166 - val_accuracy: 0.7100 - val_loss: 1.6982\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7200 - loss: 1.6291\n",
            "Epoch 14: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7197 - loss: 1.6271 - val_accuracy: 0.6600 - val_loss: 1.5521\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7253 - loss: 1.4847\n",
            "Epoch 15: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7253 - loss: 1.4835 - val_accuracy: 0.7000 - val_loss: 1.4194\n",
            "Epoch 16/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7171 - loss: 1.3765\n",
            "Epoch 16: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7170 - loss: 1.3735 - val_accuracy: 0.7200 - val_loss: 1.2973\n",
            "Epoch 17/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7209 - loss: 1.2620\n",
            "Epoch 17: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7211 - loss: 1.2593 - val_accuracy: 0.7400 - val_loss: 1.1917\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7445 - loss: 1.1574\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7441 - loss: 1.1571 - val_accuracy: 0.7100 - val_loss: 1.1415\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7390 - loss: 1.0843\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7393 - loss: 1.0835 - val_accuracy: 0.7000 - val_loss: 1.0682\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7617 - loss: 1.0115\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7611 - loss: 1.0113 - val_accuracy: 0.6700 - val_loss: 1.0423\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7382 - loss: 0.9620\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7376 - loss: 0.9619 - val_accuracy: 0.7200 - val_loss: 0.9618\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7443 - loss: 0.9140\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7441 - loss: 0.9139 - val_accuracy: 0.7200 - val_loss: 0.9247\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7478 - loss: 0.8679\n",
            "Epoch 23: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7476 - loss: 0.8676 - val_accuracy: 0.7000 - val_loss: 0.8988\n",
            "Epoch 24/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7411 - loss: 0.8420\n",
            "Epoch 24: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 0.8418 - val_accuracy: 0.6500 - val_loss: 0.9122\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7467 - loss: 0.8006\n",
            "Epoch 25: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7468 - loss: 0.8003 - val_accuracy: 0.7100 - val_loss: 0.8205\n",
            "Epoch 26/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7784 - loss: 0.7492\n",
            "Epoch 26: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7768 - loss: 0.7507 - val_accuracy: 0.7100 - val_loss: 0.8238\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7507 - loss: 0.7596\n",
            "Epoch 27: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7507 - loss: 0.7591 - val_accuracy: 0.7200 - val_loss: 0.7899\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7497 - loss: 0.7380\n",
            "Epoch 28: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7491 - loss: 0.7386 - val_accuracy: 0.6900 - val_loss: 0.7764\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7413 - loss: 0.7300\n",
            "Epoch 29: val_accuracy improved from 0.74000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7418 - loss: 0.7297 - val_accuracy: 0.7700 - val_loss: 0.7359\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7654 - loss: 0.6956\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7651 - loss: 0.6958 - val_accuracy: 0.7100 - val_loss: 0.7735\n",
            "Epoch 31/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7430 - loss: 0.6994\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7431 - loss: 0.6993 - val_accuracy: 0.7300 - val_loss: 0.7372\n",
            "Epoch 32/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7580 - loss: 0.6671\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7580 - loss: 0.6672 - val_accuracy: 0.6900 - val_loss: 0.7968\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7561 - loss: 0.6785\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7562 - loss: 0.6785 - val_accuracy: 0.6700 - val_loss: 0.7899\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7674 - loss: 0.6653\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7672 - loss: 0.6654 - val_accuracy: 0.7200 - val_loss: 0.7183\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7601 - loss: 0.6590\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7600 - loss: 0.6588 - val_accuracy: 0.7200 - val_loss: 0.7267\n",
            "Epoch 36/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7818 - loss: 0.6283\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7802 - loss: 0.6304 - val_accuracy: 0.7100 - val_loss: 0.7030\n",
            "Epoch 37/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7790 - loss: 0.6405\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7772 - loss: 0.6411 - val_accuracy: 0.7300 - val_loss: 0.7057\n",
            "Epoch 38/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7628 - loss: 0.6559\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7629 - loss: 0.6550 - val_accuracy: 0.7000 - val_loss: 0.7372\n",
            "Epoch 39/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7695 - loss: 0.6358\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7694 - loss: 0.6361 - val_accuracy: 0.7500 - val_loss: 0.6969\n",
            "Epoch 40/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7620 - loss: 0.6436\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7613 - loss: 0.6444 - val_accuracy: 0.7500 - val_loss: 0.6964\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7843 - loss: 0.6246\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7840 - loss: 0.6248 - val_accuracy: 0.6400 - val_loss: 0.7967\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7798 - loss: 0.6305\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7797 - loss: 0.6306 - val_accuracy: 0.7700 - val_loss: 0.7053\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7524 - loss: 0.6492\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7528 - loss: 0.6489 - val_accuracy: 0.7300 - val_loss: 0.6907\n",
            "Epoch 44/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7739 - loss: 0.6390\n",
            "Epoch 44: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7737 - loss: 0.6392 - val_accuracy: 0.7200 - val_loss: 0.7068\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7736 - loss: 0.6367\n",
            "Epoch 45: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7734 - loss: 0.6364 - val_accuracy: 0.7200 - val_loss: 0.7102\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7948 - loss: 0.6187\n",
            "Epoch 46: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7944 - loss: 0.6189 - val_accuracy: 0.6900 - val_loss: 0.7151\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7722 - loss: 0.6343\n",
            "Epoch 47: val_accuracy improved from 0.77000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7723 - loss: 0.6343 - val_accuracy: 0.7800 - val_loss: 0.6534\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7956 - loss: 0.6003\n",
            "Epoch 48: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7952 - loss: 0.6011 - val_accuracy: 0.6700 - val_loss: 0.7477\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7787 - loss: 0.6120\n",
            "Epoch 49: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7785 - loss: 0.6128 - val_accuracy: 0.7300 - val_loss: 0.6926\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7789 - loss: 0.6252\n",
            "Epoch 50: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7791 - loss: 0.6249 - val_accuracy: 0.7300 - val_loss: 0.7270\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
            "8 / 50\n",
            "\n",
            "--- Fold 9 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5051 - loss: 18.9115\n",
            "Epoch 1: val_accuracy improved from -inf to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - accuracy: 0.5051 - loss: 18.7938 - val_accuracy: 0.5700 - val_loss: 9.3204\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5286 - loss: 8.9578\n",
            "Epoch 2: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5274 - loss: 8.9216 - val_accuracy: 0.5500 - val_loss: 7.8480\n",
            "Epoch 3/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5295 - loss: 7.5729\n",
            "Epoch 3: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5291 - loss: 7.5450 - val_accuracy: 0.5300 - val_loss: 6.7064\n",
            "Epoch 4/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5173 - loss: 6.4982\n",
            "Epoch 4: val_accuracy improved from 0.57000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5194 - loss: 6.4660 - val_accuracy: 0.6700 - val_loss: 5.7824\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5374 - loss: 5.5939\n",
            "Epoch 5: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5375 - loss: 5.5866 - val_accuracy: 0.6700 - val_loss: 5.0201\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5457 - loss: 4.8702\n",
            "Epoch 6: val_accuracy improved from 0.67000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5459 - loss: 4.8643 - val_accuracy: 0.7000 - val_loss: 4.3963\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5719 - loss: 4.2659\n",
            "Epoch 7: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5722 - loss: 4.2581 - val_accuracy: 0.6500 - val_loss: 3.8499\n",
            "Epoch 8/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5873 - loss: 3.7455\n",
            "Epoch 8: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5874 - loss: 3.7434 - val_accuracy: 0.7000 - val_loss: 3.3959\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6260 - loss: 3.3113\n",
            "Epoch 9: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6263 - loss: 3.3076 - val_accuracy: 0.7000 - val_loss: 2.9704\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6513 - loss: 2.9411\n",
            "Epoch 10: val_accuracy improved from 0.70000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6511 - loss: 2.9382 - val_accuracy: 0.7200 - val_loss: 2.6541\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6673 - loss: 2.6235\n",
            "Epoch 11: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6680 - loss: 2.6203 - val_accuracy: 0.6700 - val_loss: 2.3739\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6969 - loss: 2.3420\n",
            "Epoch 12: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6973 - loss: 2.3395 - val_accuracy: 0.6700 - val_loss: 2.1712\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7053 - loss: 2.1153\n",
            "Epoch 13: val_accuracy improved from 0.72000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7058 - loss: 2.1130 - val_accuracy: 0.7500 - val_loss: 1.9627\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7106 - loss: 1.9278\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7108 - loss: 1.9257 - val_accuracy: 0.6300 - val_loss: 1.8693\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7109 - loss: 1.7549\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7113 - loss: 1.7531 - val_accuracy: 0.6900 - val_loss: 1.6321\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7299 - loss: 1.6098\n",
            "Epoch 16: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7300 - loss: 1.6084 - val_accuracy: 0.6800 - val_loss: 1.5269\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7203 - loss: 1.4839\n",
            "Epoch 17: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7206 - loss: 1.4829 - val_accuracy: 0.7100 - val_loss: 1.3975\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7274 - loss: 1.3632\n",
            "Epoch 18: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7274 - loss: 1.3625 - val_accuracy: 0.7500 - val_loss: 1.3163\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7496 - loss: 1.2692\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7492 - loss: 1.2689 - val_accuracy: 0.7300 - val_loss: 1.2145\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7629 - loss: 1.1732\n",
            "Epoch 20: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7626 - loss: 1.1728 - val_accuracy: 0.7000 - val_loss: 1.1566\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7575 - loss: 1.0984\n",
            "Epoch 21: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7570 - loss: 1.0981 - val_accuracy: 0.6800 - val_loss: 1.1346\n",
            "Epoch 22/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7524 - loss: 1.0520\n",
            "Epoch 22: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7532 - loss: 1.0497 - val_accuracy: 0.6800 - val_loss: 1.0600\n",
            "Epoch 23/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7474 - loss: 0.9880\n",
            "Epoch 23: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7471 - loss: 0.9877 - val_accuracy: 0.7000 - val_loss: 1.0012\n",
            "Epoch 24/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7505 - loss: 0.9532\n",
            "Epoch 24: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7504 - loss: 0.9519 - val_accuracy: 0.6900 - val_loss: 0.9797\n",
            "Epoch 25/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7686 - loss: 0.8968\n",
            "Epoch 25: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7682 - loss: 0.8959 - val_accuracy: 0.6900 - val_loss: 0.9593\n",
            "Epoch 26/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7633 - loss: 0.8543\n",
            "Epoch 26: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7626 - loss: 0.8547 - val_accuracy: 0.6900 - val_loss: 0.9222\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7636 - loss: 0.8425\n",
            "Epoch 27: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7635 - loss: 0.8422 - val_accuracy: 0.7100 - val_loss: 0.8557\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7648 - loss: 0.8058\n",
            "Epoch 28: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7647 - loss: 0.8055 - val_accuracy: 0.7200 - val_loss: 0.8332\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7693 - loss: 0.7812\n",
            "Epoch 29: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7691 - loss: 0.7810 - val_accuracy: 0.6600 - val_loss: 0.8452\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7757 - loss: 0.7428\n",
            "Epoch 30: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7749 - loss: 0.7437 - val_accuracy: 0.7100 - val_loss: 0.7948\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7719 - loss: 0.7258\n",
            "Epoch 31: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7717 - loss: 0.7259 - val_accuracy: 0.6900 - val_loss: 0.7936\n",
            "Epoch 32/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7793 - loss: 0.7092\n",
            "Epoch 32: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7792 - loss: 0.7094 - val_accuracy: 0.7100 - val_loss: 0.8132\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7811 - loss: 0.6989\n",
            "Epoch 33: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7810 - loss: 0.6989 - val_accuracy: 0.6600 - val_loss: 0.8022\n",
            "Epoch 33: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "9 / 50\n",
            "\n",
            "--- Fold 10 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4918 - loss: 15.6187\n",
            "Epoch 1: val_accuracy improved from -inf to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.4917 - loss: 15.5386 - val_accuracy: 0.6000 - val_loss: 8.6882\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4930 - loss: 8.2611\n",
            "Epoch 2: val_accuracy improved from 0.60000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.4934 - loss: 8.2094 - val_accuracy: 0.6100 - val_loss: 6.9567\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5137 - loss: 6.6369\n",
            "Epoch 3: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5139 - loss: 6.6250 - val_accuracy: 0.6000 - val_loss: 5.7260\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5087 - loss: 5.4851\n",
            "Epoch 4: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5088 - loss: 5.4761 - val_accuracy: 0.5800 - val_loss: 4.7906\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5230 - loss: 4.6042\n",
            "Epoch 5: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5226 - loss: 4.5972 - val_accuracy: 0.4800 - val_loss: 4.0606\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5169 - loss: 3.9121\n",
            "Epoch 6: val_accuracy improved from 0.61000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5170 - loss: 3.9065 - val_accuracy: 0.6400 - val_loss: 3.4768\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5573 - loss: 3.3592\n",
            "Epoch 7: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5564 - loss: 3.3524 - val_accuracy: 0.5400 - val_loss: 3.0074\n",
            "Epoch 8/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5367 - loss: 2.9196\n",
            "Epoch 8: val_accuracy improved from 0.64000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5364 - loss: 2.9083 - val_accuracy: 0.7500 - val_loss: 2.6192\n",
            "Epoch 9/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5699 - loss: 2.5511\n",
            "Epoch 9: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5706 - loss: 2.5400 - val_accuracy: 0.7500 - val_loss: 2.2616\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 2.2433\n",
            "Epoch 10: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5977 - loss: 2.2410 - val_accuracy: 0.5900 - val_loss: 2.0689\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6234 - loss: 2.0042\n",
            "Epoch 11: val_accuracy improved from 0.75000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6233 - loss: 2.0017 - val_accuracy: 0.8000 - val_loss: 1.7527\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6107 - loss: 1.7856\n",
            "Epoch 12: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6114 - loss: 1.7837 - val_accuracy: 0.6800 - val_loss: 1.6138\n",
            "Epoch 13/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6699 - loss: 1.5974\n",
            "Epoch 13: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6700 - loss: 1.5953 - val_accuracy: 0.7400 - val_loss: 1.4417\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6634 - loss: 1.4681\n",
            "Epoch 14: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6640 - loss: 1.4664 - val_accuracy: 0.7900 - val_loss: 1.2961\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6751 - loss: 1.3347\n",
            "Epoch 15: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6754 - loss: 1.3332 - val_accuracy: 0.7400 - val_loss: 1.2296\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7060 - loss: 1.2111\n",
            "Epoch 16: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7057 - loss: 1.2106 - val_accuracy: 0.7800 - val_loss: 1.1070\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7043 - loss: 1.1229\n",
            "Epoch 17: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7041 - loss: 1.1228 - val_accuracy: 0.7100 - val_loss: 1.0701\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7244 - loss: 1.0475\n",
            "Epoch 18: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7240 - loss: 1.0473 - val_accuracy: 0.7700 - val_loss: 0.9710\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7034 - loss: 1.0083\n",
            "Epoch 19: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7036 - loss: 1.0076 - val_accuracy: 0.7900 - val_loss: 0.9060\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7197 - loss: 0.9462\n",
            "Epoch 20: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 0.9454 - val_accuracy: 0.7800 - val_loss: 0.8493\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6907 - loss: 0.9282\n",
            "Epoch 21: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6911 - loss: 0.9272 - val_accuracy: 0.7600 - val_loss: 0.8088\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7097 - loss: 0.8709\n",
            "Epoch 22: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7100 - loss: 0.8702 - val_accuracy: 0.7500 - val_loss: 0.7925\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7256 - loss: 0.8227\n",
            "Epoch 23: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7258 - loss: 0.8222 - val_accuracy: 0.7800 - val_loss: 0.7482\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7132 - loss: 0.8041\n",
            "Epoch 24: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7135 - loss: 0.8038 - val_accuracy: 0.7800 - val_loss: 0.7791\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7182 - loss: 0.7875\n",
            "Epoch 25: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7183 - loss: 0.7873 - val_accuracy: 0.7900 - val_loss: 0.7449\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7253 - loss: 0.7641\n",
            "Epoch 26: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7252 - loss: 0.7640 - val_accuracy: 0.7100 - val_loss: 0.7434\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7301 - loss: 0.7426\n",
            "Epoch 27: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7302 - loss: 0.7424 - val_accuracy: 0.7300 - val_loss: 0.6982\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7240 - loss: 0.7423\n",
            "Epoch 28: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7243 - loss: 0.7418 - val_accuracy: 0.7100 - val_loss: 0.7329\n",
            "Epoch 29/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7453 - loss: 0.7076\n",
            "Epoch 29: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7451 - loss: 0.7078 - val_accuracy: 0.7500 - val_loss: 0.6809\n",
            "Epoch 30/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7517 - loss: 0.6910\n",
            "Epoch 30: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7514 - loss: 0.6913 - val_accuracy: 0.7600 - val_loss: 0.6691\n",
            "Epoch 31/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7330 - loss: 0.6942\n",
            "Epoch 31: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7331 - loss: 0.6941 - val_accuracy: 0.7100 - val_loss: 0.7154\n",
            "Epoch 31: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "10 / 50\n",
            "\n",
            "--- Fold 11 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5055 - loss: 19.4327\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 144ms/step - accuracy: 0.5056 - loss: 19.3097 - val_accuracy: 0.4600 - val_loss: 9.5886\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5062 - loss: 9.2463\n",
            "Epoch 2: val_accuracy improved from 0.46000 to 0.52000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5053 - loss: 9.2191 - val_accuracy: 0.5200 - val_loss: 8.1912\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4976 - loss: 7.9035\n",
            "Epoch 3: val_accuracy improved from 0.52000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4977 - loss: 7.8926 - val_accuracy: 0.6100 - val_loss: 7.0555\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5212 - loss: 6.8192\n",
            "Epoch 4: val_accuracy improved from 0.61000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5214 - loss: 6.8102 - val_accuracy: 0.6200 - val_loss: 6.1137\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5116 - loss: 5.9221\n",
            "Epoch 5: val_accuracy improved from 0.62000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5122 - loss: 5.9146 - val_accuracy: 0.6500 - val_loss: 5.3280\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5585 - loss: 5.1664\n",
            "Epoch 6: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5586 - loss: 5.1602 - val_accuracy: 0.6100 - val_loss: 4.6549\n",
            "Epoch 7/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5495 - loss: 4.5363\n",
            "Epoch 7: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5498 - loss: 4.5336 - val_accuracy: 0.6400 - val_loss: 4.1083\n",
            "Epoch 8/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5886 - loss: 4.0114\n",
            "Epoch 8: val_accuracy improved from 0.65000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5893 - loss: 3.9931 - val_accuracy: 0.7200 - val_loss: 3.6091\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6193 - loss: 3.5365\n",
            "Epoch 9: val_accuracy improved from 0.72000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6197 - loss: 3.5328 - val_accuracy: 0.7500 - val_loss: 3.2080\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6553 - loss: 3.1503\n",
            "Epoch 10: val_accuracy improved from 0.75000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6551 - loss: 3.1472 - val_accuracy: 0.7900 - val_loss: 2.8428\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6587 - loss: 2.8328\n",
            "Epoch 11: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6588 - loss: 2.8297 - val_accuracy: 0.7700 - val_loss: 2.5562\n",
            "Epoch 12/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6422 - loss: 2.5718\n",
            "Epoch 12: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6419 - loss: 2.5669 - val_accuracy: 0.7200 - val_loss: 2.3268\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6814 - loss: 2.2966\n",
            "Epoch 13: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6816 - loss: 2.2944 - val_accuracy: 0.6500 - val_loss: 2.1399\n",
            "Epoch 14/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7040 - loss: 2.0744\n",
            "Epoch 14: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7027 - loss: 2.0711 - val_accuracy: 0.7000 - val_loss: 1.9364\n",
            "Epoch 15/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 1.8952\n",
            "Epoch 15: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7176 - loss: 1.8915 - val_accuracy: 0.7500 - val_loss: 1.7738\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6882 - loss: 1.7563\n",
            "Epoch 16: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6885 - loss: 1.7548 - val_accuracy: 0.6700 - val_loss: 1.6608\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7017 - loss: 1.6234\n",
            "Epoch 17: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7022 - loss: 1.6216 - val_accuracy: 0.7000 - val_loss: 1.5021\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7221 - loss: 1.4838\n",
            "Epoch 18: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7219 - loss: 1.4829 - val_accuracy: 0.6800 - val_loss: 1.4261\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7128 - loss: 1.3792\n",
            "Epoch 19: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7127 - loss: 1.3784 - val_accuracy: 0.7600 - val_loss: 1.3056\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7007 - loss: 1.3088\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7011 - loss: 1.3078 - val_accuracy: 0.7400 - val_loss: 1.2209\n",
            "Epoch 21/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7247 - loss: 1.2104\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7254 - loss: 1.2072 - val_accuracy: 0.7400 - val_loss: 1.1727\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7139 - loss: 1.1397\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7142 - loss: 1.1388 - val_accuracy: 0.7500 - val_loss: 1.0932\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 1.0800\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7316 - loss: 1.0796 - val_accuracy: 0.6700 - val_loss: 1.0860\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7283 - loss: 1.0229\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7279 - loss: 1.0228 - val_accuracy: 0.7300 - val_loss: 0.9900\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7497 - loss: 0.9727\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7492 - loss: 0.9727 - val_accuracy: 0.7100 - val_loss: 0.9730\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7417 - loss: 0.9280\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7413 - loss: 0.9281 - val_accuracy: 0.7300 - val_loss: 0.9274\n",
            "Epoch 27/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7225 - loss: 0.8997\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7235 - loss: 0.8995 - val_accuracy: 0.7400 - val_loss: 0.8729\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7483 - loss: 0.8630\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7481 - loss: 0.8629 - val_accuracy: 0.7400 - val_loss: 0.8751\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7352 - loss: 0.8533\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7351 - loss: 0.8529 - val_accuracy: 0.6200 - val_loss: 0.8874\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7565 - loss: 0.8185\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7558 - loss: 0.8189 - val_accuracy: 0.7400 - val_loss: 0.7965\n",
            "Epoch 30: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "11 / 50\n",
            "\n",
            "--- Fold 12 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.4858 - loss: 20.5098\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 160ms/step - accuracy: 0.4857 - loss: 20.3690 - val_accuracy: 0.5200 - val_loss: 9.3026\n",
            "Epoch 2/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5185 - loss: 8.9356\n",
            "Epoch 2: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5184 - loss: 8.9145 - val_accuracy: 0.4900 - val_loss: 7.8684\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5254 - loss: 7.5877\n",
            "Epoch 3: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5255 - loss: 7.5772 - val_accuracy: 0.4900 - val_loss: 6.7723\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5178 - loss: 6.5502\n",
            "Epoch 4: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5180 - loss: 6.5417 - val_accuracy: 0.4800 - val_loss: 5.8941\n",
            "Epoch 5/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5240 - loss: 5.7328\n",
            "Epoch 5: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5220 - loss: 5.7045 - val_accuracy: 0.4800 - val_loss: 5.1739\n",
            "Epoch 6/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5331 - loss: 5.0389\n",
            "Epoch 6: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5314 - loss: 5.0154 - val_accuracy: 0.4900 - val_loss: 4.5750\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5424 - loss: 4.4469\n",
            "Epoch 7: val_accuracy improved from 0.52000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5419 - loss: 4.4421 - val_accuracy: 0.5400 - val_loss: 4.0701\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5423 - loss: 3.9602\n",
            "Epoch 8: val_accuracy improved from 0.54000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5425 - loss: 3.9562 - val_accuracy: 0.6500 - val_loss: 3.6417\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5582 - loss: 3.5460\n",
            "Epoch 9: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5585 - loss: 3.5425 - val_accuracy: 0.6300 - val_loss: 3.2533\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5530 - loss: 3.2030\n",
            "Epoch 10: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5530 - loss: 3.1998 - val_accuracy: 0.6000 - val_loss: 2.9525\n",
            "Epoch 11/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5920 - loss: 2.8886\n",
            "Epoch 11: val_accuracy improved from 0.65000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5944 - loss: 2.8773 - val_accuracy: 0.7400 - val_loss: 2.6180\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6215 - loss: 2.6143\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6224 - loss: 2.6116 - val_accuracy: 0.7200 - val_loss: 2.3940\n",
            "Epoch 13/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6637 - loss: 2.3571\n",
            "Epoch 13: val_accuracy improved from 0.74000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6637 - loss: 2.3562 - val_accuracy: 0.7600 - val_loss: 2.1864\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7219 - loss: 2.1336\n",
            "Epoch 14: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7211 - loss: 2.1325 - val_accuracy: 0.7600 - val_loss: 2.0329\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7074 - loss: 1.9778\n",
            "Epoch 15: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7073 - loss: 1.9762 - val_accuracy: 0.7400 - val_loss: 1.8540\n",
            "Epoch 16/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7093 - loss: 1.8224\n",
            "Epoch 16: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7098 - loss: 1.8196 - val_accuracy: 0.7700 - val_loss: 1.7093\n",
            "Epoch 17/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7271 - loss: 1.6759\n",
            "Epoch 17: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7270 - loss: 1.6723 - val_accuracy: 0.6200 - val_loss: 1.6490\n",
            "Epoch 18/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7275 - loss: 1.5689\n",
            "Epoch 18: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7280 - loss: 1.5642 - val_accuracy: 0.7300 - val_loss: 1.4964\n",
            "Epoch 19/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 1.4426\n",
            "Epoch 19: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7352 - loss: 1.4417 - val_accuracy: 0.7500 - val_loss: 1.3974\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7290 - loss: 1.3617\n",
            "Epoch 20: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 1.3608 - val_accuracy: 0.7400 - val_loss: 1.3254\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 1.2929\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7345 - loss: 1.2922 - val_accuracy: 0.6500 - val_loss: 1.2848\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7239 - loss: 1.2173\n",
            "Epoch 22: val_accuracy improved from 0.77000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7244 - loss: 1.2162 - val_accuracy: 0.7900 - val_loss: 1.1727\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 1.1424\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7273 - loss: 1.1414 - val_accuracy: 0.7500 - val_loss: 1.1274\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7405 - loss: 1.0845\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7403 - loss: 1.0841 - val_accuracy: 0.7100 - val_loss: 1.0718\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7520 - loss: 1.0316\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7517 - loss: 1.0312 - val_accuracy: 0.7100 - val_loss: 1.0437\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7419 - loss: 0.9939\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7417 - loss: 0.9934 - val_accuracy: 0.7000 - val_loss: 1.0341\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.9671\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7295 - loss: 0.9661 - val_accuracy: 0.7300 - val_loss: 0.9724\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7381 - loss: 0.9177\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7382 - loss: 0.9173 - val_accuracy: 0.7200 - val_loss: 0.9378\n",
            "Epoch 29/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.8648\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7590 - loss: 0.8652 - val_accuracy: 0.7300 - val_loss: 0.9114\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7538 - loss: 0.8402\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7537 - loss: 0.8403 - val_accuracy: 0.7500 - val_loss: 0.8670\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7599 - loss: 0.8181\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7596 - loss: 0.8185 - val_accuracy: 0.6300 - val_loss: 0.9260\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7449 - loss: 0.8210\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7452 - loss: 0.8206 - val_accuracy: 0.7600 - val_loss: 0.8368\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7618 - loss: 0.7764\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7613 - loss: 0.7766 - val_accuracy: 0.7400 - val_loss: 0.8230\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7573 - loss: 0.7578\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7573 - loss: 0.7578 - val_accuracy: 0.7800 - val_loss: 0.7779\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7672 - loss: 0.7377\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7670 - loss: 0.7377 - val_accuracy: 0.6100 - val_loss: 0.8480\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.7244\n",
            "Epoch 36: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7658 - loss: 0.7244 - val_accuracy: 0.7400 - val_loss: 0.7766\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7516 - loss: 0.7179\n",
            "Epoch 37: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7519 - loss: 0.7177 - val_accuracy: 0.6900 - val_loss: 0.7956\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7745 - loss: 0.7036\n",
            "Epoch 38: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7738 - loss: 0.7040 - val_accuracy: 0.7000 - val_loss: 0.7767\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7714 - loss: 0.6862\n",
            "Epoch 39: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7710 - loss: 0.6867 - val_accuracy: 0.6600 - val_loss: 0.7830\n",
            "Epoch 40/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7762 - loss: 0.6854\n",
            "Epoch 40: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7747 - loss: 0.6859 - val_accuracy: 0.6800 - val_loss: 0.7735\n",
            "Epoch 41/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7891 - loss: 0.6570\n",
            "Epoch 41: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7866 - loss: 0.6591 - val_accuracy: 0.5600 - val_loss: 0.8695\n",
            "Epoch 42/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7465 - loss: 0.7008\n",
            "Epoch 42: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7478 - loss: 0.6996 - val_accuracy: 0.5400 - val_loss: 0.8571\n",
            "Epoch 42: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "12 / 50\n",
            "\n",
            "--- Fold 13 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5091 - loss: 16.4848\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 0.5090 - loss: 16.3994 - val_accuracy: 0.5300 - val_loss: 9.2615\n",
            "Epoch 2/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5016 - loss: 8.8335\n",
            "Epoch 2: val_accuracy improved from 0.53000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5017 - loss: 8.8174 - val_accuracy: 0.5500 - val_loss: 7.5967\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5015 - loss: 7.2668\n",
            "Epoch 3: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5017 - loss: 7.2543 - val_accuracy: 0.5400 - val_loss: 6.3061\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5265 - loss: 6.0462\n",
            "Epoch 4: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5274 - loss: 6.0364 - val_accuracy: 0.5500 - val_loss: 5.2873\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5390 - loss: 5.0802\n",
            "Epoch 5: val_accuracy improved from 0.55000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5397 - loss: 5.0723 - val_accuracy: 0.6400 - val_loss: 4.4663\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5802 - loss: 4.3068\n",
            "Epoch 6: val_accuracy improved from 0.64000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5801 - loss: 4.3006 - val_accuracy: 0.6700 - val_loss: 3.8067\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5741 - loss: 3.6849\n",
            "Epoch 7: val_accuracy improved from 0.67000 to 0.69000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5745 - loss: 3.6798 - val_accuracy: 0.6900 - val_loss: 3.2433\n",
            "Epoch 8/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6197 - loss: 3.1709\n",
            "Epoch 8: val_accuracy improved from 0.69000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6202 - loss: 3.1647 - val_accuracy: 0.7000 - val_loss: 2.8248\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6543 - loss: 2.7561\n",
            "Epoch 9: val_accuracy improved from 0.70000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6546 - loss: 2.7525 - val_accuracy: 0.7400 - val_loss: 2.4694\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6701 - loss: 2.4093\n",
            "Epoch 10: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6704 - loss: 2.4063 - val_accuracy: 0.7000 - val_loss: 2.1656\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7012 - loss: 2.1132\n",
            "Epoch 11: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7007 - loss: 2.1104 - val_accuracy: 0.7300 - val_loss: 1.9252\n",
            "Epoch 12/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7117 - loss: 1.8884\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7117 - loss: 1.8875 - val_accuracy: 0.7100 - val_loss: 1.7478\n",
            "Epoch 13/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7117 - loss: 1.7042\n",
            "Epoch 13: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7119 - loss: 1.7020 - val_accuracy: 0.7100 - val_loss: 1.5794\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7161 - loss: 1.5418\n",
            "Epoch 14: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7159 - loss: 1.5397 - val_accuracy: 0.7400 - val_loss: 1.4411\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7334 - loss: 1.4006\n",
            "Epoch 15: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7330 - loss: 1.3998 - val_accuracy: 0.7200 - val_loss: 1.3466\n",
            "Epoch 16/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7222 - loss: 1.3037\n",
            "Epoch 16: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7228 - loss: 1.2988 - val_accuracy: 0.7300 - val_loss: 1.2421\n",
            "Epoch 17/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7106 - loss: 1.2160\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7108 - loss: 1.2155 - val_accuracy: 0.7200 - val_loss: 1.1767\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7202 - loss: 1.1251\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7207 - loss: 1.1239 - val_accuracy: 0.6400 - val_loss: 1.1152\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7357 - loss: 1.0268\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7359 - loss: 1.0265 - val_accuracy: 0.7300 - val_loss: 1.0167\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7380 - loss: 0.9715\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7380 - loss: 0.9717 - val_accuracy: 0.7200 - val_loss: 0.9666\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7545 - loss: 0.9169\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7541 - loss: 0.9168 - val_accuracy: 0.7100 - val_loss: 0.9139\n",
            "Epoch 22/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7465 - loss: 0.8718\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7460 - loss: 0.8728 - val_accuracy: 0.5900 - val_loss: 0.9485\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7375 - loss: 0.8609\n",
            "Epoch 23: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7378 - loss: 0.8604 - val_accuracy: 0.7500 - val_loss: 0.8561\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7381 - loss: 0.8225\n",
            "Epoch 24: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7380 - loss: 0.8224 - val_accuracy: 0.7300 - val_loss: 0.8228\n",
            "Epoch 25/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7632 - loss: 0.7723\n",
            "Epoch 25: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7627 - loss: 0.7728 - val_accuracy: 0.6900 - val_loss: 0.8540\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7454 - loss: 0.7892\n",
            "Epoch 26: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7454 - loss: 0.7887 - val_accuracy: 0.7400 - val_loss: 0.8070\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7399 - loss: 0.7615\n",
            "Epoch 27: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7401 - loss: 0.7612 - val_accuracy: 0.7300 - val_loss: 0.7692\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7537 - loss: 0.7371\n",
            "Epoch 28: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7536 - loss: 0.7369 - val_accuracy: 0.7300 - val_loss: 0.7377\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7542 - loss: 0.7153\n",
            "Epoch 29: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7542 - loss: 0.7153 - val_accuracy: 0.6600 - val_loss: 0.8059\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7310 - loss: 0.7226\n",
            "Epoch 30: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7313 - loss: 0.7222 - val_accuracy: 0.7100 - val_loss: 0.7503\n",
            "Epoch 31/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7529 - loss: 0.6902\n",
            "Epoch 31: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7532 - loss: 0.6896 - val_accuracy: 0.7500 - val_loss: 0.7072\n",
            "Epoch 32/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7692 - loss: 0.6582\n",
            "Epoch 32: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7691 - loss: 0.6585 - val_accuracy: 0.7100 - val_loss: 0.7166\n",
            "Epoch 33/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7543 - loss: 0.6752\n",
            "Epoch 33: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7542 - loss: 0.6752 - val_accuracy: 0.7500 - val_loss: 0.7125\n",
            "Epoch 34/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7623 - loss: 0.6629\n",
            "Epoch 34: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7612 - loss: 0.6631 - val_accuracy: 0.6900 - val_loss: 0.7357\n",
            "Epoch 35/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7571 - loss: 0.6607\n",
            "Epoch 35: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7580 - loss: 0.6596 - val_accuracy: 0.7200 - val_loss: 0.7281\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7538 - loss: 0.6389\n",
            "Epoch 36: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7539 - loss: 0.6394 - val_accuracy: 0.7200 - val_loss: 0.7059\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7744 - loss: 0.6255\n",
            "Epoch 37: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7742 - loss: 0.6261 - val_accuracy: 0.6800 - val_loss: 0.7182\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7555 - loss: 0.6516\n",
            "Epoch 38: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7553 - loss: 0.6518 - val_accuracy: 0.7200 - val_loss: 0.6944\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7592 - loss: 0.6368\n",
            "Epoch 39: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7590 - loss: 0.6371 - val_accuracy: 0.7000 - val_loss: 0.7175\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7523 - loss: 0.6530\n",
            "Epoch 40: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7528 - loss: 0.6523 - val_accuracy: 0.7700 - val_loss: 0.6790\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.6304\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7545 - loss: 0.6303 - val_accuracy: 0.7000 - val_loss: 0.7271\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7626 - loss: 0.6175\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7624 - loss: 0.6179 - val_accuracy: 0.7300 - val_loss: 0.6930\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7746 - loss: 0.6220\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7738 - loss: 0.6226 - val_accuracy: 0.7600 - val_loss: 0.6828\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7620 - loss: 0.6290\n",
            "Epoch 44: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7616 - loss: 0.6295 - val_accuracy: 0.6700 - val_loss: 0.7172\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7674 - loss: 0.6131\n",
            "Epoch 45: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 0.6138 - val_accuracy: 0.7300 - val_loss: 0.6701\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.6038\n",
            "Epoch 46: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7757 - loss: 0.6044 - val_accuracy: 0.7000 - val_loss: 0.6985\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7613 - loss: 0.6175\n",
            "Epoch 47: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7611 - loss: 0.6179 - val_accuracy: 0.7200 - val_loss: 0.6692\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7646 - loss: 0.6165\n",
            "Epoch 48: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7643 - loss: 0.6169 - val_accuracy: 0.7400 - val_loss: 0.6744\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.6272\n",
            "Epoch 49: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7601 - loss: 0.6267 - val_accuracy: 0.7700 - val_loss: 0.6537\n",
            "Epoch 50/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7717 - loss: 0.6051\n",
            "Epoch 50: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7708 - loss: 0.6063 - val_accuracy: 0.6900 - val_loss: 0.7173\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "13 / 50\n",
            "\n",
            "--- Fold 14 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4827 - loss: 16.9641\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 135ms/step - accuracy: 0.4829 - loss: 16.8738 - val_accuracy: 0.5000 - val_loss: 9.3538\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5155 - loss: 8.9630\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.5159 - loss: 8.9317 - val_accuracy: 0.5400 - val_loss: 7.7673\n",
            "Epoch 3/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5060 - loss: 7.4683\n",
            "Epoch 3: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5061 - loss: 7.4441 - val_accuracy: 0.5400 - val_loss: 6.5389\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5081 - loss: 6.2926\n",
            "Epoch 4: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5085 - loss: 6.2832 - val_accuracy: 0.5300 - val_loss: 5.5646\n",
            "Epoch 5/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5312 - loss: 5.3596\n",
            "Epoch 5: val_accuracy improved from 0.54000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5313 - loss: 5.3559 - val_accuracy: 0.6100 - val_loss: 4.7749\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5230 - loss: 4.6211\n",
            "Epoch 6: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5233 - loss: 4.6149 - val_accuracy: 0.5400 - val_loss: 4.1341\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5345 - loss: 4.0032\n",
            "Epoch 7: val_accuracy improved from 0.61000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5355 - loss: 3.9979 - val_accuracy: 0.6400 - val_loss: 3.5928\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5782 - loss: 3.4853\n",
            "Epoch 8: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5784 - loss: 3.4812 - val_accuracy: 0.6200 - val_loss: 3.1579\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6075 - loss: 3.0626\n",
            "Epoch 9: val_accuracy improved from 0.64000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6079 - loss: 3.0592 - val_accuracy: 0.7100 - val_loss: 2.7729\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6570 - loss: 2.6993\n",
            "Epoch 10: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6568 - loss: 2.6964 - val_accuracy: 0.7100 - val_loss: 2.4506\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6602 - loss: 2.3998\n",
            "Epoch 11: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6605 - loss: 2.3972 - val_accuracy: 0.6900 - val_loss: 2.1918\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6519 - loss: 2.1657\n",
            "Epoch 12: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6520 - loss: 2.1636 - val_accuracy: 0.7000 - val_loss: 1.9518\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6991 - loss: 1.9233\n",
            "Epoch 13: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6989 - loss: 1.9217 - val_accuracy: 0.7000 - val_loss: 1.7754\n",
            "Epoch 14/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6960 - loss: 1.7479\n",
            "Epoch 14: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6962 - loss: 1.7423 - val_accuracy: 0.6500 - val_loss: 1.6529\n",
            "Epoch 15/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6934 - loss: 1.6104\n",
            "Epoch 15: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6952 - loss: 1.6039 - val_accuracy: 0.6500 - val_loss: 1.5138\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6997 - loss: 1.4737\n",
            "Epoch 16: val_accuracy improved from 0.71000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7002 - loss: 1.4720 - val_accuracy: 0.7200 - val_loss: 1.3561\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7184 - loss: 1.3549\n",
            "Epoch 17: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7184 - loss: 1.3536 - val_accuracy: 0.6900 - val_loss: 1.2994\n",
            "Epoch 18/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7062 - loss: 1.2603\n",
            "Epoch 18: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7066 - loss: 1.2596 - val_accuracy: 0.7000 - val_loss: 1.1914\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7187 - loss: 1.1629\n",
            "Epoch 19: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7187 - loss: 1.1625 - val_accuracy: 0.7200 - val_loss: 1.1182\n",
            "Epoch 20/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7296 - loss: 1.0851\n",
            "Epoch 20: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7277 - loss: 1.0851 - val_accuracy: 0.6900 - val_loss: 1.0505\n",
            "Epoch 21/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7486 - loss: 1.0299\n",
            "Epoch 21: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7481 - loss: 1.0284 - val_accuracy: 0.7000 - val_loss: 1.0247\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7406 - loss: 0.9669\n",
            "Epoch 22: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7406 - loss: 0.9668 - val_accuracy: 0.6900 - val_loss: 0.9590\n",
            "Epoch 23/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7472 - loss: 0.9214\n",
            "Epoch 23: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7468 - loss: 0.9206 - val_accuracy: 0.7100 - val_loss: 0.9251\n",
            "Epoch 24/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7327 - loss: 0.8824\n",
            "Epoch 24: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7332 - loss: 0.8817 - val_accuracy: 0.6900 - val_loss: 0.8854\n",
            "Epoch 25/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7157 - loss: 0.8809\n",
            "Epoch 25: val_accuracy improved from 0.72000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7165 - loss: 0.8795 - val_accuracy: 0.7400 - val_loss: 0.8695\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7355 - loss: 0.8387\n",
            "Epoch 26: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7357 - loss: 0.8382 - val_accuracy: 0.6600 - val_loss: 0.8704\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7553 - loss: 0.7945\n",
            "Epoch 27: val_accuracy improved from 0.74000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7555 - loss: 0.7942 - val_accuracy: 0.7600 - val_loss: 0.8093\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7493 - loss: 0.7681\n",
            "Epoch 28: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7495 - loss: 0.7677 - val_accuracy: 0.7500 - val_loss: 0.7803\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7468 - loss: 0.7582\n",
            "Epoch 29: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7468 - loss: 0.7580 - val_accuracy: 0.7400 - val_loss: 0.7521\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7652 - loss: 0.7289\n",
            "Epoch 30: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7645 - loss: 0.7295 - val_accuracy: 0.6900 - val_loss: 0.7824\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7508 - loss: 0.7110\n",
            "Epoch 31: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7506 - loss: 0.7113 - val_accuracy: 0.7100 - val_loss: 0.7407\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7537 - loss: 0.6956\n",
            "Epoch 32: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7535 - loss: 0.6959 - val_accuracy: 0.7100 - val_loss: 0.7248\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7518 - loss: 0.7011\n",
            "Epoch 33: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7517 - loss: 0.7007 - val_accuracy: 0.7000 - val_loss: 0.7527\n",
            "Epoch 34/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7589 - loss: 0.6834\n",
            "Epoch 34: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7583 - loss: 0.6841 - val_accuracy: 0.7100 - val_loss: 0.7383\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7641 - loss: 0.6722\n",
            "Epoch 35: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7639 - loss: 0.6724 - val_accuracy: 0.7300 - val_loss: 0.7340\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7700 - loss: 0.6577\n",
            "Epoch 36: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7700 - loss: 0.6576 - val_accuracy: 0.7000 - val_loss: 0.7298\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7579 - loss: 0.6744\n",
            "Epoch 37: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7579 - loss: 0.6744 - val_accuracy: 0.7300 - val_loss: 0.7118\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7805 - loss: 0.6537\n",
            "Epoch 38: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7801 - loss: 0.6540 - val_accuracy: 0.7300 - val_loss: 0.7046\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7568 - loss: 0.6462\n",
            "Epoch 39: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7568 - loss: 0.6464 - val_accuracy: 0.6500 - val_loss: 0.7317\n",
            "Epoch 40/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7680 - loss: 0.6448\n",
            "Epoch 40: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7676 - loss: 0.6449 - val_accuracy: 0.7000 - val_loss: 0.7186\n",
            "Epoch 41/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7746 - loss: 0.6305\n",
            "Epoch 41: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7726 - loss: 0.6333 - val_accuracy: 0.7000 - val_loss: 0.6925\n",
            "Epoch 42/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7823 - loss: 0.6318\n",
            "Epoch 42: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7823 - loss: 0.6318 - val_accuracy: 0.6900 - val_loss: 0.6943\n",
            "Epoch 43/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7698 - loss: 0.6219\n",
            "Epoch 43: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7696 - loss: 0.6226 - val_accuracy: 0.6600 - val_loss: 0.7669\n",
            "Epoch 44/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7425 - loss: 0.6663\n",
            "Epoch 44: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7443 - loss: 0.6640 - val_accuracy: 0.7000 - val_loss: 0.7353\n",
            "Epoch 45/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7654 - loss: 0.6248\n",
            "Epoch 45: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7654 - loss: 0.6260 - val_accuracy: 0.6900 - val_loss: 0.7275\n",
            "Epoch 46/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7827 - loss: 0.6208\n",
            "Epoch 46: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7823 - loss: 0.6221 - val_accuracy: 0.7700 - val_loss: 0.6872\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7558 - loss: 0.6528\n",
            "Epoch 47: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7560 - loss: 0.6524 - val_accuracy: 0.7200 - val_loss: 0.6892\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7857 - loss: 0.6025\n",
            "Epoch 48: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7850 - loss: 0.6037 - val_accuracy: 0.6900 - val_loss: 0.7243\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7686 - loss: 0.6319\n",
            "Epoch 49: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.6319 - val_accuracy: 0.6700 - val_loss: 0.7060\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7677 - loss: 0.6197\n",
            "Epoch 50: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7678 - loss: 0.6198 - val_accuracy: 0.6900 - val_loss: 0.7122\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "14 / 50\n",
            "\n",
            "--- Fold 15 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5108 - loss: 19.0755\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.5106 - loss: 18.9552 - val_accuracy: 0.4800 - val_loss: 9.3214\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5016 - loss: 8.9524\n",
            "Epoch 2: val_accuracy did not improve from 0.48000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5023 - loss: 8.9232 - val_accuracy: 0.4500 - val_loss: 7.8428\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5063 - loss: 7.5512\n",
            "Epoch 3: val_accuracy did not improve from 0.48000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5067 - loss: 7.5402 - val_accuracy: 0.4500 - val_loss: 6.7016\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5128 - loss: 6.4686\n",
            "Epoch 4: val_accuracy did not improve from 0.48000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5125 - loss: 6.4598 - val_accuracy: 0.4500 - val_loss: 5.7850\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5086 - loss: 5.5948\n",
            "Epoch 5: val_accuracy did not improve from 0.48000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5088 - loss: 5.5876 - val_accuracy: 0.4500 - val_loss: 5.0368\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5133 - loss: 4.8811\n",
            "Epoch 6: val_accuracy did not improve from 0.48000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5131 - loss: 4.8721 - val_accuracy: 0.4500 - val_loss: 4.4166\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5114 - loss: 4.2853\n",
            "Epoch 7: val_accuracy improved from 0.48000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5117 - loss: 4.2803 - val_accuracy: 0.5400 - val_loss: 3.8964\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5153 - loss: 3.7871\n",
            "Epoch 8: val_accuracy improved from 0.54000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5156 - loss: 3.7829 - val_accuracy: 0.6500 - val_loss: 3.4554\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5418 - loss: 3.3646\n",
            "Epoch 9: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5417 - loss: 3.3611 - val_accuracy: 0.4600 - val_loss: 3.0941\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5562 - loss: 3.0085\n",
            "Epoch 10: val_accuracy improved from 0.65000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5566 - loss: 3.0054 - val_accuracy: 0.7100 - val_loss: 2.7586\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5739 - loss: 2.6967\n",
            "Epoch 11: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5744 - loss: 2.6940 - val_accuracy: 0.6800 - val_loss: 2.4471\n",
            "Epoch 12/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6012 - loss: 2.4353\n",
            "Epoch 12: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6020 - loss: 2.4289 - val_accuracy: 0.6700 - val_loss: 2.2142\n",
            "Epoch 13/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6299 - loss: 2.2060\n",
            "Epoch 13: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6300 - loss: 2.2012 - val_accuracy: 0.6600 - val_loss: 2.0265\n",
            "Epoch 14/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6540 - loss: 1.9927\n",
            "Epoch 14: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6555 - loss: 1.9872 - val_accuracy: 0.6400 - val_loss: 1.8682\n",
            "Epoch 15/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6767 - loss: 1.8103\n",
            "Epoch 15: val_accuracy improved from 0.71000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6773 - loss: 1.8078 - val_accuracy: 0.7600 - val_loss: 1.6810\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6985 - loss: 1.6571\n",
            "Epoch 16: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6981 - loss: 1.6563 - val_accuracy: 0.7100 - val_loss: 1.5484\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6890 - loss: 1.5381\n",
            "Epoch 17: val_accuracy improved from 0.76000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6891 - loss: 1.5370 - val_accuracy: 0.7800 - val_loss: 1.4049\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7143 - loss: 1.4171\n",
            "Epoch 18: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7141 - loss: 1.4162 - val_accuracy: 0.6200 - val_loss: 1.3819\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7067 - loss: 1.3332\n",
            "Epoch 19: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7069 - loss: 1.3322 - val_accuracy: 0.7900 - val_loss: 1.2198\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7255 - loss: 1.2268\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7249 - loss: 1.2267 - val_accuracy: 0.7800 - val_loss: 1.1183\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7434 - loss: 1.1439\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7428 - loss: 1.1438 - val_accuracy: 0.6800 - val_loss: 1.1249\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7304 - loss: 1.0882\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7304 - loss: 1.0877 - val_accuracy: 0.6100 - val_loss: 1.1100\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7293 - loss: 1.0437\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7295 - loss: 1.0431 - val_accuracy: 0.6200 - val_loss: 1.0508\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7289 - loss: 0.9941\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7289 - loss: 0.9937 - val_accuracy: 0.7900 - val_loss: 0.9326\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7385 - loss: 0.9379\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7382 - loss: 0.9379 - val_accuracy: 0.7600 - val_loss: 0.8951\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7176 - loss: 0.9117\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7182 - loss: 0.9111 - val_accuracy: 0.7300 - val_loss: 0.8558\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7621 - loss: 0.8423\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7613 - loss: 0.8429 - val_accuracy: 0.7900 - val_loss: 0.8084\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7561 - loss: 0.8171\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7559 - loss: 0.8173 - val_accuracy: 0.6600 - val_loss: 0.8646\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.8069\n",
            "Epoch 29: val_accuracy improved from 0.79000 to 0.81000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7317 - loss: 0.8071 - val_accuracy: 0.8100 - val_loss: 0.7650\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7629 - loss: 0.7797\n",
            "Epoch 30: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7624 - loss: 0.7802 - val_accuracy: 0.7700 - val_loss: 0.7163\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7538 - loss: 0.7608\n",
            "Epoch 31: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7532 - loss: 0.7609 - val_accuracy: 0.8000 - val_loss: 0.7121\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7462 - loss: 0.7449\n",
            "Epoch 32: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7462 - loss: 0.7445 - val_accuracy: 0.7200 - val_loss: 0.7625\n",
            "Epoch 33/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7387 - loss: 0.7433\n",
            "Epoch 33: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7389 - loss: 0.7429 - val_accuracy: 0.7400 - val_loss: 0.6914\n",
            "Epoch 34/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.7030\n",
            "Epoch 34: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7596 - loss: 0.7035 - val_accuracy: 0.7900 - val_loss: 0.6800\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7469 - loss: 0.7131\n",
            "Epoch 35: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7469 - loss: 0.7129 - val_accuracy: 0.7500 - val_loss: 0.6783\n",
            "Epoch 36/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7554 - loss: 0.6902\n",
            "Epoch 36: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7546 - loss: 0.6908 - val_accuracy: 0.7100 - val_loss: 0.7080\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7503 - loss: 0.6913\n",
            "Epoch 37: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7504 - loss: 0.6909 - val_accuracy: 0.7900 - val_loss: 0.6275\n",
            "Epoch 38/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7487 - loss: 0.6822\n",
            "Epoch 38: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7478 - loss: 0.6834 - val_accuracy: 0.7700 - val_loss: 0.7053\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7620 - loss: 0.6716\n",
            "Epoch 39: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7618 - loss: 0.6715 - val_accuracy: 0.7800 - val_loss: 0.6447\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7586 - loss: 0.6630\n",
            "Epoch 40: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7586 - loss: 0.6630 - val_accuracy: 0.7800 - val_loss: 0.6255\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7527 - loss: 0.6564\n",
            "Epoch 41: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7532 - loss: 0.6558 - val_accuracy: 0.7900 - val_loss: 0.5984\n",
            "Epoch 42/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7503 - loss: 0.6658\n",
            "Epoch 42: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7500 - loss: 0.6650 - val_accuracy: 0.7500 - val_loss: 0.6139\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7777 - loss: 0.6242\n",
            "Epoch 43: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7771 - loss: 0.6250 - val_accuracy: 0.7000 - val_loss: 0.6480\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7670 - loss: 0.6363\n",
            "Epoch 44: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7670 - loss: 0.6365 - val_accuracy: 0.7700 - val_loss: 0.6047\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7516 - loss: 0.6516\n",
            "Epoch 45: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7512 - loss: 0.6521 - val_accuracy: 0.6800 - val_loss: 0.6905\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7637 - loss: 0.6285\n",
            "Epoch 46: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7633 - loss: 0.6293 - val_accuracy: 0.7300 - val_loss: 0.6313\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7572 - loss: 0.6361\n",
            "Epoch 47: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7575 - loss: 0.6360 - val_accuracy: 0.7200 - val_loss: 0.6551\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7819 - loss: 0.6186\n",
            "Epoch 48: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7815 - loss: 0.6192 - val_accuracy: 0.7300 - val_loss: 0.6415\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7639 - loss: 0.6352\n",
            "Epoch 49: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7641 - loss: 0.6348 - val_accuracy: 0.7700 - val_loss: 0.5798\n",
            "Epoch 49: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "15 / 50\n",
            "\n",
            "--- Fold 16 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4739 - loss: 18.0382\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 153ms/step - accuracy: 0.4741 - loss: 17.9317 - val_accuracy: 0.5000 - val_loss: 9.3916\n",
            "Epoch 2/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5194 - loss: 9.0110\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5199 - loss: 8.9889 - val_accuracy: 0.6200 - val_loss: 7.8846\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5288 - loss: 7.5870\n",
            "Epoch 3: val_accuracy improved from 0.62000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5291 - loss: 7.5756 - val_accuracy: 0.6700 - val_loss: 6.7056\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5487 - loss: 6.4637\n",
            "Epoch 4: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5483 - loss: 6.4546 - val_accuracy: 0.5400 - val_loss: 5.7507\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5446 - loss: 5.5592\n",
            "Epoch 5: val_accuracy improved from 0.67000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5446 - loss: 5.5517 - val_accuracy: 0.7300 - val_loss: 4.9635\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5789 - loss: 4.8101\n",
            "Epoch 6: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5784 - loss: 4.8041 - val_accuracy: 0.5800 - val_loss: 4.3296\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5831 - loss: 4.1983\n",
            "Epoch 7: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5834 - loss: 4.1931 - val_accuracy: 0.6100 - val_loss: 3.7668\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6318 - loss: 3.6672\n",
            "Epoch 8: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6319 - loss: 3.6629 - val_accuracy: 0.7100 - val_loss: 3.2987\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6266 - loss: 3.2370\n",
            "Epoch 9: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6267 - loss: 3.2334 - val_accuracy: 0.6800 - val_loss: 2.9098\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6362 - loss: 2.8921\n",
            "Epoch 10: val_accuracy improved from 0.73000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6371 - loss: 2.8883 - val_accuracy: 0.7600 - val_loss: 2.5596\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6943 - loss: 2.5299\n",
            "Epoch 11: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6943 - loss: 2.5278 - val_accuracy: 0.7200 - val_loss: 2.2923\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6845 - loss: 2.2998\n",
            "Epoch 12: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6845 - loss: 2.2975 - val_accuracy: 0.6900 - val_loss: 2.1083\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 2.0761\n",
            "Epoch 13: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6956 - loss: 2.0738 - val_accuracy: 0.6900 - val_loss: 1.9142\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 1.8549\n",
            "Epoch 14: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7313 - loss: 1.8538 - val_accuracy: 0.7200 - val_loss: 1.7598\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7408 - loss: 1.6845\n",
            "Epoch 15: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7401 - loss: 1.6840 - val_accuracy: 0.6700 - val_loss: 1.6615\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 1.5667\n",
            "Epoch 16: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7315 - loss: 1.5655 - val_accuracy: 0.6700 - val_loss: 1.5195\n",
            "Epoch 17/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7473 - loss: 1.4246\n",
            "Epoch 17: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7472 - loss: 1.4229 - val_accuracy: 0.6800 - val_loss: 1.3773\n",
            "Epoch 18/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7580 - loss: 1.3075\n",
            "Epoch 18: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7562 - loss: 1.3076 - val_accuracy: 0.7500 - val_loss: 1.2677\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7515 - loss: 1.2300\n",
            "Epoch 19: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7509 - loss: 1.2292 - val_accuracy: 0.7600 - val_loss: 1.1799\n",
            "Epoch 20/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7463 - loss: 1.1391\n",
            "Epoch 20: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7467 - loss: 1.1383 - val_accuracy: 0.7200 - val_loss: 1.1207\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7570 - loss: 1.0783\n",
            "Epoch 21: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7569 - loss: 1.0779 - val_accuracy: 0.7500 - val_loss: 1.0863\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7330 - loss: 1.0415\n",
            "Epoch 22: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7334 - loss: 1.0408 - val_accuracy: 0.6800 - val_loss: 1.0475\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7414 - loss: 0.9821\n",
            "Epoch 23: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7413 - loss: 0.9817 - val_accuracy: 0.6400 - val_loss: 1.0316\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7413 - loss: 0.9403\n",
            "Epoch 24: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 0.9399 - val_accuracy: 0.7100 - val_loss: 0.9366\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7521 - loss: 0.8830\n",
            "Epoch 25: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7525 - loss: 0.8831 - val_accuracy: 0.6900 - val_loss: 0.8986\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7614 - loss: 0.8628\n",
            "Epoch 26: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7613 - loss: 0.8623 - val_accuracy: 0.6900 - val_loss: 0.8615\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7712 - loss: 0.8063\n",
            "Epoch 27: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7709 - loss: 0.8066 - val_accuracy: 0.7100 - val_loss: 0.8273\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7750 - loss: 0.7777\n",
            "Epoch 28: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7747 - loss: 0.7780 - val_accuracy: 0.7200 - val_loss: 0.8065\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7893 - loss: 0.7401\n",
            "Epoch 29: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7886 - loss: 0.7408 - val_accuracy: 0.6600 - val_loss: 0.8268\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7579 - loss: 0.7531\n",
            "Epoch 30: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7581 - loss: 0.7526 - val_accuracy: 0.6600 - val_loss: 0.8544\n",
            "Epoch 30: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "16 / 50\n",
            "\n",
            "--- Fold 17 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5027 - loss: 15.8123\n",
            "Epoch 1: val_accuracy improved from -inf to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.5027 - loss: 15.7324 - val_accuracy: 0.6200 - val_loss: 8.9951\n",
            "Epoch 2/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5408 - loss: 8.5426\n",
            "Epoch 2: val_accuracy improved from 0.62000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5409 - loss: 8.5259 - val_accuracy: 0.6400 - val_loss: 7.2672\n",
            "Epoch 3/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5402 - loss: 6.9638\n",
            "Epoch 3: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5401 - loss: 6.9256 - val_accuracy: 0.6000 - val_loss: 5.9794\n",
            "Epoch 4/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5626 - loss: 5.7410\n",
            "Epoch 4: val_accuracy improved from 0.64000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5623 - loss: 5.7170 - val_accuracy: 0.6500 - val_loss: 4.9845\n",
            "Epoch 5/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5877 - loss: 4.7954\n",
            "Epoch 5: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5877 - loss: 4.7799 - val_accuracy: 0.5900 - val_loss: 4.1963\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6064 - loss: 4.0460\n",
            "Epoch 6: val_accuracy improved from 0.65000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6068 - loss: 4.0369 - val_accuracy: 0.7600 - val_loss: 3.5190\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6525 - loss: 3.4344\n",
            "Epoch 7: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6522 - loss: 3.4298 - val_accuracy: 0.7500 - val_loss: 2.9859\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6588 - loss: 2.9707\n",
            "Epoch 8: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6588 - loss: 2.9669 - val_accuracy: 0.7300 - val_loss: 2.6544\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 2.5646\n",
            "Epoch 9: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6953 - loss: 2.5615 - val_accuracy: 0.7200 - val_loss: 2.2703\n",
            "Epoch 10/50\n",
            "\u001b[1m44/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6878 - loss: 2.2667\n",
            "Epoch 10: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6907 - loss: 2.2533 - val_accuracy: 0.7100 - val_loss: 2.0436\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6963 - loss: 2.0063\n",
            "Epoch 11: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6960 - loss: 2.0041 - val_accuracy: 0.6800 - val_loss: 1.8549\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7127 - loss: 1.7781\n",
            "Epoch 12: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7128 - loss: 1.7759 - val_accuracy: 0.7300 - val_loss: 1.6175\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7033 - loss: 1.6003\n",
            "Epoch 13: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7042 - loss: 1.5983 - val_accuracy: 0.7400 - val_loss: 1.4768\n",
            "Epoch 14/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7304 - loss: 1.4343\n",
            "Epoch 14: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7303 - loss: 1.4338 - val_accuracy: 0.7300 - val_loss: 1.3517\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7258 - loss: 1.3216\n",
            "Epoch 15: val_accuracy improved from 0.76000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7259 - loss: 1.3206 - val_accuracy: 0.7900 - val_loss: 1.2198\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7221 - loss: 1.2173\n",
            "Epoch 16: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7222 - loss: 1.2163 - val_accuracy: 0.7100 - val_loss: 1.1844\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7284 - loss: 1.1331\n",
            "Epoch 17: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7283 - loss: 1.1324 - val_accuracy: 0.7900 - val_loss: 1.0680\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7286 - loss: 1.0567\n",
            "Epoch 18: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7288 - loss: 1.0558 - val_accuracy: 0.7800 - val_loss: 1.0040\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7370 - loss: 0.9933\n",
            "Epoch 19: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7372 - loss: 0.9923 - val_accuracy: 0.7800 - val_loss: 0.9347\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7442 - loss: 0.9324\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7441 - loss: 0.9316 - val_accuracy: 0.7500 - val_loss: 0.9337\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7522 - loss: 0.8824\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7521 - loss: 0.8821 - val_accuracy: 0.6400 - val_loss: 0.9369\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7474 - loss: 0.8491\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7472 - loss: 0.8487 - val_accuracy: 0.6300 - val_loss: 0.9083\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7657 - loss: 0.7941\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7643 - loss: 0.7952 - val_accuracy: 0.7200 - val_loss: 0.8341\n",
            "Epoch 24/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7533 - loss: 0.7863\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7529 - loss: 0.7867 - val_accuracy: 0.7400 - val_loss: 0.8159\n",
            "Epoch 25/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7551 - loss: 0.7629\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7548 - loss: 0.7624 - val_accuracy: 0.7100 - val_loss: 0.8063\n",
            "Epoch 26/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 0.7489\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7552 - loss: 0.7479 - val_accuracy: 0.7500 - val_loss: 0.7583\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7528 - loss: 0.7290\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7525 - loss: 0.7289 - val_accuracy: 0.7200 - val_loss: 0.7479\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7536 - loss: 0.7028\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7536 - loss: 0.7028 - val_accuracy: 0.6100 - val_loss: 0.8441\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7459 - loss: 0.7066\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7463 - loss: 0.7061 - val_accuracy: 0.7200 - val_loss: 0.7683\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7507 - loss: 0.6986\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7507 - loss: 0.6985 - val_accuracy: 0.7600 - val_loss: 0.7262\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7578 - loss: 0.6798\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7571 - loss: 0.6803 - val_accuracy: 0.7300 - val_loss: 0.7266\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7542 - loss: 0.6666\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7542 - loss: 0.6666 - val_accuracy: 0.7600 - val_loss: 0.7082\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7475 - loss: 0.6741\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7479 - loss: 0.6736 - val_accuracy: 0.7200 - val_loss: 0.7467\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7722 - loss: 0.6359\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.6364 - val_accuracy: 0.7000 - val_loss: 0.7610\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.6529\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.6531 - val_accuracy: 0.7200 - val_loss: 0.7300\n",
            "Epoch 35: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "17 / 50\n",
            "\n",
            "--- Fold 18 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5055 - loss: 16.0681\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.5056 - loss: 15.9863 - val_accuracy: 0.4600 - val_loss: 9.1380\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5021 - loss: 8.7337\n",
            "Epoch 2: val_accuracy improved from 0.46000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5027 - loss: 8.7020 - val_accuracy: 0.5500 - val_loss: 7.5270\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5302 - loss: 7.2147\n",
            "Epoch 3: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5301 - loss: 7.2030 - val_accuracy: 0.4800 - val_loss: 6.3163\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5386 - loss: 6.0711\n",
            "Epoch 4: val_accuracy improved from 0.55000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5386 - loss: 6.0619 - val_accuracy: 0.6700 - val_loss: 5.3580\n",
            "Epoch 5/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5631 - loss: 5.1817\n",
            "Epoch 5: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5633 - loss: 5.1553 - val_accuracy: 0.5800 - val_loss: 4.5756\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5493 - loss: 4.4394\n",
            "Epoch 6: val_accuracy improved from 0.67000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5501 - loss: 4.4301 - val_accuracy: 0.7300 - val_loss: 3.9063\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5988 - loss: 3.8281\n",
            "Epoch 7: val_accuracy improved from 0.73000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5991 - loss: 3.8230 - val_accuracy: 0.7800 - val_loss: 3.3710\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6124 - loss: 3.3388\n",
            "Epoch 8: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6124 - loss: 3.3347 - val_accuracy: 0.7600 - val_loss: 2.9363\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6690 - loss: 2.8992\n",
            "Epoch 9: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6691 - loss: 2.8959 - val_accuracy: 0.7500 - val_loss: 2.5825\n",
            "Epoch 10/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6799 - loss: 2.5658\n",
            "Epoch 10: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6791 - loss: 2.5618 - val_accuracy: 0.7200 - val_loss: 2.2935\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6852 - loss: 2.2729\n",
            "Epoch 11: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6856 - loss: 2.2704 - val_accuracy: 0.7800 - val_loss: 2.0307\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6782 - loss: 2.0493\n",
            "Epoch 12: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6788 - loss: 2.0469 - val_accuracy: 0.7700 - val_loss: 1.8209\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6873 - loss: 1.8292\n",
            "Epoch 13: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6876 - loss: 1.8273 - val_accuracy: 0.7200 - val_loss: 1.6319\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7046 - loss: 1.6473\n",
            "Epoch 14: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7043 - loss: 1.6463 - val_accuracy: 0.7300 - val_loss: 1.5330\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7255 - loss: 1.4978\n",
            "Epoch 15: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7252 - loss: 1.4967 - val_accuracy: 0.6100 - val_loss: 1.4534\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7191 - loss: 1.3869\n",
            "Epoch 16: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7190 - loss: 1.3860 - val_accuracy: 0.7900 - val_loss: 1.2241\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7257 - loss: 1.2740\n",
            "Epoch 17: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7257 - loss: 1.2731 - val_accuracy: 0.7800 - val_loss: 1.1710\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7224 - loss: 1.1760\n",
            "Epoch 18: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7228 - loss: 1.1752 - val_accuracy: 0.7400 - val_loss: 1.1111\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7307 - loss: 1.1100\n",
            "Epoch 19: val_accuracy improved from 0.79000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7308 - loss: 1.1091 - val_accuracy: 0.8000 - val_loss: 0.9997\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7300 - loss: 1.0409\n",
            "Epoch 20: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7296 - loss: 1.0407 - val_accuracy: 0.7700 - val_loss: 0.9673\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7244 - loss: 0.9947\n",
            "Epoch 21: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7246 - loss: 0.9940 - val_accuracy: 0.7500 - val_loss: 0.9419\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7325 - loss: 0.9316\n",
            "Epoch 22: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7327 - loss: 0.9312 - val_accuracy: 0.7600 - val_loss: 0.8556\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7483 - loss: 0.8689\n",
            "Epoch 23: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7477 - loss: 0.8693 - val_accuracy: 0.8000 - val_loss: 0.8001\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7535 - loss: 0.8368\n",
            "Epoch 24: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7529 - loss: 0.8374 - val_accuracy: 0.7900 - val_loss: 0.8128\n",
            "Epoch 25/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7419 - loss: 0.8231\n",
            "Epoch 25: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7420 - loss: 0.8224 - val_accuracy: 0.7700 - val_loss: 0.7747\n",
            "Epoch 26/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7517 - loss: 0.7838\n",
            "Epoch 26: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7513 - loss: 0.7837 - val_accuracy: 0.8000 - val_loss: 0.7430\n",
            "Epoch 27/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7544 - loss: 0.7791\n",
            "Epoch 27: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7545 - loss: 0.7781 - val_accuracy: 0.7400 - val_loss: 0.7568\n",
            "Epoch 28/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.7367\n",
            "Epoch 28: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.7368 - val_accuracy: 0.7900 - val_loss: 0.6904\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7527 - loss: 0.7306\n",
            "Epoch 29: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7527 - loss: 0.7306 - val_accuracy: 0.8000 - val_loss: 0.6996\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7468 - loss: 0.7185\n",
            "Epoch 30: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7466 - loss: 0.7187 - val_accuracy: 0.7900 - val_loss: 0.6806\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.7015\n",
            "Epoch 31: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7647 - loss: 0.7025 - val_accuracy: 0.6800 - val_loss: 0.7868\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7546 - loss: 0.6975\n",
            "Epoch 32: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7542 - loss: 0.6976 - val_accuracy: 0.7700 - val_loss: 0.6904\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7499 - loss: 0.6875\n",
            "Epoch 33: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7499 - loss: 0.6874 - val_accuracy: 0.7700 - val_loss: 0.6306\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.6530\n",
            "Epoch 34: val_accuracy improved from 0.80000 to 0.81000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7656 - loss: 0.6534 - val_accuracy: 0.8100 - val_loss: 0.6262\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7603 - loss: 0.6508\n",
            "Epoch 35: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7599 - loss: 0.6513 - val_accuracy: 0.7900 - val_loss: 0.6261\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7483 - loss: 0.6743\n",
            "Epoch 36: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7484 - loss: 0.6739 - val_accuracy: 0.7700 - val_loss: 0.6361\n",
            "Epoch 37/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7416 - loss: 0.6679\n",
            "Epoch 37: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7420 - loss: 0.6678 - val_accuracy: 0.7600 - val_loss: 0.6728\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7710 - loss: 0.6292\n",
            "Epoch 38: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7707 - loss: 0.6297 - val_accuracy: 0.7900 - val_loss: 0.6350\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7517 - loss: 0.6590\n",
            "Epoch 39: val_accuracy improved from 0.81000 to 0.82000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7516 - loss: 0.6588 - val_accuracy: 0.8200 - val_loss: 0.5967\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7503 - loss: 0.6412\n",
            "Epoch 40: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7503 - loss: 0.6414 - val_accuracy: 0.6800 - val_loss: 0.7162\n",
            "Epoch 41/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7585 - loss: 0.6384\n",
            "Epoch 41: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7588 - loss: 0.6379 - val_accuracy: 0.7700 - val_loss: 0.6311\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7658 - loss: 0.6260\n",
            "Epoch 42: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7656 - loss: 0.6264 - val_accuracy: 0.8000 - val_loss: 0.6126\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7731 - loss: 0.6273\n",
            "Epoch 43: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7726 - loss: 0.6279 - val_accuracy: 0.7100 - val_loss: 0.6998\n",
            "Epoch 44/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7565 - loss: 0.6268\n",
            "Epoch 44: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7566 - loss: 0.6273 - val_accuracy: 0.7900 - val_loss: 0.6049\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7755 - loss: 0.6298\n",
            "Epoch 45: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7752 - loss: 0.6298 - val_accuracy: 0.7800 - val_loss: 0.5992\n",
            "Epoch 46/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7743 - loss: 0.6362\n",
            "Epoch 46: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7739 - loss: 0.6364 - val_accuracy: 0.7900 - val_loss: 0.5823\n",
            "Epoch 47/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7863 - loss: 0.5932\n",
            "Epoch 47: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7849 - loss: 0.5958 - val_accuracy: 0.7800 - val_loss: 0.6139\n",
            "Epoch 48/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7647 - loss: 0.6210\n",
            "Epoch 48: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7641 - loss: 0.6223 - val_accuracy: 0.7300 - val_loss: 0.6872\n",
            "Epoch 49/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.6184\n",
            "Epoch 49: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7669 - loss: 0.6191 - val_accuracy: 0.7500 - val_loss: 0.6352\n",
            "Epoch 50/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7692 - loss: 0.6298\n",
            "Epoch 50: val_accuracy improved from 0.82000 to 0.84000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7692 - loss: 0.6296 - val_accuracy: 0.8400 - val_loss: 0.5700\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "18 / 50\n",
            "\n",
            "--- Fold 19 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5008 - loss: 19.7129\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 134ms/step - accuracy: 0.5008 - loss: 19.5867 - val_accuracy: 0.4700 - val_loss: 9.6088\n",
            "Epoch 2/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5210 - loss: 9.2844\n",
            "Epoch 2: val_accuracy improved from 0.47000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5214 - loss: 9.2353 - val_accuracy: 0.5400 - val_loss: 8.1964\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5083 - loss: 7.9116\n",
            "Epoch 3: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5084 - loss: 7.9007 - val_accuracy: 0.5000 - val_loss: 7.0660\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5104 - loss: 6.8347\n",
            "Epoch 4: val_accuracy improved from 0.54000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5107 - loss: 6.8212 - val_accuracy: 0.5500 - val_loss: 6.1350\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5138 - loss: 5.9410\n",
            "Epoch 5: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5140 - loss: 5.9335 - val_accuracy: 0.5400 - val_loss: 5.3633\n",
            "Epoch 6/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5142 - loss: 5.2059\n",
            "Epoch 6: val_accuracy improved from 0.55000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5147 - loss: 5.1933 - val_accuracy: 0.6000 - val_loss: 4.7159\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5106 - loss: 4.5813\n",
            "Epoch 7: val_accuracy improved from 0.60000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5112 - loss: 4.5760 - val_accuracy: 0.6200 - val_loss: 4.1687\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5095 - loss: 4.0552\n",
            "Epoch 8: val_accuracy did not improve from 0.62000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5099 - loss: 4.0507 - val_accuracy: 0.5400 - val_loss: 3.7077\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5468 - loss: 3.6081\n",
            "Epoch 9: val_accuracy improved from 0.62000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5469 - loss: 3.6043 - val_accuracy: 0.6400 - val_loss: 3.3103\n",
            "Epoch 10/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5724 - loss: 3.2271\n",
            "Epoch 10: val_accuracy improved from 0.64000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5716 - loss: 3.2207 - val_accuracy: 0.6500 - val_loss: 2.9481\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6145 - loss: 2.8915\n",
            "Epoch 11: val_accuracy improved from 0.65000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6144 - loss: 2.8870 - val_accuracy: 0.7200 - val_loss: 2.6254\n",
            "Epoch 12/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6533 - loss: 2.5908\n",
            "Epoch 12: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6529 - loss: 2.5841 - val_accuracy: 0.6800 - val_loss: 2.3863\n",
            "Epoch 13/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6442 - loss: 2.3601\n",
            "Epoch 13: val_accuracy improved from 0.72000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6441 - loss: 2.3557 - val_accuracy: 0.7300 - val_loss: 2.1579\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6865 - loss: 2.1241\n",
            "Epoch 14: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6860 - loss: 2.1225 - val_accuracy: 0.6400 - val_loss: 1.9932\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6793 - loss: 1.9493\n",
            "Epoch 15: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6795 - loss: 1.9481 - val_accuracy: 0.7300 - val_loss: 1.8119\n",
            "Epoch 16/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7147 - loss: 1.7602\n",
            "Epoch 16: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7136 - loss: 1.7596 - val_accuracy: 0.6700 - val_loss: 1.6983\n",
            "Epoch 17/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7168 - loss: 1.6331\n",
            "Epoch 17: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7160 - loss: 1.6320 - val_accuracy: 0.7300 - val_loss: 1.5681\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7028 - loss: 1.5302\n",
            "Epoch 18: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7028 - loss: 1.5292 - val_accuracy: 0.7400 - val_loss: 1.4397\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7244 - loss: 1.4106\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7244 - loss: 1.4097 - val_accuracy: 0.7400 - val_loss: 1.3542\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7164 - loss: 1.3333\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7163 - loss: 1.3324 - val_accuracy: 0.7300 - val_loss: 1.2725\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7309 - loss: 1.2406\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7303 - loss: 1.2404 - val_accuracy: 0.7200 - val_loss: 1.1939\n",
            "Epoch 22/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 1.1722\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7290 - loss: 1.1710 - val_accuracy: 0.7400 - val_loss: 1.1247\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7442 - loss: 1.0896\n",
            "Epoch 23: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7436 - loss: 1.0898 - val_accuracy: 0.6400 - val_loss: 1.1160\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7235 - loss: 1.0625\n",
            "Epoch 24: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7238 - loss: 1.0615 - val_accuracy: 0.7200 - val_loss: 1.0340\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7398 - loss: 0.9973\n",
            "Epoch 25: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7396 - loss: 0.9971 - val_accuracy: 0.7500 - val_loss: 0.9885\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7291 - loss: 0.9589\n",
            "Epoch 26: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7291 - loss: 0.9587 - val_accuracy: 0.6300 - val_loss: 0.9820\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7301 - loss: 0.9270\n",
            "Epoch 27: val_accuracy improved from 0.75000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7302 - loss: 0.9265 - val_accuracy: 0.7600 - val_loss: 0.8889\n",
            "Epoch 28/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7444 - loss: 0.8756\n",
            "Epoch 28: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7439 - loss: 0.8756 - val_accuracy: 0.6800 - val_loss: 0.9100\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7385 - loss: 0.8457\n",
            "Epoch 29: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7386 - loss: 0.8455 - val_accuracy: 0.7400 - val_loss: 0.8682\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7458 - loss: 0.8342\n",
            "Epoch 30: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7458 - loss: 0.8337 - val_accuracy: 0.6400 - val_loss: 0.9234\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7329 - loss: 0.8198\n",
            "Epoch 31: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7332 - loss: 0.8191 - val_accuracy: 0.7500 - val_loss: 0.8324\n",
            "Epoch 32/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7419 - loss: 0.7860\n",
            "Epoch 32: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7429 - loss: 0.7851 - val_accuracy: 0.7400 - val_loss: 0.7987\n",
            "Epoch 33/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7561 - loss: 0.7586\n",
            "Epoch 33: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7561 - loss: 0.7585 - val_accuracy: 0.7600 - val_loss: 0.7950\n",
            "Epoch 34/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7536 - loss: 0.7454\n",
            "Epoch 34: val_accuracy improved from 0.76000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7532 - loss: 0.7457 - val_accuracy: 0.8000 - val_loss: 0.7604\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7422 - loss: 0.7434\n",
            "Epoch 35: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7425 - loss: 0.7430 - val_accuracy: 0.7200 - val_loss: 0.7884\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7421 - loss: 0.7270\n",
            "Epoch 36: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7422 - loss: 0.7268 - val_accuracy: 0.7600 - val_loss: 0.7604\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7515 - loss: 0.7220\n",
            "Epoch 37: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7518 - loss: 0.7214 - val_accuracy: 0.7600 - val_loss: 0.7373\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7467 - loss: 0.6966\n",
            "Epoch 38: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7467 - loss: 0.6970 - val_accuracy: 0.7500 - val_loss: 0.7269\n",
            "Epoch 39/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7627 - loss: 0.6896\n",
            "Epoch 39: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7617 - loss: 0.6902 - val_accuracy: 0.7500 - val_loss: 0.7434\n",
            "Epoch 40/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7562 - loss: 0.6826\n",
            "Epoch 40: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7559 - loss: 0.6828 - val_accuracy: 0.7900 - val_loss: 0.7135\n",
            "Epoch 41/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7579 - loss: 0.6760\n",
            "Epoch 41: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7577 - loss: 0.6763 - val_accuracy: 0.7600 - val_loss: 0.7299\n",
            "Epoch 42/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7571 - loss: 0.6800\n",
            "Epoch 42: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7568 - loss: 0.6805 - val_accuracy: 0.7600 - val_loss: 0.6958\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.6575\n",
            "Epoch 43: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7680 - loss: 0.6581 - val_accuracy: 0.7500 - val_loss: 0.7184\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7619 - loss: 0.6529\n",
            "Epoch 44: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7616 - loss: 0.6536 - val_accuracy: 0.7200 - val_loss: 0.7050\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7576 - loss: 0.6624\n",
            "Epoch 45: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7575 - loss: 0.6626 - val_accuracy: 0.7600 - val_loss: 0.7131\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7614 - loss: 0.6489\n",
            "Epoch 46: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7614 - loss: 0.6489 - val_accuracy: 0.7200 - val_loss: 0.7165\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7594 - loss: 0.6508\n",
            "Epoch 47: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7596 - loss: 0.6508 - val_accuracy: 0.7700 - val_loss: 0.6830\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7787 - loss: 0.6303\n",
            "Epoch 48: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7780 - loss: 0.6310 - val_accuracy: 0.7600 - val_loss: 0.6803\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7638 - loss: 0.6464\n",
            "Epoch 49: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7634 - loss: 0.6467 - val_accuracy: 0.6900 - val_loss: 0.7301\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7532 - loss: 0.6452\n",
            "Epoch 50: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7535 - loss: 0.6451 - val_accuracy: 0.7300 - val_loss: 0.7226\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "19 / 50\n",
            "\n",
            "--- Fold 20 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5216 - loss: 17.6104\n",
            "Epoch 1: val_accuracy improved from -inf to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 0.5214 - loss: 17.5094 - val_accuracy: 0.5400 - val_loss: 9.4043\n",
            "Epoch 2/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5232 - loss: 8.9994\n",
            "Epoch 2: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5231 - loss: 8.9922 - val_accuracy: 0.5400 - val_loss: 7.8645\n",
            "Epoch 3/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5254 - loss: 7.5625\n",
            "Epoch 3: val_accuracy improved from 0.54000 to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5256 - loss: 7.5448 - val_accuracy: 0.5700 - val_loss: 6.6531\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5011 - loss: 6.4072\n",
            "Epoch 4: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5015 - loss: 6.3978 - val_accuracy: 0.5000 - val_loss: 5.6773\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5243 - loss: 5.4747\n",
            "Epoch 5: val_accuracy improved from 0.57000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5248 - loss: 5.4670 - val_accuracy: 0.6000 - val_loss: 4.8776\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5514 - loss: 4.7110\n",
            "Epoch 6: val_accuracy improved from 0.60000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5523 - loss: 4.7046 - val_accuracy: 0.6200 - val_loss: 4.2090\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5677 - loss: 4.0858\n",
            "Epoch 7: val_accuracy improved from 0.62000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5683 - loss: 4.0778 - val_accuracy: 0.7300 - val_loss: 3.6519\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6419 - loss: 3.5423\n",
            "Epoch 8: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6416 - loss: 3.5382 - val_accuracy: 0.5300 - val_loss: 3.2409\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6170 - loss: 3.1319\n",
            "Epoch 9: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6179 - loss: 3.1278 - val_accuracy: 0.5800 - val_loss: 2.8352\n",
            "Epoch 10/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7035 - loss: 2.7247\n",
            "Epoch 10: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7025 - loss: 2.7209 - val_accuracy: 0.6900 - val_loss: 2.5129\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7102 - loss: 2.4164\n",
            "Epoch 11: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7104 - loss: 2.4138 - val_accuracy: 0.7300 - val_loss: 2.2080\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7020 - loss: 2.1735\n",
            "Epoch 12: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7016 - loss: 2.1717 - val_accuracy: 0.6700 - val_loss: 2.0342\n",
            "Epoch 13/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7074 - loss: 1.9578\n",
            "Epoch 13: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7077 - loss: 1.9547 - val_accuracy: 0.6400 - val_loss: 1.8446\n",
            "Epoch 14/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7250 - loss: 1.7692\n",
            "Epoch 14: val_accuracy improved from 0.73000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7242 - loss: 1.7641 - val_accuracy: 0.7600 - val_loss: 1.6468\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7064 - loss: 1.6058\n",
            "Epoch 15: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7066 - loss: 1.6048 - val_accuracy: 0.7400 - val_loss: 1.4898\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7243 - loss: 1.4776\n",
            "Epoch 16: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7236 - loss: 1.4773 - val_accuracy: 0.7500 - val_loss: 1.3800\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7347 - loss: 1.3498\n",
            "Epoch 17: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7338 - loss: 1.3498 - val_accuracy: 0.6900 - val_loss: 1.3110\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7286 - loss: 1.2573\n",
            "Epoch 18: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7284 - loss: 1.2565 - val_accuracy: 0.7100 - val_loss: 1.2098\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7438 - loss: 1.1576\n",
            "Epoch 19: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7436 - loss: 1.1571 - val_accuracy: 0.6800 - val_loss: 1.1468\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 1.0868\n",
            "Epoch 20: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7481 - loss: 1.0866 - val_accuracy: 0.6100 - val_loss: 1.1161\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7517 - loss: 1.0238\n",
            "Epoch 21: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7512 - loss: 1.0239 - val_accuracy: 0.6200 - val_loss: 1.0516\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7374 - loss: 0.9761\n",
            "Epoch 22: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7376 - loss: 0.9757 - val_accuracy: 0.6500 - val_loss: 1.0016\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7332 - loss: 0.9296\n",
            "Epoch 23: val_accuracy improved from 0.76000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7329 - loss: 0.9297 - val_accuracy: 0.7800 - val_loss: 0.9331\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7390 - loss: 0.8950\n",
            "Epoch 24: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7391 - loss: 0.8946 - val_accuracy: 0.6700 - val_loss: 0.9245\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7421 - loss: 0.8608\n",
            "Epoch 25: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7418 - loss: 0.8608 - val_accuracy: 0.7600 - val_loss: 0.8628\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7472 - loss: 0.8221\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7473 - loss: 0.8220 - val_accuracy: 0.6900 - val_loss: 0.8556\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7312 - loss: 0.8129\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7316 - loss: 0.8123 - val_accuracy: 0.7000 - val_loss: 0.8328\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7464 - loss: 0.7836\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7465 - loss: 0.7831 - val_accuracy: 0.7100 - val_loss: 0.8168\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7507 - loss: 0.7718\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7505 - loss: 0.7715 - val_accuracy: 0.6400 - val_loss: 0.8429\n",
            "Epoch 30/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7553 - loss: 0.7469\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7550 - loss: 0.7471 - val_accuracy: 0.6500 - val_loss: 0.7853\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7505 - loss: 0.7294\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7506 - loss: 0.7293 - val_accuracy: 0.7300 - val_loss: 0.7397\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.7128\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.7126 - val_accuracy: 0.5800 - val_loss: 0.8093\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7526 - loss: 0.7109\n",
            "Epoch 33: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7524 - loss: 0.7107 - val_accuracy: 0.6200 - val_loss: 0.7829\n",
            "Epoch 34/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7626 - loss: 0.6826\n",
            "Epoch 34: val_accuracy improved from 0.78000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7613 - loss: 0.6840 - val_accuracy: 0.8000 - val_loss: 0.7362\n",
            "Epoch 35/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7598 - loss: 0.6850\n",
            "Epoch 35: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7598 - loss: 0.6847 - val_accuracy: 0.7700 - val_loss: 0.7063\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7637 - loss: 0.6628\n",
            "Epoch 36: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7632 - loss: 0.6637 - val_accuracy: 0.6400 - val_loss: 0.7714\n",
            "Epoch 37/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7517 - loss: 0.6830\n",
            "Epoch 37: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7518 - loss: 0.6827 - val_accuracy: 0.6400 - val_loss: 0.7787\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7745 - loss: 0.6398\n",
            "Epoch 38: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7741 - loss: 0.6404 - val_accuracy: 0.6800 - val_loss: 0.7249\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7683 - loss: 0.6452\n",
            "Epoch 39: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7674 - loss: 0.6461 - val_accuracy: 0.6600 - val_loss: 0.7141\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7645 - loss: 0.6503\n",
            "Epoch 40: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7643 - loss: 0.6503 - val_accuracy: 0.7200 - val_loss: 0.7139\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7572 - loss: 0.6507\n",
            "Epoch 41: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7574 - loss: 0.6507 - val_accuracy: 0.6800 - val_loss: 0.7216\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7613 - loss: 0.6437\n",
            "Epoch 42: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7614 - loss: 0.6437 - val_accuracy: 0.7400 - val_loss: 0.6764\n",
            "Epoch 43/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7697 - loss: 0.6401\n",
            "Epoch 43: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7690 - loss: 0.6410 - val_accuracy: 0.6700 - val_loss: 0.7267\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7545 - loss: 0.6627\n",
            "Epoch 44: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7548 - loss: 0.6622 - val_accuracy: 0.6900 - val_loss: 0.7077\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - loss: 0.6484\n",
            "Epoch 45: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7499 - loss: 0.6478 - val_accuracy: 0.5100 - val_loss: 0.9111\n",
            "Epoch 46/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7489 - loss: 0.6611\n",
            "Epoch 46: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7496 - loss: 0.6597 - val_accuracy: 0.7000 - val_loss: 0.7105\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7810 - loss: 0.6155\n",
            "Epoch 47: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7805 - loss: 0.6160 - val_accuracy: 0.5800 - val_loss: 0.8294\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7540 - loss: 0.6397\n",
            "Epoch 48: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7543 - loss: 0.6397 - val_accuracy: 0.6500 - val_loss: 0.7429\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7646 - loss: 0.6249\n",
            "Epoch 49: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7645 - loss: 0.6249 - val_accuracy: 0.7300 - val_loss: 0.6781\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7634 - loss: 0.6401\n",
            "Epoch 50: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7632 - loss: 0.6403 - val_accuracy: 0.7500 - val_loss: 0.6671\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "20 / 50\n",
            "\n",
            "--- Fold 21 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.4807 - loss: 17.8197\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 0.4807 - loss: 17.7159 - val_accuracy: 0.5000 - val_loss: 9.2847\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5113 - loss: 8.9096\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5106 - loss: 8.8720 - val_accuracy: 0.5900 - val_loss: 7.7586\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5238 - loss: 7.4579\n",
            "Epoch 3: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5234 - loss: 7.4467 - val_accuracy: 0.5500 - val_loss: 6.5848\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5065 - loss: 6.3459\n",
            "Epoch 4: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5067 - loss: 6.3369 - val_accuracy: 0.5600 - val_loss: 5.6467\n",
            "Epoch 5/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5226 - loss: 5.4494\n",
            "Epoch 5: val_accuracy improved from 0.59000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5225 - loss: 5.4458 - val_accuracy: 0.6400 - val_loss: 4.8835\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5432 - loss: 4.7241\n",
            "Epoch 6: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5424 - loss: 4.7181 - val_accuracy: 0.5500 - val_loss: 4.2547\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5074 - loss: 4.1253\n",
            "Epoch 7: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5075 - loss: 4.1177 - val_accuracy: 0.6300 - val_loss: 3.7314\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5523 - loss: 3.6200\n",
            "Epoch 8: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5523 - loss: 3.6158 - val_accuracy: 0.6100 - val_loss: 3.2871\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5652 - loss: 3.1938\n",
            "Epoch 9: val_accuracy improved from 0.64000 to 0.66000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5652 - loss: 3.1904 - val_accuracy: 0.6600 - val_loss: 2.9168\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6021 - loss: 2.8339\n",
            "Epoch 10: val_accuracy did not improve from 0.66000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6022 - loss: 2.8310 - val_accuracy: 0.6600 - val_loss: 2.5888\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6247 - loss: 2.5244\n",
            "Epoch 11: val_accuracy improved from 0.66000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6250 - loss: 2.5207 - val_accuracy: 0.7100 - val_loss: 2.2914\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6612 - loss: 2.2568\n",
            "Epoch 12: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6612 - loss: 2.2546 - val_accuracy: 0.6600 - val_loss: 2.0421\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6674 - loss: 2.0325\n",
            "Epoch 13: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6667 - loss: 2.0314 - val_accuracy: 0.6600 - val_loss: 1.8667\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6842 - loss: 1.8432\n",
            "Epoch 14: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6840 - loss: 1.8419 - val_accuracy: 0.6600 - val_loss: 1.7110\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6913 - loss: 1.6748\n",
            "Epoch 15: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6909 - loss: 1.6739 - val_accuracy: 0.6900 - val_loss: 1.5631\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6806 - loss: 1.5524\n",
            "Epoch 16: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6813 - loss: 1.5509 - val_accuracy: 0.6900 - val_loss: 1.4164\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7046 - loss: 1.4179\n",
            "Epoch 17: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7041 - loss: 1.4174 - val_accuracy: 0.7000 - val_loss: 1.3203\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7081 - loss: 1.3133\n",
            "Epoch 18: val_accuracy improved from 0.71000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7080 - loss: 1.3121 - val_accuracy: 0.7400 - val_loss: 1.2359\n",
            "Epoch 19/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7148 - loss: 1.2287\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7143 - loss: 1.2275 - val_accuracy: 0.7200 - val_loss: 1.1870\n",
            "Epoch 20/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7266 - loss: 1.1514\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7258 - loss: 1.1502 - val_accuracy: 0.7300 - val_loss: 1.0839\n",
            "Epoch 21/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7077 - loss: 1.0886\n",
            "Epoch 21: val_accuracy improved from 0.74000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7071 - loss: 1.0868 - val_accuracy: 0.7600 - val_loss: 1.0237\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7133 - loss: 1.0202\n",
            "Epoch 22: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7133 - loss: 1.0200 - val_accuracy: 0.7000 - val_loss: 1.0077\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7410 - loss: 0.9631\n",
            "Epoch 23: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7401 - loss: 0.9632 - val_accuracy: 0.7500 - val_loss: 0.9600\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7330 - loss: 0.9286\n",
            "Epoch 24: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7326 - loss: 0.9283 - val_accuracy: 0.7300 - val_loss: 0.9021\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7332 - loss: 0.8739\n",
            "Epoch 25: val_accuracy improved from 0.76000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7328 - loss: 0.8741 - val_accuracy: 0.7800 - val_loss: 0.8839\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7277 - loss: 0.8457\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7273 - loss: 0.8461 - val_accuracy: 0.7400 - val_loss: 0.8579\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6998 - loss: 0.8563\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7003 - loss: 0.8553 - val_accuracy: 0.7100 - val_loss: 0.8186\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7244 - loss: 0.8019\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7244 - loss: 0.8017 - val_accuracy: 0.6800 - val_loss: 0.7956\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7145 - loss: 0.7944\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7148 - loss: 0.7942 - val_accuracy: 0.7400 - val_loss: 0.7606\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7224 - loss: 0.7723\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7232 - loss: 0.7709 - val_accuracy: 0.7000 - val_loss: 0.7731\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7118 - loss: 0.7617\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7121 - loss: 0.7614 - val_accuracy: 0.7200 - val_loss: 0.7598\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7189 - loss: 0.7530\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7191 - loss: 0.7526 - val_accuracy: 0.6600 - val_loss: 0.7621\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7381 - loss: 0.7219\n",
            "Epoch 33: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7385 - loss: 0.7213 - val_accuracy: 0.7000 - val_loss: 0.7153\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7432 - loss: 0.7032\n",
            "Epoch 34: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7428 - loss: 0.7034 - val_accuracy: 0.7300 - val_loss: 0.7300\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7508 - loss: 0.6819\n",
            "Epoch 35: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7502 - loss: 0.6823 - val_accuracy: 0.6800 - val_loss: 0.7374\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7353 - loss: 0.7027\n",
            "Epoch 36: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7353 - loss: 0.7022 - val_accuracy: 0.7300 - val_loss: 0.7153\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7473 - loss: 0.6718\n",
            "Epoch 37: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7474 - loss: 0.6717 - val_accuracy: 0.7400 - val_loss: 0.7150\n",
            "Epoch 38/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7420 - loss: 0.6711\n",
            "Epoch 38: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7418 - loss: 0.6716 - val_accuracy: 0.6300 - val_loss: 0.7629\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7453 - loss: 0.6759\n",
            "Epoch 39: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7454 - loss: 0.6759 - val_accuracy: 0.6200 - val_loss: 0.8379\n",
            "Epoch 40/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7291 - loss: 0.7031\n",
            "Epoch 40: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7308 - loss: 0.7004 - val_accuracy: 0.7000 - val_loss: 0.6898\n",
            "Epoch 41/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7426 - loss: 0.6544\n",
            "Epoch 41: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7425 - loss: 0.6545 - val_accuracy: 0.7100 - val_loss: 0.7015\n",
            "Epoch 42/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7479 - loss: 0.6572\n",
            "Epoch 42: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7470 - loss: 0.6583 - val_accuracy: 0.7200 - val_loss: 0.6845\n",
            "Epoch 43/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7440 - loss: 0.6521\n",
            "Epoch 43: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7433 - loss: 0.6531 - val_accuracy: 0.7100 - val_loss: 0.6855\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7341 - loss: 0.6516\n",
            "Epoch 44: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7344 - loss: 0.6515 - val_accuracy: 0.6800 - val_loss: 0.6952\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7284 - loss: 0.6604\n",
            "Epoch 45: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7286 - loss: 0.6603 - val_accuracy: 0.6800 - val_loss: 0.6844\n",
            "Epoch 45: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "21 / 50\n",
            "\n",
            "--- Fold 22 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5117 - loss: 15.7784\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.5118 - loss: 15.7002 - val_accuracy: 0.4600 - val_loss: 9.0740\n",
            "Epoch 2/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5245 - loss: 8.6439 \n",
            "Epoch 2: val_accuracy improved from 0.46000 to 0.58000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5236 - loss: 8.6196 - val_accuracy: 0.5800 - val_loss: 7.4063\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5248 - loss: 7.0837\n",
            "Epoch 3: val_accuracy improved from 0.58000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5247 - loss: 7.0717 - val_accuracy: 0.6000 - val_loss: 6.1543\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5045 - loss: 5.9048\n",
            "Epoch 4: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5050 - loss: 5.8954 - val_accuracy: 0.4600 - val_loss: 5.1754\n",
            "Epoch 5/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5260 - loss: 4.9735\n",
            "Epoch 5: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5259 - loss: 4.9698 - val_accuracy: 0.5700 - val_loss: 4.3876\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5264 - loss: 4.2409\n",
            "Epoch 6: val_accuracy improved from 0.60000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5266 - loss: 4.2348 - val_accuracy: 0.7200 - val_loss: 3.7634\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5698 - loss: 3.6358\n",
            "Epoch 7: val_accuracy improved from 0.72000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5705 - loss: 3.6280 - val_accuracy: 0.7700 - val_loss: 3.2112\n",
            "Epoch 8/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6054 - loss: 3.1245\n",
            "Epoch 8: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6052 - loss: 3.1228 - val_accuracy: 0.7000 - val_loss: 2.8093\n",
            "Epoch 9/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6214 - loss: 2.7337\n",
            "Epoch 9: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6220 - loss: 2.7238 - val_accuracy: 0.7100 - val_loss: 2.4181\n",
            "Epoch 10/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6365 - loss: 2.4082\n",
            "Epoch 10: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6385 - loss: 2.3978 - val_accuracy: 0.6500 - val_loss: 2.1842\n",
            "Epoch 11/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6885 - loss: 2.0996\n",
            "Epoch 11: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6894 - loss: 2.0931 - val_accuracy: 0.7300 - val_loss: 1.9034\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6901 - loss: 1.8728\n",
            "Epoch 12: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6904 - loss: 1.8709 - val_accuracy: 0.7200 - val_loss: 1.7171\n",
            "Epoch 13/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 1.6759\n",
            "Epoch 13: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 1.6732 - val_accuracy: 0.6900 - val_loss: 1.5609\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7116 - loss: 1.5302\n",
            "Epoch 14: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7111 - loss: 1.5293 - val_accuracy: 0.6100 - val_loss: 1.4958\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7197 - loss: 1.3907\n",
            "Epoch 15: val_accuracy improved from 0.77000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7201 - loss: 1.3891 - val_accuracy: 0.7800 - val_loss: 1.2401\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7460 - loss: 1.2604\n",
            "Epoch 16: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7461 - loss: 1.2594 - val_accuracy: 0.7900 - val_loss: 1.1647\n",
            "Epoch 17/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7514 - loss: 1.1671\n",
            "Epoch 17: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7511 - loss: 1.1660 - val_accuracy: 0.7900 - val_loss: 1.0766\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7356 - loss: 1.0919\n",
            "Epoch 18: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7354 - loss: 1.0916 - val_accuracy: 0.7400 - val_loss: 1.0195\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7587 - loss: 0.9878\n",
            "Epoch 19: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7579 - loss: 0.9886 - val_accuracy: 0.6400 - val_loss: 1.0448\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7143 - loss: 0.9875\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7150 - loss: 0.9866 - val_accuracy: 0.7400 - val_loss: 0.9364\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7652 - loss: 0.8946\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7648 - loss: 0.8944 - val_accuracy: 0.7700 - val_loss: 0.8695\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7524 - loss: 0.8443\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7523 - loss: 0.8444 - val_accuracy: 0.7800 - val_loss: 0.8397\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7469 - loss: 0.8305\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7474 - loss: 0.8297 - val_accuracy: 0.7800 - val_loss: 0.7674\n",
            "Epoch 24/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7618 - loss: 0.7820\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7617 - loss: 0.7819 - val_accuracy: 0.7600 - val_loss: 0.7917\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7496 - loss: 0.7650\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7646 - val_accuracy: 0.7800 - val_loss: 0.7503\n",
            "Epoch 26/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7398 - loss: 0.7699\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7406 - loss: 0.7686 - val_accuracy: 0.7700 - val_loss: 0.7492\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7576 - loss: 0.7122\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7578 - loss: 0.7122 - val_accuracy: 0.7900 - val_loss: 0.6882\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7768 - loss: 0.6967\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7766 - loss: 0.6964 - val_accuracy: 0.7900 - val_loss: 0.6634\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7566 - loss: 0.6972\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7568 - loss: 0.6971 - val_accuracy: 0.7800 - val_loss: 0.6828\n",
            "Epoch 30/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7703 - loss: 0.6705\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7708 - loss: 0.6706 - val_accuracy: 0.7900 - val_loss: 0.6434\n",
            "Epoch 31/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7585 - loss: 0.6733\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7592 - loss: 0.6726 - val_accuracy: 0.7300 - val_loss: 0.6945\n",
            "Epoch 32/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7507 - loss: 0.6586\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7504 - loss: 0.6599 - val_accuracy: 0.7300 - val_loss: 0.6966\n",
            "Epoch 33/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7573 - loss: 0.6637\n",
            "Epoch 33: val_accuracy improved from 0.79000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7571 - loss: 0.6634 - val_accuracy: 0.8000 - val_loss: 0.6308\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7707 - loss: 0.6331\n",
            "Epoch 34: val_accuracy improved from 0.80000 to 0.82000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7704 - loss: 0.6336 - val_accuracy: 0.8200 - val_loss: 0.6313\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7668 - loss: 0.6456\n",
            "Epoch 35: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7670 - loss: 0.6451 - val_accuracy: 0.7600 - val_loss: 0.6432\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7703 - loss: 0.6231\n",
            "Epoch 36: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7696 - loss: 0.6239 - val_accuracy: 0.7900 - val_loss: 0.6215\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7589 - loss: 0.6453\n",
            "Epoch 37: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7590 - loss: 0.6452 - val_accuracy: 0.7200 - val_loss: 0.6607\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7791 - loss: 0.6077\n",
            "Epoch 38: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7787 - loss: 0.6081 - val_accuracy: 0.7900 - val_loss: 0.6086\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7645 - loss: 0.6330\n",
            "Epoch 39: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7646 - loss: 0.6329 - val_accuracy: 0.7600 - val_loss: 0.6547\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7692 - loss: 0.6163\n",
            "Epoch 40: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7689 - loss: 0.6168 - val_accuracy: 0.7700 - val_loss: 0.6075\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7849 - loss: 0.6065\n",
            "Epoch 41: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7848 - loss: 0.6069 - val_accuracy: 0.7400 - val_loss: 0.6695\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7754 - loss: 0.6064\n",
            "Epoch 42: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7752 - loss: 0.6068 - val_accuracy: 0.7900 - val_loss: 0.6001\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7903 - loss: 0.6049\n",
            "Epoch 43: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7900 - loss: 0.6052 - val_accuracy: 0.7600 - val_loss: 0.6497\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7727 - loss: 0.6310\n",
            "Epoch 44: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7730 - loss: 0.6303 - val_accuracy: 0.7900 - val_loss: 0.6251\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7853 - loss: 0.6076\n",
            "Epoch 45: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7848 - loss: 0.6079 - val_accuracy: 0.7400 - val_loss: 0.6594\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7826 - loss: 0.6168\n",
            "Epoch 46: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7823 - loss: 0.6169 - val_accuracy: 0.7800 - val_loss: 0.5830\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7844 - loss: 0.5961\n",
            "Epoch 47: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7843 - loss: 0.5963 - val_accuracy: 0.7600 - val_loss: 0.5936\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7727 - loss: 0.5994\n",
            "Epoch 48: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7725 - loss: 0.5996 - val_accuracy: 0.7300 - val_loss: 0.6666\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7886 - loss: 0.5942\n",
            "Epoch 49: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7877 - loss: 0.5950 - val_accuracy: 0.7400 - val_loss: 0.6233\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8045 - loss: 0.5842\n",
            "Epoch 50: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8039 - loss: 0.5848 - val_accuracy: 0.7300 - val_loss: 0.7103\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "22 / 50\n",
            "\n",
            "--- Fold 23 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5184 - loss: 17.1143\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 0.5184 - loss: 17.0204 - val_accuracy: 0.5200 - val_loss: 9.2713\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5011 - loss: 8.8863 \n",
            "Epoch 2: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5015 - loss: 8.8559 - val_accuracy: 0.4900 - val_loss: 7.7216\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5320 - loss: 7.4116\n",
            "Epoch 3: val_accuracy improved from 0.52000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5317 - loss: 7.4002 - val_accuracy: 0.5500 - val_loss: 6.5234\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5342 - loss: 6.2835\n",
            "Epoch 4: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5337 - loss: 6.2697 - val_accuracy: 0.5100 - val_loss: 5.5694\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5214 - loss: 5.3756\n",
            "Epoch 5: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5217 - loss: 5.3681 - val_accuracy: 0.5200 - val_loss: 4.7970\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5473 - loss: 4.6364\n",
            "Epoch 6: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5471 - loss: 4.6303 - val_accuracy: 0.5400 - val_loss: 4.1622\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5539 - loss: 4.0314\n",
            "Epoch 7: val_accuracy improved from 0.55000 to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5537 - loss: 4.0264 - val_accuracy: 0.5900 - val_loss: 3.6291\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5737 - loss: 3.5275\n",
            "Epoch 8: val_accuracy improved from 0.59000 to 0.63000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5736 - loss: 3.5234 - val_accuracy: 0.6300 - val_loss: 3.1869\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6038 - loss: 3.0990\n",
            "Epoch 9: val_accuracy improved from 0.63000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6042 - loss: 3.0954 - val_accuracy: 0.6500 - val_loss: 2.8038\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6269 - loss: 2.7422\n",
            "Epoch 10: val_accuracy improved from 0.65000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6271 - loss: 2.7394 - val_accuracy: 0.6700 - val_loss: 2.4973\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6500 - loss: 2.4437\n",
            "Epoch 11: val_accuracy improved from 0.67000 to 0.69000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6493 - loss: 2.4406 - val_accuracy: 0.6900 - val_loss: 2.2247\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6638 - loss: 2.1986\n",
            "Epoch 12: val_accuracy did not improve from 0.69000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6640 - loss: 2.1961 - val_accuracy: 0.6800 - val_loss: 2.0027\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6681 - loss: 1.9809\n",
            "Epoch 13: val_accuracy did not improve from 0.69000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6681 - loss: 1.9793 - val_accuracy: 0.5900 - val_loss: 1.8615\n",
            "Epoch 14/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6733 - loss: 1.8031\n",
            "Epoch 14: val_accuracy improved from 0.69000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6731 - loss: 1.7997 - val_accuracy: 0.7000 - val_loss: 1.6797\n",
            "Epoch 15/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7002 - loss: 1.6484\n",
            "Epoch 15: val_accuracy improved from 0.70000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6997 - loss: 1.6432 - val_accuracy: 0.7400 - val_loss: 1.5152\n",
            "Epoch 16/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7035 - loss: 1.5037\n",
            "Epoch 16: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7032 - loss: 1.5013 - val_accuracy: 0.6200 - val_loss: 1.4504\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7051 - loss: 1.3914\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7051 - loss: 1.3903 - val_accuracy: 0.7000 - val_loss: 1.3090\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6960 - loss: 1.3059\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6964 - loss: 1.3047 - val_accuracy: 0.7000 - val_loss: 1.2094\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7235 - loss: 1.1888\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7224 - loss: 1.1887 - val_accuracy: 0.6800 - val_loss: 1.1458\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7067 - loss: 1.1426\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7066 - loss: 1.1424 - val_accuracy: 0.6800 - val_loss: 1.0892\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7142 - loss: 1.0750\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7145 - loss: 1.0742 - val_accuracy: 0.6800 - val_loss: 1.0178\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6934 - loss: 1.0326\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6940 - loss: 1.0313 - val_accuracy: 0.6900 - val_loss: 0.9892\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7256 - loss: 0.9695\n",
            "Epoch 23: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7254 - loss: 0.9693 - val_accuracy: 0.6700 - val_loss: 0.9539\n",
            "Epoch 24/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7264 - loss: 0.9061\n",
            "Epoch 24: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7262 - loss: 0.9063 - val_accuracy: 0.6700 - val_loss: 0.9436\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7115 - loss: 0.8971\n",
            "Epoch 25: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7113 - loss: 0.8969 - val_accuracy: 0.7200 - val_loss: 0.8738\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7356 - loss: 0.8415\n",
            "Epoch 26: val_accuracy improved from 0.74000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7354 - loss: 0.8415 - val_accuracy: 0.7700 - val_loss: 0.8409\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7418 - loss: 0.8183\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7418 - loss: 0.8182 - val_accuracy: 0.6300 - val_loss: 0.8660\n",
            "Epoch 28/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7278 - loss: 0.8148\n",
            "Epoch 28: val_accuracy improved from 0.77000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7280 - loss: 0.8136 - val_accuracy: 0.7900 - val_loss: 0.7690\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.7791\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7339 - loss: 0.7789 - val_accuracy: 0.7200 - val_loss: 0.7971\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7524 - loss: 0.7539\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7520 - loss: 0.7540 - val_accuracy: 0.6600 - val_loss: 0.8027\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7219 - loss: 0.7672\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7218 - loss: 0.7670 - val_accuracy: 0.7600 - val_loss: 0.7485\n",
            "Epoch 32/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7337 - loss: 0.7360\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7337 - loss: 0.7358 - val_accuracy: 0.7800 - val_loss: 0.7447\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7280 - loss: 0.7499\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7280 - loss: 0.7498 - val_accuracy: 0.7400 - val_loss: 0.7394\n",
            "Epoch 34/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7652 - loss: 0.6772\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7641 - loss: 0.6789 - val_accuracy: 0.7400 - val_loss: 0.7442\n",
            "Epoch 35/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.6842\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7616 - loss: 0.6873 - val_accuracy: 0.7200 - val_loss: 0.7367\n",
            "Epoch 36/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7512 - loss: 0.6855\n",
            "Epoch 36: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7496 - loss: 0.6870 - val_accuracy: 0.7100 - val_loss: 0.7085\n",
            "Epoch 37/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7343 - loss: 0.6970\n",
            "Epoch 37: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7352 - loss: 0.6962 - val_accuracy: 0.7200 - val_loss: 0.7072\n",
            "Epoch 38/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7526 - loss: 0.6730\n",
            "Epoch 38: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7515 - loss: 0.6737 - val_accuracy: 0.7200 - val_loss: 0.7022\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7398 - loss: 0.6689\n",
            "Epoch 39: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7398 - loss: 0.6693 - val_accuracy: 0.7000 - val_loss: 0.7181\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7366 - loss: 0.6703\n",
            "Epoch 40: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7369 - loss: 0.6705 - val_accuracy: 0.7200 - val_loss: 0.6919\n",
            "Epoch 41/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7559 - loss: 0.6414\n",
            "Epoch 41: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7550 - loss: 0.6431 - val_accuracy: 0.7500 - val_loss: 0.7059\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7583 - loss: 0.6521\n",
            "Epoch 42: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7578 - loss: 0.6525 - val_accuracy: 0.6800 - val_loss: 0.7451\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7481 - loss: 0.6707\n",
            "Epoch 43: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7483 - loss: 0.6704 - val_accuracy: 0.7100 - val_loss: 0.7354\n",
            "Epoch 44/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7565 - loss: 0.6496\n",
            "Epoch 44: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7565 - loss: 0.6496 - val_accuracy: 0.6900 - val_loss: 0.6915\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7512 - loss: 0.6481\n",
            "Epoch 45: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7511 - loss: 0.6486 - val_accuracy: 0.7000 - val_loss: 0.7032\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7609 - loss: 0.6542\n",
            "Epoch 46: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7605 - loss: 0.6545 - val_accuracy: 0.7200 - val_loss: 0.6866\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7668 - loss: 0.6373\n",
            "Epoch 47: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7661 - loss: 0.6380 - val_accuracy: 0.6800 - val_loss: 0.6909\n",
            "Epoch 48/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.6342\n",
            "Epoch 48: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7689 - loss: 0.6355 - val_accuracy: 0.7200 - val_loss: 0.6900\n",
            "Epoch 48: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "23 / 50\n",
            "\n",
            "--- Fold 24 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5204 - loss: 18.8934\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 153ms/step - accuracy: 0.5201 - loss: 18.7757 - val_accuracy: 0.4900 - val_loss: 9.3865\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5055 - loss: 9.0310 \n",
            "Epoch 2: val_accuracy improved from 0.49000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5060 - loss: 9.0027 - val_accuracy: 0.5500 - val_loss: 7.9481\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5018 - loss: 7.6596\n",
            "Epoch 3: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5023 - loss: 7.6487 - val_accuracy: 0.5500 - val_loss: 6.8085\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5183 - loss: 6.5732\n",
            "Epoch 4: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5180 - loss: 6.5644 - val_accuracy: 0.4600 - val_loss: 5.8811\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5457 - loss: 5.6846\n",
            "Epoch 5: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5451 - loss: 5.6774 - val_accuracy: 0.4900 - val_loss: 5.1170\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5198 - loss: 4.9557\n",
            "Epoch 6: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5201 - loss: 4.9495 - val_accuracy: 0.5100 - val_loss: 4.4765\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5612 - loss: 4.3398\n",
            "Epoch 7: val_accuracy improved from 0.55000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5613 - loss: 4.3347 - val_accuracy: 0.6200 - val_loss: 3.9261\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5901 - loss: 3.8224\n",
            "Epoch 8: val_accuracy improved from 0.62000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5904 - loss: 3.8179 - val_accuracy: 0.7300 - val_loss: 3.4441\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6100 - loss: 3.3859\n",
            "Epoch 9: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6104 - loss: 3.3822 - val_accuracy: 0.7000 - val_loss: 3.0394\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6648 - loss: 2.9993\n",
            "Epoch 10: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6653 - loss: 2.9962 - val_accuracy: 0.7300 - val_loss: 2.7295\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6719 - loss: 2.6947\n",
            "Epoch 11: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6720 - loss: 2.6921 - val_accuracy: 0.7400 - val_loss: 2.4420\n",
            "Epoch 12/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6815 - loss: 2.4211\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6823 - loss: 2.4170 - val_accuracy: 0.6200 - val_loss: 2.2441\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7110 - loss: 2.1783\n",
            "Epoch 13: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7107 - loss: 2.1763 - val_accuracy: 0.7500 - val_loss: 2.0189\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7095 - loss: 1.9744\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7096 - loss: 1.9724 - val_accuracy: 0.7400 - val_loss: 1.8369\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7295 - loss: 1.7894\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7293 - loss: 1.7881 - val_accuracy: 0.6700 - val_loss: 1.7015\n",
            "Epoch 16/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7296 - loss: 1.6454\n",
            "Epoch 16: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7296 - loss: 1.6428 - val_accuracy: 0.7300 - val_loss: 1.5267\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7323 - loss: 1.5128\n",
            "Epoch 17: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7324 - loss: 1.5116 - val_accuracy: 0.7300 - val_loss: 1.4637\n",
            "Epoch 18/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7300 - loss: 1.3991\n",
            "Epoch 18: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7293 - loss: 1.3980 - val_accuracy: 0.7300 - val_loss: 1.3412\n",
            "Epoch 19/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7215 - loss: 1.3147\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7226 - loss: 1.3122 - val_accuracy: 0.7300 - val_loss: 1.2305\n",
            "Epoch 20/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7372 - loss: 1.2139\n",
            "Epoch 20: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7370 - loss: 1.2128 - val_accuracy: 0.7500 - val_loss: 1.1670\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7419 - loss: 1.1645\n",
            "Epoch 21: val_accuracy improved from 0.75000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7422 - loss: 1.1634 - val_accuracy: 0.7800 - val_loss: 1.1014\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7491 - loss: 1.0648\n",
            "Epoch 22: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7487 - loss: 1.0648 - val_accuracy: 0.7700 - val_loss: 1.0414\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7362 - loss: 1.0423\n",
            "Epoch 23: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7365 - loss: 1.0414 - val_accuracy: 0.7000 - val_loss: 1.0523\n",
            "Epoch 24/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7323 - loss: 0.9902\n",
            "Epoch 24: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7324 - loss: 0.9900 - val_accuracy: 0.7500 - val_loss: 0.9428\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7426 - loss: 0.9290\n",
            "Epoch 25: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7426 - loss: 0.9287 - val_accuracy: 0.6600 - val_loss: 0.9699\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7325 - loss: 0.9092\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7327 - loss: 0.9089 - val_accuracy: 0.7200 - val_loss: 0.9022\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.8504\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7599 - loss: 0.8508 - val_accuracy: 0.7500 - val_loss: 0.8473\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7351 - loss: 0.8603\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7354 - loss: 0.8595 - val_accuracy: 0.7400 - val_loss: 0.8343\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7599 - loss: 0.8130\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7593 - loss: 0.8132 - val_accuracy: 0.7000 - val_loss: 0.8429\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7638 - loss: 0.7783\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7631 - loss: 0.7787 - val_accuracy: 0.7100 - val_loss: 0.7891\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7290 - loss: 0.7988\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7295 - loss: 0.7980 - val_accuracy: 0.7200 - val_loss: 0.7835\n",
            "Epoch 32/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7552 - loss: 0.7499\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7549 - loss: 0.7501 - val_accuracy: 0.7300 - val_loss: 0.7771\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7589 - loss: 0.7223\n",
            "Epoch 33: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7587 - loss: 0.7225 - val_accuracy: 0.6900 - val_loss: 0.7800\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7515 - loss: 0.7200\n",
            "Epoch 34: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7517 - loss: 0.7200 - val_accuracy: 0.7600 - val_loss: 0.7149\n",
            "Epoch 35/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7620 - loss: 0.7026\n",
            "Epoch 35: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7618 - loss: 0.7027 - val_accuracy: 0.7200 - val_loss: 0.7155\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7691 - loss: 0.6871\n",
            "Epoch 36: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7689 - loss: 0.6872 - val_accuracy: 0.7500 - val_loss: 0.6940\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7462 - loss: 0.6938\n",
            "Epoch 37: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7465 - loss: 0.6937 - val_accuracy: 0.7300 - val_loss: 0.7093\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7599 - loss: 0.6790\n",
            "Epoch 38: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7598 - loss: 0.6790 - val_accuracy: 0.7200 - val_loss: 0.6990\n",
            "Epoch 39/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7741 - loss: 0.6583\n",
            "Epoch 39: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7735 - loss: 0.6589 - val_accuracy: 0.7500 - val_loss: 0.7157\n",
            "Epoch 40/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7793 - loss: 0.6607\n",
            "Epoch 40: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7785 - loss: 0.6613 - val_accuracy: 0.7600 - val_loss: 0.6735\n",
            "Epoch 41/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7631 - loss: 0.6578\n",
            "Epoch 41: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7629 - loss: 0.6585 - val_accuracy: 0.7000 - val_loss: 0.6907\n",
            "Epoch 41: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "24 / 50\n",
            "\n",
            "--- Fold 25 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5001 - loss: 14.9519\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 137ms/step - accuracy: 0.5000 - loss: 14.8852 - val_accuracy: 0.5000 - val_loss: 9.0581\n",
            "Epoch 2/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5096 - loss: 8.6010\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5098 - loss: 8.5841 - val_accuracy: 0.5300 - val_loss: 7.3085\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5064 - loss: 6.9697\n",
            "Epoch 3: val_accuracy improved from 0.53000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5067 - loss: 6.9571 - val_accuracy: 0.6000 - val_loss: 5.9948\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5046 - loss: 5.7351\n",
            "Epoch 4: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5051 - loss: 5.7253 - val_accuracy: 0.5200 - val_loss: 4.9784\n",
            "Epoch 5/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5261 - loss: 4.7782\n",
            "Epoch 5: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5264 - loss: 4.7665 - val_accuracy: 0.5400 - val_loss: 4.1785\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5362 - loss: 4.0161\n",
            "Epoch 6: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5365 - loss: 4.0100 - val_accuracy: 0.5500 - val_loss: 3.5374\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5262 - loss: 3.4103\n",
            "Epoch 7: val_accuracy improved from 0.60000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5269 - loss: 3.4053 - val_accuracy: 0.6500 - val_loss: 3.0097\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5451 - loss: 2.9319\n",
            "Epoch 8: val_accuracy improved from 0.65000 to 0.68000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5456 - loss: 2.9278 - val_accuracy: 0.6800 - val_loss: 2.5949\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6035 - loss: 2.5143\n",
            "Epoch 9: val_accuracy improved from 0.68000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6039 - loss: 2.5112 - val_accuracy: 0.7100 - val_loss: 2.2321\n",
            "Epoch 10/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6468 - loss: 2.1857\n",
            "Epoch 10: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6467 - loss: 2.1823 - val_accuracy: 0.6100 - val_loss: 2.0141\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6803 - loss: 1.9121\n",
            "Epoch 11: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6807 - loss: 1.9087 - val_accuracy: 0.6600 - val_loss: 1.7633\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6935 - loss: 1.7007\n",
            "Epoch 12: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6936 - loss: 1.6989 - val_accuracy: 0.6100 - val_loss: 1.5991\n",
            "Epoch 13/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7002 - loss: 1.5251\n",
            "Epoch 13: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7005 - loss: 1.5241 - val_accuracy: 0.6600 - val_loss: 1.4426\n",
            "Epoch 14/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 1.3661\n",
            "Epoch 14: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7289 - loss: 1.3640 - val_accuracy: 0.6900 - val_loss: 1.3036\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7280 - loss: 1.2447\n",
            "Epoch 15: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7279 - loss: 1.2441 - val_accuracy: 0.6800 - val_loss: 1.2161\n",
            "Epoch 16/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7214 - loss: 1.1535\n",
            "Epoch 16: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7216 - loss: 1.1524 - val_accuracy: 0.7000 - val_loss: 1.1063\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7249 - loss: 1.0680\n",
            "Epoch 17: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7251 - loss: 1.0671 - val_accuracy: 0.6700 - val_loss: 1.0655\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7292 - loss: 0.9977\n",
            "Epoch 18: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7293 - loss: 0.9970 - val_accuracy: 0.7000 - val_loss: 0.9879\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7597 - loss: 0.9205\n",
            "Epoch 19: val_accuracy did not improve from 0.71000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7591 - loss: 0.9204 - val_accuracy: 0.6700 - val_loss: 0.9388\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7529 - loss: 0.8613\n",
            "Epoch 20: val_accuracy improved from 0.71000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7527 - loss: 0.8615 - val_accuracy: 0.7400 - val_loss: 0.8784\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7726 - loss: 0.8223\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7715 - loss: 0.8229 - val_accuracy: 0.7300 - val_loss: 0.8422\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7502 - loss: 0.8016\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.8013 - val_accuracy: 0.6600 - val_loss: 0.8693\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7607 - loss: 0.7587\n",
            "Epoch 23: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7599 - loss: 0.7592 - val_accuracy: 0.6400 - val_loss: 0.8384\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7540 - loss: 0.7426\n",
            "Epoch 24: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7539 - loss: 0.7428 - val_accuracy: 0.6800 - val_loss: 0.7918\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7515 - loss: 0.7341\n",
            "Epoch 25: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7511 - loss: 0.7338 - val_accuracy: 0.7200 - val_loss: 0.7454\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7487 - loss: 0.7186\n",
            "Epoch 26: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7490 - loss: 0.7182 - val_accuracy: 0.5900 - val_loss: 0.8323\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7552 - loss: 0.7006\n",
            "Epoch 27: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7554 - loss: 0.7003 - val_accuracy: 0.7100 - val_loss: 0.7289\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7581 - loss: 0.6790\n",
            "Epoch 28: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7580 - loss: 0.6791 - val_accuracy: 0.7300 - val_loss: 0.7300\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7636 - loss: 0.6656\n",
            "Epoch 29: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7633 - loss: 0.6660 - val_accuracy: 0.7000 - val_loss: 0.7550\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7503 - loss: 0.6725\n",
            "Epoch 30: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7501 - loss: 0.6725 - val_accuracy: 0.6900 - val_loss: 0.7449\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7672 - loss: 0.6411\n",
            "Epoch 31: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7668 - loss: 0.6413 - val_accuracy: 0.6600 - val_loss: 0.7614\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7722 - loss: 0.6389\n",
            "Epoch 32: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7721 - loss: 0.6391 - val_accuracy: 0.7300 - val_loss: 0.7214\n",
            "Epoch 33/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7513 - loss: 0.6507\n",
            "Epoch 33: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7514 - loss: 0.6499 - val_accuracy: 0.7400 - val_loss: 0.7100\n",
            "Epoch 34/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7592 - loss: 0.6257\n",
            "Epoch 34: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7589 - loss: 0.6262 - val_accuracy: 0.7100 - val_loss: 0.7266\n",
            "Epoch 35/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7464 - loss: 0.6519\n",
            "Epoch 35: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7466 - loss: 0.6517 - val_accuracy: 0.7300 - val_loss: 0.7059\n",
            "Epoch 36/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7725 - loss: 0.6220\n",
            "Epoch 36: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7715 - loss: 0.6229 - val_accuracy: 0.7200 - val_loss: 0.7115\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7864 - loss: 0.6040\n",
            "Epoch 37: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7857 - loss: 0.6047 - val_accuracy: 0.7500 - val_loss: 0.7044\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7725 - loss: 0.6089\n",
            "Epoch 38: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7724 - loss: 0.6093 - val_accuracy: 0.7300 - val_loss: 0.6608\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7742 - loss: 0.6075\n",
            "Epoch 39: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7740 - loss: 0.6076 - val_accuracy: 0.6700 - val_loss: 0.7414\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7651 - loss: 0.6108\n",
            "Epoch 40: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7654 - loss: 0.6107 - val_accuracy: 0.7000 - val_loss: 0.7423\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7701 - loss: 0.6152\n",
            "Epoch 41: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7698 - loss: 0.6157 - val_accuracy: 0.6700 - val_loss: 0.7390\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7719 - loss: 0.6260\n",
            "Epoch 42: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7717 - loss: 0.6260 - val_accuracy: 0.6600 - val_loss: 0.7627\n",
            "Epoch 43/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7812 - loss: 0.6097\n",
            "Epoch 43: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7810 - loss: 0.6099 - val_accuracy: 0.6600 - val_loss: 0.7880\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7789 - loss: 0.6115\n",
            "Epoch 44: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7785 - loss: 0.6117 - val_accuracy: 0.6600 - val_loss: 0.8080\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7789 - loss: 0.6060\n",
            "Epoch 45: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7783 - loss: 0.6065 - val_accuracy: 0.7000 - val_loss: 0.7323\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7513 - loss: 0.6172\n",
            "Epoch 46: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7516 - loss: 0.6170 - val_accuracy: 0.7100 - val_loss: 0.7715\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.5985\n",
            "Epoch 47: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7745 - loss: 0.5995 - val_accuracy: 0.6400 - val_loss: 0.7609\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7731 - loss: 0.6133\n",
            "Epoch 48: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7732 - loss: 0.6131 - val_accuracy: 0.7200 - val_loss: 0.7170\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7819 - loss: 0.6051\n",
            "Epoch 49: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.6057 - val_accuracy: 0.6800 - val_loss: 0.7233\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7837 - loss: 0.6047\n",
            "Epoch 50: val_accuracy improved from 0.75000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7835 - loss: 0.6049 - val_accuracy: 0.7600 - val_loss: 0.7097\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "25 / 50\n",
            "\n",
            "--- Fold 26 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5135 - loss: 16.0462\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 136ms/step - accuracy: 0.5135 - loss: 15.9620 - val_accuracy: 0.5100 - val_loss: 8.8541\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5178 - loss: 8.4121 \n",
            "Epoch 2: val_accuracy improved from 0.51000 to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5171 - loss: 8.3781 - val_accuracy: 0.5300 - val_loss: 7.1272\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5399 - loss: 6.7988\n",
            "Epoch 3: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5392 - loss: 6.7868 - val_accuracy: 0.5100 - val_loss: 5.8721\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5114 - loss: 5.6243\n",
            "Epoch 4: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5118 - loss: 5.6151 - val_accuracy: 0.5100 - val_loss: 4.9110\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5123 - loss: 4.7165\n",
            "Epoch 5: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5127 - loss: 4.7093 - val_accuracy: 0.5200 - val_loss: 4.1575\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5507 - loss: 4.0049\n",
            "Epoch 6: val_accuracy improved from 0.53000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5509 - loss: 3.9990 - val_accuracy: 0.7300 - val_loss: 3.5446\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5737 - loss: 3.4339\n",
            "Epoch 7: val_accuracy improved from 0.73000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5731 - loss: 3.4295 - val_accuracy: 0.7600 - val_loss: 3.0786\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5574 - loss: 2.9767\n",
            "Epoch 8: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5577 - loss: 2.9728 - val_accuracy: 0.7700 - val_loss: 2.6299\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6015 - loss: 2.5951\n",
            "Epoch 9: val_accuracy improved from 0.77000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6015 - loss: 2.5919 - val_accuracy: 0.8000 - val_loss: 2.3215\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6253 - loss: 2.2756\n",
            "Epoch 10: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6260 - loss: 2.2726 - val_accuracy: 0.6400 - val_loss: 2.0592\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6633 - loss: 2.0232\n",
            "Epoch 11: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6639 - loss: 2.0207 - val_accuracy: 0.7200 - val_loss: 1.8759\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6931 - loss: 1.8047\n",
            "Epoch 12: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6930 - loss: 1.8029 - val_accuracy: 0.5500 - val_loss: 1.7283\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6823 - loss: 1.6328\n",
            "Epoch 13: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6832 - loss: 1.6306 - val_accuracy: 0.7500 - val_loss: 1.5116\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6997 - loss: 1.4777\n",
            "Epoch 14: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6998 - loss: 1.4767 - val_accuracy: 0.7400 - val_loss: 1.3681\n",
            "Epoch 15/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7196 - loss: 1.3491\n",
            "Epoch 15: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7192 - loss: 1.3477 - val_accuracy: 0.6700 - val_loss: 1.3090\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6880 - loss: 1.2607\n",
            "Epoch 16: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6888 - loss: 1.2592 - val_accuracy: 0.7000 - val_loss: 1.2065\n",
            "Epoch 17/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7304 - loss: 1.1372\n",
            "Epoch 17: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7295 - loss: 1.1367 - val_accuracy: 0.7600 - val_loss: 1.1149\n",
            "Epoch 18/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7239 - loss: 1.0860\n",
            "Epoch 18: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7238 - loss: 1.0839 - val_accuracy: 0.7200 - val_loss: 1.0439\n",
            "Epoch 19/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7348 - loss: 0.9965\n",
            "Epoch 19: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7342 - loss: 0.9965 - val_accuracy: 0.7300 - val_loss: 0.9892\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7281 - loss: 0.9546\n",
            "Epoch 20: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7280 - loss: 0.9540 - val_accuracy: 0.6500 - val_loss: 0.9908\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7235 - loss: 0.9198\n",
            "Epoch 21: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7239 - loss: 0.9192 - val_accuracy: 0.7200 - val_loss: 0.9359\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7398 - loss: 0.8675\n",
            "Epoch 22: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7397 - loss: 0.8674 - val_accuracy: 0.7200 - val_loss: 0.9107\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7385 - loss: 0.8438\n",
            "Epoch 23: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7388 - loss: 0.8432 - val_accuracy: 0.6900 - val_loss: 0.8593\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7541 - loss: 0.8102\n",
            "Epoch 24: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 0.8097 - val_accuracy: 0.7500 - val_loss: 0.8147\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7514 - loss: 0.7695\n",
            "Epoch 25: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7515 - loss: 0.7697 - val_accuracy: 0.7100 - val_loss: 0.8265\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7337 - loss: 0.7724\n",
            "Epoch 26: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7341 - loss: 0.7721 - val_accuracy: 0.7100 - val_loss: 0.7869\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7498 - loss: 0.7484\n",
            "Epoch 27: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7495 - loss: 0.7489 - val_accuracy: 0.6800 - val_loss: 0.8262\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7509 - loss: 0.7502\n",
            "Epoch 28: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7505 - loss: 0.7498 - val_accuracy: 0.7300 - val_loss: 0.7472\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7563 - loss: 0.7069\n",
            "Epoch 29: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7563 - loss: 0.7067 - val_accuracy: 0.6600 - val_loss: 0.7944\n",
            "Epoch 29: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "26 / 50\n",
            "\n",
            "--- Fold 27 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5142 - loss: 16.2378\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.5141 - loss: 16.1545 - val_accuracy: 0.4900 - val_loss: 9.2260\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4999 - loss: 8.8242\n",
            "Epoch 2: val_accuracy improved from 0.49000 to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5002 - loss: 8.7743 - val_accuracy: 0.5700 - val_loss: 7.5468\n",
            "Epoch 3/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5109 - loss: 7.2420\n",
            "Epoch 3: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5115 - loss: 7.2038 - val_accuracy: 0.5200 - val_loss: 6.2583\n",
            "Epoch 4/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5035 - loss: 6.0152\n",
            "Epoch 4: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5053 - loss: 5.9902 - val_accuracy: 0.5400 - val_loss: 5.2439\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5102 - loss: 5.0392\n",
            "Epoch 5: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5107 - loss: 5.0314 - val_accuracy: 0.5400 - val_loss: 4.4360\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5220 - loss: 4.2704\n",
            "Epoch 6: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5225 - loss: 4.2642 - val_accuracy: 0.5400 - val_loss: 3.7849\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5701 - loss: 3.6520\n",
            "Epoch 7: val_accuracy improved from 0.57000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5701 - loss: 3.6443 - val_accuracy: 0.7000 - val_loss: 3.2487\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5528 - loss: 3.1503\n",
            "Epoch 8: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5523 - loss: 3.1463 - val_accuracy: 0.5300 - val_loss: 2.8295\n",
            "Epoch 9/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5873 - loss: 2.7335\n",
            "Epoch 9: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5878 - loss: 2.7280 - val_accuracy: 0.6600 - val_loss: 2.4269\n",
            "Epoch 10/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6385 - loss: 2.3740\n",
            "Epoch 10: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6384 - loss: 2.3704 - val_accuracy: 0.6300 - val_loss: 2.1774\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6623 - loss: 2.0996\n",
            "Epoch 11: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6625 - loss: 2.0972 - val_accuracy: 0.7000 - val_loss: 1.9185\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6874 - loss: 1.8644\n",
            "Epoch 12: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 1.8620 - val_accuracy: 0.6100 - val_loss: 1.7566\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6761 - loss: 1.6823\n",
            "Epoch 13: val_accuracy improved from 0.70000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6762 - loss: 1.6806 - val_accuracy: 0.7100 - val_loss: 1.5159\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7069 - loss: 1.4899\n",
            "Epoch 14: val_accuracy improved from 0.71000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7064 - loss: 1.4892 - val_accuracy: 0.7300 - val_loss: 1.4030\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6987 - loss: 1.3739\n",
            "Epoch 15: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6991 - loss: 1.3724 - val_accuracy: 0.6500 - val_loss: 1.3061\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7207 - loss: 1.2447\n",
            "Epoch 16: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7206 - loss: 1.2441 - val_accuracy: 0.6800 - val_loss: 1.2128\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6912 - loss: 1.1892\n",
            "Epoch 17: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6919 - loss: 1.1874 - val_accuracy: 0.6800 - val_loss: 1.1243\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7046 - loss: 1.0924\n",
            "Epoch 18: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7049 - loss: 1.0914 - val_accuracy: 0.7400 - val_loss: 1.0400\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7178 - loss: 1.0213\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7177 - loss: 1.0207 - val_accuracy: 0.7100 - val_loss: 0.9787\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7117 - loss: 0.9640\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7122 - loss: 0.9631 - val_accuracy: 0.6700 - val_loss: 0.9516\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6975 - loss: 0.9354\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6982 - loss: 0.9344 - val_accuracy: 0.7000 - val_loss: 0.9210\n",
            "Epoch 22/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7306 - loss: 0.8633\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7305 - loss: 0.8633 - val_accuracy: 0.7100 - val_loss: 0.8576\n",
            "Epoch 23/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7319 - loss: 0.8358\n",
            "Epoch 23: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7315 - loss: 0.8351 - val_accuracy: 0.7000 - val_loss: 0.8475\n",
            "Epoch 24/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7230 - loss: 0.8048\n",
            "Epoch 24: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7229 - loss: 0.8044 - val_accuracy: 0.7100 - val_loss: 0.8177\n",
            "Epoch 25/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7306 - loss: 0.7688\n",
            "Epoch 25: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7307 - loss: 0.7683 - val_accuracy: 0.6400 - val_loss: 0.8362\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7395 - loss: 0.7574\n",
            "Epoch 26: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7390 - loss: 0.7577 - val_accuracy: 0.6800 - val_loss: 0.7873\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7408 - loss: 0.7426\n",
            "Epoch 27: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7408 - loss: 0.7423 - val_accuracy: 0.7400 - val_loss: 0.7845\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7314 - loss: 0.7311\n",
            "Epoch 28: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7314 - loss: 0.7308 - val_accuracy: 0.7100 - val_loss: 0.7548\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7398 - loss: 0.6922\n",
            "Epoch 29: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7396 - loss: 0.6927 - val_accuracy: 0.6900 - val_loss: 0.7839\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7248 - loss: 0.7166\n",
            "Epoch 30: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7252 - loss: 0.7163 - val_accuracy: 0.7300 - val_loss: 0.7368\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7453 - loss: 0.6832\n",
            "Epoch 31: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7454 - loss: 0.6833 - val_accuracy: 0.6800 - val_loss: 0.7373\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7472 - loss: 0.6817\n",
            "Epoch 32: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7468 - loss: 0.6818 - val_accuracy: 0.7100 - val_loss: 0.7436\n",
            "Epoch 33/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7414 - loss: 0.6718\n",
            "Epoch 33: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7410 - loss: 0.6719 - val_accuracy: 0.7000 - val_loss: 0.7349\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7417 - loss: 0.6738\n",
            "Epoch 34: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7416 - loss: 0.6738 - val_accuracy: 0.7000 - val_loss: 0.7117\n",
            "Epoch 35/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 0.6592\n",
            "Epoch 35: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7489 - loss: 0.6591 - val_accuracy: 0.6900 - val_loss: 0.7212\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7513 - loss: 0.6577\n",
            "Epoch 36: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7512 - loss: 0.6575 - val_accuracy: 0.6800 - val_loss: 0.7410\n",
            "Epoch 37/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7695 - loss: 0.6366\n",
            "Epoch 37: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7686 - loss: 0.6377 - val_accuracy: 0.7200 - val_loss: 0.7284\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 0.6655\n",
            "Epoch 38: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7379 - loss: 0.6655 - val_accuracy: 0.6800 - val_loss: 0.7437\n",
            "Epoch 38: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "27 / 50\n",
            "\n",
            "--- Fold 28 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5044 - loss: 15.8531\n",
            "Epoch 1: val_accuracy improved from -inf to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 160ms/step - accuracy: 0.5042 - loss: 15.7750 - val_accuracy: 0.5900 - val_loss: 9.1106\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5170 - loss: 8.7026\n",
            "Epoch 2: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5177 - loss: 8.6618 - val_accuracy: 0.4600 - val_loss: 7.4565\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5278 - loss: 7.1339\n",
            "Epoch 3: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5279 - loss: 7.1218 - val_accuracy: 0.4300 - val_loss: 6.2065\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5212 - loss: 5.9569\n",
            "Epoch 4: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5216 - loss: 5.9474 - val_accuracy: 0.4500 - val_loss: 5.2255\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5313 - loss: 5.0220\n",
            "Epoch 5: val_accuracy improved from 0.59000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5322 - loss: 5.0144 - val_accuracy: 0.6200 - val_loss: 4.4262\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5776 - loss: 4.2816\n",
            "Epoch 6: val_accuracy improved from 0.62000 to 0.66000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5773 - loss: 4.2727 - val_accuracy: 0.6600 - val_loss: 3.7967\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6108 - loss: 3.6639\n",
            "Epoch 7: val_accuracy improved from 0.66000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6114 - loss: 3.6585 - val_accuracy: 0.6700 - val_loss: 3.2367\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6505 - loss: 3.1600\n",
            "Epoch 8: val_accuracy improved from 0.67000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6507 - loss: 3.1557 - val_accuracy: 0.7200 - val_loss: 2.8171\n",
            "Epoch 9/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6658 - loss: 2.7547\n",
            "Epoch 9: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6666 - loss: 2.7494 - val_accuracy: 0.6900 - val_loss: 2.4549\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7018 - loss: 2.4058\n",
            "Epoch 10: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7013 - loss: 2.4035 - val_accuracy: 0.7000 - val_loss: 2.1991\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7151 - loss: 2.1154\n",
            "Epoch 11: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7148 - loss: 2.1121 - val_accuracy: 0.6700 - val_loss: 1.9400\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6987 - loss: 1.8964\n",
            "Epoch 12: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6993 - loss: 1.8940 - val_accuracy: 0.6900 - val_loss: 1.7427\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7251 - loss: 1.6783\n",
            "Epoch 13: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7251 - loss: 1.6771 - val_accuracy: 0.6500 - val_loss: 1.6250\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7160 - loss: 1.5489\n",
            "Epoch 14: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7163 - loss: 1.5472 - val_accuracy: 0.7100 - val_loss: 1.4379\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7574 - loss: 1.3709\n",
            "Epoch 15: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7568 - loss: 1.3705 - val_accuracy: 0.6600 - val_loss: 1.3561\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7348 - loss: 1.2842\n",
            "Epoch 16: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7344 - loss: 1.2835 - val_accuracy: 0.6700 - val_loss: 1.2336\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7362 - loss: 1.1892\n",
            "Epoch 17: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7361 - loss: 1.1887 - val_accuracy: 0.6700 - val_loss: 1.1395\n",
            "Epoch 18/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7400 - loss: 1.1118\n",
            "Epoch 18: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7404 - loss: 1.1085 - val_accuracy: 0.5800 - val_loss: 1.1575\n",
            "Epoch 19/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7197 - loss: 1.0477\n",
            "Epoch 19: val_accuracy improved from 0.72000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7199 - loss: 1.0457 - val_accuracy: 0.7300 - val_loss: 0.9911\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7454 - loss: 0.9667\n",
            "Epoch 20: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7451 - loss: 0.9665 - val_accuracy: 0.7100 - val_loss: 0.9465\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7523 - loss: 0.9075\n",
            "Epoch 21: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7520 - loss: 0.9073 - val_accuracy: 0.6900 - val_loss: 0.9193\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7626 - loss: 0.8381\n",
            "Epoch 22: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7621 - loss: 0.8387 - val_accuracy: 0.5300 - val_loss: 0.9553\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7418 - loss: 0.8403\n",
            "Epoch 23: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7423 - loss: 0.8396 - val_accuracy: 0.6900 - val_loss: 0.8658\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7466 - loss: 0.7968\n",
            "Epoch 24: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7468 - loss: 0.7964 - val_accuracy: 0.6700 - val_loss: 0.8454\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7587 - loss: 0.7581\n",
            "Epoch 25: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7583 - loss: 0.7585 - val_accuracy: 0.7100 - val_loss: 0.8043\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7508 - loss: 0.7555\n",
            "Epoch 26: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7508 - loss: 0.7551 - val_accuracy: 0.7100 - val_loss: 0.7734\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7709 - loss: 0.7143\n",
            "Epoch 27: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7703 - loss: 0.7146 - val_accuracy: 0.6900 - val_loss: 0.7581\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7673 - loss: 0.6977\n",
            "Epoch 28: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7668 - loss: 0.6980 - val_accuracy: 0.6900 - val_loss: 0.7483\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7531 - loss: 0.6920\n",
            "Epoch 29: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7530 - loss: 0.6920 - val_accuracy: 0.7000 - val_loss: 0.7609\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7337 - loss: 0.7063\n",
            "Epoch 30: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7350 - loss: 0.7048 - val_accuracy: 0.7300 - val_loss: 0.7022\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7685 - loss: 0.6675\n",
            "Epoch 31: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7681 - loss: 0.6677 - val_accuracy: 0.7000 - val_loss: 0.7270\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.6467\n",
            "Epoch 32: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.6467 - val_accuracy: 0.7300 - val_loss: 0.7237\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7604 - loss: 0.6594\n",
            "Epoch 33: val_accuracy improved from 0.73000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7603 - loss: 0.6598 - val_accuracy: 0.7500 - val_loss: 0.6738\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7724 - loss: 0.6321\n",
            "Epoch 34: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.6329 - val_accuracy: 0.6900 - val_loss: 0.7062\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7765 - loss: 0.6392\n",
            "Epoch 35: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7760 - loss: 0.6397 - val_accuracy: 0.6800 - val_loss: 0.7276\n",
            "Epoch 36/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7650 - loss: 0.6274\n",
            "Epoch 36: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7649 - loss: 0.6277 - val_accuracy: 0.7500 - val_loss: 0.6735\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7815 - loss: 0.6181\n",
            "Epoch 37: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7810 - loss: 0.6187 - val_accuracy: 0.6800 - val_loss: 0.7252\n",
            "Epoch 38/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7768 - loss: 0.6359\n",
            "Epoch 38: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7766 - loss: 0.6344 - val_accuracy: 0.6500 - val_loss: 0.6960\n",
            "Epoch 39/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7588 - loss: 0.6463\n",
            "Epoch 39: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7588 - loss: 0.6457 - val_accuracy: 0.7000 - val_loss: 0.6790\n",
            "Epoch 40/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7710 - loss: 0.6281\n",
            "Epoch 40: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7706 - loss: 0.6283 - val_accuracy: 0.6800 - val_loss: 0.6900\n",
            "Epoch 41/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7783 - loss: 0.6087\n",
            "Epoch 41: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7778 - loss: 0.6097 - val_accuracy: 0.7200 - val_loss: 0.6806\n",
            "Epoch 42/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7837 - loss: 0.6055\n",
            "Epoch 42: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7826 - loss: 0.6067 - val_accuracy: 0.6700 - val_loss: 0.7278\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7584 - loss: 0.6341\n",
            "Epoch 43: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7586 - loss: 0.6339 - val_accuracy: 0.6900 - val_loss: 0.6936\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7632 - loss: 0.6186\n",
            "Epoch 44: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7634 - loss: 0.6187 - val_accuracy: 0.6700 - val_loss: 0.6949\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.6055\n",
            "Epoch 45: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7752 - loss: 0.6055 - val_accuracy: 0.6600 - val_loss: 0.7318\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.6196\n",
            "Epoch 46: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7681 - loss: 0.6194 - val_accuracy: 0.7100 - val_loss: 0.6659\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7864 - loss: 0.5999\n",
            "Epoch 47: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7857 - loss: 0.6012 - val_accuracy: 0.7400 - val_loss: 0.6798\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7823 - loss: 0.6140\n",
            "Epoch 48: val_accuracy improved from 0.75000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7822 - loss: 0.6142 - val_accuracy: 0.7600 - val_loss: 0.6487\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7979 - loss: 0.5765\n",
            "Epoch 49: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7970 - loss: 0.5782 - val_accuracy: 0.7300 - val_loss: 0.6909\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7642 - loss: 0.6162\n",
            "Epoch 50: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7643 - loss: 0.6163 - val_accuracy: 0.7100 - val_loss: 0.6778\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "28 / 50\n",
            "\n",
            "--- Fold 29 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4690 - loss: 15.4508\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.4693 - loss: 15.3754 - val_accuracy: 0.4500 - val_loss: 8.8604\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5132 - loss: 8.4120\n",
            "Epoch 2: val_accuracy improved from 0.45000 to 0.46000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5135 - loss: 8.3677 - val_accuracy: 0.4600 - val_loss: 7.0697\n",
            "Epoch 3/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5118 - loss: 6.7435\n",
            "Epoch 3: val_accuracy did not improve from 0.46000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5129 - loss: 6.7177 - val_accuracy: 0.4500 - val_loss: 5.7655\n",
            "Epoch 4/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5153 - loss: 5.5173\n",
            "Epoch 4: val_accuracy improved from 0.46000 to 0.49000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5166 - loss: 5.4977 - val_accuracy: 0.4900 - val_loss: 4.7703\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5492 - loss: 4.5693\n",
            "Epoch 5: val_accuracy improved from 0.49000 to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5494 - loss: 4.5618 - val_accuracy: 0.5700 - val_loss: 3.9936\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5497 - loss: 3.8409\n",
            "Epoch 6: val_accuracy improved from 0.57000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5502 - loss: 3.8349 - val_accuracy: 0.6500 - val_loss: 3.3679\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6028 - loss: 3.2458\n",
            "Epoch 7: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6030 - loss: 3.2413 - val_accuracy: 0.6500 - val_loss: 2.8771\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6142 - loss: 2.7792\n",
            "Epoch 8: val_accuracy improved from 0.65000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6149 - loss: 2.7755 - val_accuracy: 0.7000 - val_loss: 2.4949\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6669 - loss: 2.4093\n",
            "Epoch 9: val_accuracy improved from 0.70000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6675 - loss: 2.4058 - val_accuracy: 0.7400 - val_loss: 2.1072\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6635 - loss: 2.1121\n",
            "Epoch 10: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6637 - loss: 2.1098 - val_accuracy: 0.6700 - val_loss: 1.9002\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6944 - loss: 1.8513\n",
            "Epoch 11: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6946 - loss: 1.8481 - val_accuracy: 0.7000 - val_loss: 1.6653\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7153 - loss: 1.6421\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7153 - loss: 1.6406 - val_accuracy: 0.6600 - val_loss: 1.5321\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7233 - loss: 1.4741\n",
            "Epoch 13: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7231 - loss: 1.4729 - val_accuracy: 0.7400 - val_loss: 1.3586\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7252 - loss: 1.3305\n",
            "Epoch 14: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7244 - loss: 1.3295 - val_accuracy: 0.7100 - val_loss: 1.2251\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7370 - loss: 1.2163\n",
            "Epoch 15: val_accuracy improved from 0.74000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7368 - loss: 1.2156 - val_accuracy: 0.7700 - val_loss: 1.1346\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7538 - loss: 1.1091\n",
            "Epoch 16: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7532 - loss: 1.1091 - val_accuracy: 0.6400 - val_loss: 1.1143\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7351 - loss: 1.0538\n",
            "Epoch 17: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7351 - loss: 1.0534 - val_accuracy: 0.6800 - val_loss: 1.0171\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 0.9857\n",
            "Epoch 18: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7285 - loss: 0.9857 - val_accuracy: 0.7300 - val_loss: 0.9477\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7285 - loss: 0.9454\n",
            "Epoch 19: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7289 - loss: 0.9448 - val_accuracy: 0.6900 - val_loss: 0.8984\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7340 - loss: 0.8876\n",
            "Epoch 20: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7341 - loss: 0.8874 - val_accuracy: 0.7300 - val_loss: 0.8518\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7566 - loss: 0.8285\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7558 - loss: 0.8288 - val_accuracy: 0.7300 - val_loss: 0.8091\n",
            "Epoch 22/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7458 - loss: 0.8103\n",
            "Epoch 22: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7459 - loss: 0.8102 - val_accuracy: 0.7700 - val_loss: 0.7810\n",
            "Epoch 23/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7334 - loss: 0.7918\n",
            "Epoch 23: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7338 - loss: 0.7910 - val_accuracy: 0.7300 - val_loss: 0.7732\n",
            "Epoch 24/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7664 - loss: 0.7430\n",
            "Epoch 24: val_accuracy improved from 0.77000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7660 - loss: 0.7432 - val_accuracy: 0.7800 - val_loss: 0.7507\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7470 - loss: 0.7342\n",
            "Epoch 25: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7472 - loss: 0.7338 - val_accuracy: 0.7100 - val_loss: 0.7441\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7459 - loss: 0.7249\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7461 - loss: 0.7247 - val_accuracy: 0.7100 - val_loss: 0.7523\n",
            "Epoch 27/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7584 - loss: 0.6985\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7583 - loss: 0.6986 - val_accuracy: 0.7400 - val_loss: 0.7245\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7824 - loss: 0.6658\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7819 - loss: 0.6665 - val_accuracy: 0.6400 - val_loss: 0.7557\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7407 - loss: 0.6888\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7408 - loss: 0.6890 - val_accuracy: 0.7400 - val_loss: 0.7014\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7677 - loss: 0.6676\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7676 - loss: 0.6675 - val_accuracy: 0.7300 - val_loss: 0.7099\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7542 - loss: 0.6697\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7547 - loss: 0.6692 - val_accuracy: 0.7700 - val_loss: 0.6881\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.6475\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7723 - loss: 0.6481 - val_accuracy: 0.6300 - val_loss: 0.7578\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7489 - loss: 0.6693\n",
            "Epoch 33: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7486 - loss: 0.6693 - val_accuracy: 0.7100 - val_loss: 0.6827\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7685 - loss: 0.6432\n",
            "Epoch 34: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7681 - loss: 0.6436 - val_accuracy: 0.7300 - val_loss: 0.6549\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7651 - loss: 0.6329\n",
            "Epoch 35: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7653 - loss: 0.6329 - val_accuracy: 0.7000 - val_loss: 0.7182\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.6353\n",
            "Epoch 36: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7677 - loss: 0.6354 - val_accuracy: 0.7500 - val_loss: 0.6570\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7766 - loss: 0.6145\n",
            "Epoch 37: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7763 - loss: 0.6150 - val_accuracy: 0.7600 - val_loss: 0.6482\n",
            "Epoch 38/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7694 - loss: 0.6263\n",
            "Epoch 38: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7689 - loss: 0.6266 - val_accuracy: 0.6900 - val_loss: 0.7115\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7731 - loss: 0.6120\n",
            "Epoch 39: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7731 - loss: 0.6125 - val_accuracy: 0.7000 - val_loss: 0.7211\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7784 - loss: 0.6164\n",
            "Epoch 40: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7783 - loss: 0.6163 - val_accuracy: 0.7900 - val_loss: 0.6350\n",
            "Epoch 41/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7828 - loss: 0.6136\n",
            "Epoch 41: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7821 - loss: 0.6144 - val_accuracy: 0.7600 - val_loss: 0.6441\n",
            "Epoch 42/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7755 - loss: 0.6082\n",
            "Epoch 42: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7756 - loss: 0.6083 - val_accuracy: 0.7100 - val_loss: 0.6800\n",
            "Epoch 43/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7586 - loss: 0.6189\n",
            "Epoch 43: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7595 - loss: 0.6184 - val_accuracy: 0.7000 - val_loss: 0.6989\n",
            "Epoch 44/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7777 - loss: 0.6023\n",
            "Epoch 44: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7758 - loss: 0.6045 - val_accuracy: 0.5300 - val_loss: 0.8763\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7535 - loss: 0.6464\n",
            "Epoch 45: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7534 - loss: 0.6464 - val_accuracy: 0.7600 - val_loss: 0.6235\n",
            "Epoch 46/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7817 - loss: 0.6063\n",
            "Epoch 46: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7815 - loss: 0.6066 - val_accuracy: 0.7000 - val_loss: 0.6833\n",
            "Epoch 47/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7861 - loss: 0.6072\n",
            "Epoch 47: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7857 - loss: 0.6080 - val_accuracy: 0.7000 - val_loss: 0.6715\n",
            "Epoch 48/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7745 - loss: 0.6168\n",
            "Epoch 48: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7743 - loss: 0.6166 - val_accuracy: 0.7300 - val_loss: 0.6560\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7856 - loss: 0.6070\n",
            "Epoch 49: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7855 - loss: 0.6069 - val_accuracy: 0.7100 - val_loss: 0.6663\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7877 - loss: 0.6116\n",
            "Epoch 50: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7876 - loss: 0.6114 - val_accuracy: 0.6400 - val_loss: 0.7768\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "29 / 50\n",
            "\n",
            "--- Fold 30 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4875 - loss: 15.2981\n",
            "Epoch 1: val_accuracy improved from -inf to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 129ms/step - accuracy: 0.4876 - loss: 15.2304 - val_accuracy: 0.5700 - val_loss: 9.3765\n",
            "Epoch 2/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5074 - loss: 8.9794\n",
            "Epoch 2: val_accuracy improved from 0.57000 to 0.63000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5073 - loss: 8.9561 - val_accuracy: 0.6300 - val_loss: 7.7824\n",
            "Epoch 3/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4861 - loss: 7.5035\n",
            "Epoch 3: val_accuracy did not improve from 0.63000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4887 - loss: 7.4601 - val_accuracy: 0.6200 - val_loss: 6.5387\n",
            "Epoch 4/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5065 - loss: 6.3081\n",
            "Epoch 4: val_accuracy improved from 0.63000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5074 - loss: 6.2787 - val_accuracy: 0.6500 - val_loss: 5.5417\n",
            "Epoch 5/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5210 - loss: 5.3475\n",
            "Epoch 5: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5222 - loss: 5.3357 - val_accuracy: 0.5200 - val_loss: 4.7400\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5763 - loss: 4.5762\n",
            "Epoch 6: val_accuracy improved from 0.65000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5762 - loss: 4.5668 - val_accuracy: 0.7500 - val_loss: 4.0599\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6050 - loss: 3.9439\n",
            "Epoch 7: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6050 - loss: 3.9386 - val_accuracy: 0.6500 - val_loss: 3.5264\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6343 - loss: 3.4155\n",
            "Epoch 8: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6344 - loss: 3.4112 - val_accuracy: 0.7200 - val_loss: 3.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6390 - loss: 3.0008\n",
            "Epoch 9: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6393 - loss: 2.9970 - val_accuracy: 0.7300 - val_loss: 2.6524\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6781 - loss: 2.6228\n",
            "Epoch 10: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6784 - loss: 2.6196 - val_accuracy: 0.7300 - val_loss: 2.3341\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6986 - loss: 2.3177\n",
            "Epoch 11: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6983 - loss: 2.3154 - val_accuracy: 0.6700 - val_loss: 2.1259\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7151 - loss: 2.0567\n",
            "Epoch 12: val_accuracy improved from 0.75000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7144 - loss: 2.0552 - val_accuracy: 0.7600 - val_loss: 1.8726\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7068 - loss: 1.8550\n",
            "Epoch 13: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7072 - loss: 1.8531 - val_accuracy: 0.7400 - val_loss: 1.6751\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7110 - loss: 1.6833\n",
            "Epoch 14: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7111 - loss: 1.6818 - val_accuracy: 0.6700 - val_loss: 1.5893\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7293 - loss: 1.5258\n",
            "Epoch 15: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7288 - loss: 1.5248 - val_accuracy: 0.5600 - val_loss: 1.5062\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7032 - loss: 1.4136\n",
            "Epoch 16: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7040 - loss: 1.4119 - val_accuracy: 0.7100 - val_loss: 1.3329\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7414 - loss: 1.2736\n",
            "Epoch 17: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7411 - loss: 1.2731 - val_accuracy: 0.7600 - val_loss: 1.1908\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7298 - loss: 1.1898\n",
            "Epoch 18: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7298 - loss: 1.1890 - val_accuracy: 0.7200 - val_loss: 1.1109\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7385 - loss: 1.1152\n",
            "Epoch 19: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7380 - loss: 1.1149 - val_accuracy: 0.7500 - val_loss: 1.0628\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7438 - loss: 1.0375\n",
            "Epoch 20: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7437 - loss: 1.0372 - val_accuracy: 0.7200 - val_loss: 0.9815\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7472 - loss: 0.9737\n",
            "Epoch 21: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7474 - loss: 0.9731 - val_accuracy: 0.7000 - val_loss: 0.9640\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7384 - loss: 0.9345\n",
            "Epoch 22: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7381 - loss: 0.9344 - val_accuracy: 0.6800 - val_loss: 0.9266\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7452 - loss: 0.8818\n",
            "Epoch 23: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7450 - loss: 0.8817 - val_accuracy: 0.7700 - val_loss: 0.8445\n",
            "Epoch 24/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 0.8564\n",
            "Epoch 24: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7484 - loss: 0.8553 - val_accuracy: 0.6800 - val_loss: 0.8710\n",
            "Epoch 25/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7587 - loss: 0.7971\n",
            "Epoch 25: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7573 - loss: 0.7983 - val_accuracy: 0.7000 - val_loss: 0.8081\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7536 - loss: 0.7966\n",
            "Epoch 26: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7533 - loss: 0.7966 - val_accuracy: 0.6800 - val_loss: 0.9051\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7409 - loss: 0.7864\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7411 - loss: 0.7856 - val_accuracy: 0.6500 - val_loss: 0.8339\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7672 - loss: 0.7305\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.7307 - val_accuracy: 0.6700 - val_loss: 0.8211\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7467 - loss: 0.7422\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7471 - loss: 0.7416 - val_accuracy: 0.7200 - val_loss: 0.7611\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7428 - loss: 0.7116\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7426 - loss: 0.7122 - val_accuracy: 0.6600 - val_loss: 0.7699\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7556 - loss: 0.6991\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7548 - loss: 0.6999 - val_accuracy: 0.7100 - val_loss: 0.7193\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7458 - loss: 0.6878\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7461 - loss: 0.6876 - val_accuracy: 0.7400 - val_loss: 0.6885\n",
            "Epoch 33/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7477 - loss: 0.6819\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7477 - loss: 0.6816 - val_accuracy: 0.7300 - val_loss: 0.6936\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7534 - loss: 0.6747\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7536 - loss: 0.6747 - val_accuracy: 0.7300 - val_loss: 0.6999\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7634 - loss: 0.6578\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7631 - loss: 0.6579 - val_accuracy: 0.6900 - val_loss: 0.6835\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7693 - loss: 0.6317\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7689 - loss: 0.6322 - val_accuracy: 0.7400 - val_loss: 0.6627\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7590 - loss: 0.6552\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7590 - loss: 0.6552 - val_accuracy: 0.7400 - val_loss: 0.6625\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7666 - loss: 0.6415\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7663 - loss: 0.6417 - val_accuracy: 0.7000 - val_loss: 0.7205\n",
            "Epoch 39/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7635 - loss: 0.6449\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7630 - loss: 0.6451 - val_accuracy: 0.7500 - val_loss: 0.6673\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7623 - loss: 0.6422\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7621 - loss: 0.6425 - val_accuracy: 0.7200 - val_loss: 0.6836\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7827 - loss: 0.6324\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7823 - loss: 0.6328 - val_accuracy: 0.7400 - val_loss: 0.6516\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 0.6278\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7481 - loss: 0.6283 - val_accuracy: 0.7500 - val_loss: 0.6533\n",
            "Epoch 43/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7718 - loss: 0.6179\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7712 - loss: 0.6192 - val_accuracy: 0.7700 - val_loss: 0.6269\n",
            "Epoch 43: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "30 / 50\n",
            "\n",
            "--- Fold 31 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5069 - loss: 16.6921\n",
            "Epoch 1: val_accuracy improved from -inf to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - accuracy: 0.5070 - loss: 16.6031 - val_accuracy: 0.5400 - val_loss: 9.2574\n",
            "Epoch 2/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5068 - loss: 8.8143\n",
            "Epoch 2: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5071 - loss: 8.8063 - val_accuracy: 0.4500 - val_loss: 7.5799\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5184 - loss: 7.2461\n",
            "Epoch 3: val_accuracy improved from 0.54000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5190 - loss: 7.2336 - val_accuracy: 0.6500 - val_loss: 6.2842\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5408 - loss: 6.0266\n",
            "Epoch 4: val_accuracy improved from 0.65000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5412 - loss: 6.0118 - val_accuracy: 0.7800 - val_loss: 5.2564\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5806 - loss: 5.0505\n",
            "Epoch 5: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5809 - loss: 5.0427 - val_accuracy: 0.6900 - val_loss: 4.4383\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5613 - loss: 4.2937\n",
            "Epoch 6: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5621 - loss: 4.2839 - val_accuracy: 0.7500 - val_loss: 3.7564\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5831 - loss: 3.6622\n",
            "Epoch 7: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5831 - loss: 3.6573 - val_accuracy: 0.7300 - val_loss: 3.2215\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6171 - loss: 3.1449\n",
            "Epoch 8: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6173 - loss: 3.1406 - val_accuracy: 0.6300 - val_loss: 2.8196\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6513 - loss: 2.7188\n",
            "Epoch 9: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6512 - loss: 2.7156 - val_accuracy: 0.5600 - val_loss: 2.4831\n",
            "Epoch 10/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6741 - loss: 2.3840\n",
            "Epoch 10: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6727 - loss: 2.3806 - val_accuracy: 0.7600 - val_loss: 2.1315\n",
            "Epoch 11/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6744 - loss: 2.1092\n",
            "Epoch 11: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6744 - loss: 2.1082 - val_accuracy: 0.7900 - val_loss: 1.8894\n",
            "Epoch 12/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6878 - loss: 1.8677\n",
            "Epoch 12: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6871 - loss: 1.8646 - val_accuracy: 0.7700 - val_loss: 1.6714\n",
            "Epoch 13/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6819 - loss: 1.6830\n",
            "Epoch 13: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6818 - loss: 1.6797 - val_accuracy: 0.6600 - val_loss: 1.5834\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7153 - loss: 1.5252\n",
            "Epoch 14: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7141 - loss: 1.5238 - val_accuracy: 0.7700 - val_loss: 1.3846\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7057 - loss: 1.3865\n",
            "Epoch 15: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7056 - loss: 1.3856 - val_accuracy: 0.7700 - val_loss: 1.2626\n",
            "Epoch 16/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6959 - loss: 1.2738\n",
            "Epoch 16: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6966 - loss: 1.2725 - val_accuracy: 0.7100 - val_loss: 1.1827\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7202 - loss: 1.1902\n",
            "Epoch 17: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7201 - loss: 1.1892 - val_accuracy: 0.6900 - val_loss: 1.1213\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7081 - loss: 1.1136\n",
            "Epoch 18: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7081 - loss: 1.1130 - val_accuracy: 0.7500 - val_loss: 1.0500\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7032 - loss: 1.0481\n",
            "Epoch 19: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7035 - loss: 1.0473 - val_accuracy: 0.5400 - val_loss: 1.0863\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7086 - loss: 0.9910\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7089 - loss: 0.9903 - val_accuracy: 0.7200 - val_loss: 0.9459\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7237 - loss: 0.9363\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7240 - loss: 0.9356 - val_accuracy: 0.7300 - val_loss: 0.8949\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7352 - loss: 0.8823\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7347 - loss: 0.8825 - val_accuracy: 0.7700 - val_loss: 0.8801\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7181 - loss: 0.8680\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7184 - loss: 0.8674 - val_accuracy: 0.7300 - val_loss: 0.8030\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6935 - loss: 0.8650\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6940 - loss: 0.8642 - val_accuracy: 0.7000 - val_loss: 0.8311\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7408 - loss: 0.7905\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7407 - loss: 0.7902 - val_accuracy: 0.7600 - val_loss: 0.7755\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7364 - loss: 0.7721\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7357 - loss: 0.7724 - val_accuracy: 0.7500 - val_loss: 0.7693\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7362 - loss: 0.7502\n",
            "Epoch 27: val_accuracy improved from 0.79000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7360 - loss: 0.7503 - val_accuracy: 0.8000 - val_loss: 0.7320\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7284 - loss: 0.7477\n",
            "Epoch 28: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7286 - loss: 0.7475 - val_accuracy: 0.7100 - val_loss: 0.7421\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7439 - loss: 0.7187\n",
            "Epoch 29: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7437 - loss: 0.7188 - val_accuracy: 0.7900 - val_loss: 0.6862\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7304 - loss: 0.7175\n",
            "Epoch 30: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7307 - loss: 0.7171 - val_accuracy: 0.7300 - val_loss: 0.7094\n",
            "Epoch 31/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7376 - loss: 0.7117\n",
            "Epoch 31: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7380 - loss: 0.7104 - val_accuracy: 0.6300 - val_loss: 0.7580\n",
            "Epoch 32/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7358 - loss: 0.6902\n",
            "Epoch 32: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7356 - loss: 0.6905 - val_accuracy: 0.7600 - val_loss: 0.6758\n",
            "Epoch 33/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7391 - loss: 0.6955\n",
            "Epoch 33: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7389 - loss: 0.6952 - val_accuracy: 0.5900 - val_loss: 0.7806\n",
            "Epoch 34/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7413 - loss: 0.6796\n",
            "Epoch 34: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7413 - loss: 0.6796 - val_accuracy: 0.6700 - val_loss: 0.7617\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7629 - loss: 0.6525\n",
            "Epoch 35: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7625 - loss: 0.6526 - val_accuracy: 0.7600 - val_loss: 0.6577\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7465 - loss: 0.6696\n",
            "Epoch 36: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7462 - loss: 0.6701 - val_accuracy: 0.8000 - val_loss: 0.6428\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7460 - loss: 0.6633\n",
            "Epoch 37: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7459 - loss: 0.6634 - val_accuracy: 0.7900 - val_loss: 0.6637\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 0.6423\n",
            "Epoch 38: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7544 - loss: 0.6430 - val_accuracy: 0.7400 - val_loss: 0.6980\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7536 - loss: 0.6526\n",
            "Epoch 39: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7534 - loss: 0.6526 - val_accuracy: 0.7600 - val_loss: 0.6488\n",
            "Epoch 40/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7417 - loss: 0.6556\n",
            "Epoch 40: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7425 - loss: 0.6551 - val_accuracy: 0.7800 - val_loss: 0.6368\n",
            "Epoch 41/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7598 - loss: 0.6385\n",
            "Epoch 41: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7591 - loss: 0.6393 - val_accuracy: 0.6500 - val_loss: 0.7132\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7544 - loss: 0.6431\n",
            "Epoch 42: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7544 - loss: 0.6432 - val_accuracy: 0.6200 - val_loss: 0.7772\n",
            "Epoch 43/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7425 - loss: 0.6441\n",
            "Epoch 43: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7428 - loss: 0.6437 - val_accuracy: 0.7400 - val_loss: 0.6819\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7479 - loss: 0.6196\n",
            "Epoch 44: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7475 - loss: 0.6204 - val_accuracy: 0.7100 - val_loss: 0.6961\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7775 - loss: 0.6178\n",
            "Epoch 45: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7770 - loss: 0.6182 - val_accuracy: 0.7300 - val_loss: 0.6529\n",
            "Epoch 46/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7604 - loss: 0.6208\n",
            "Epoch 46: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7600 - loss: 0.6218 - val_accuracy: 0.7500 - val_loss: 0.6661\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7502 - loss: 0.6460\n",
            "Epoch 47: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7505 - loss: 0.6458 - val_accuracy: 0.7800 - val_loss: 0.6503\n",
            "Epoch 47: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "31 / 50\n",
            "\n",
            "--- Fold 32 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.4905 - loss: 15.4594\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 148ms/step - accuracy: 0.4908 - loss: 15.3821 - val_accuracy: 0.5000 - val_loss: 8.7227\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5135 - loss: 8.2843\n",
            "Epoch 2: val_accuracy improved from 0.50000 to 0.51000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5134 - loss: 8.2313 - val_accuracy: 0.5100 - val_loss: 6.9414\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5186 - loss: 6.6082\n",
            "Epoch 3: val_accuracy did not improve from 0.51000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5188 - loss: 6.5958 - val_accuracy: 0.5000 - val_loss: 5.6593\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5129 - loss: 5.4081\n",
            "Epoch 4: val_accuracy did not improve from 0.51000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5129 - loss: 5.3988 - val_accuracy: 0.5100 - val_loss: 4.6876\n",
            "Epoch 5/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5091 - loss: 4.5135\n",
            "Epoch 5: val_accuracy did not improve from 0.51000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5094 - loss: 4.4873 - val_accuracy: 0.5000 - val_loss: 3.9346\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5129 - loss: 3.7862\n",
            "Epoch 6: val_accuracy did not improve from 0.51000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5131 - loss: 3.7775 - val_accuracy: 0.5100 - val_loss: 3.3416\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5079 - loss: 3.2211\n",
            "Epoch 7: val_accuracy did not improve from 0.51000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5086 - loss: 3.2165 - val_accuracy: 0.5000 - val_loss: 2.8697\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5291 - loss: 2.7716\n",
            "Epoch 8: val_accuracy improved from 0.51000 to 0.52000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5293 - loss: 2.7680 - val_accuracy: 0.5200 - val_loss: 2.4898\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5469 - loss: 2.4156\n",
            "Epoch 9: val_accuracy improved from 0.52000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5470 - loss: 2.4125 - val_accuracy: 0.6700 - val_loss: 2.1670\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5272 - loss: 2.1218\n",
            "Epoch 10: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5285 - loss: 2.1192 - val_accuracy: 0.5300 - val_loss: 1.9261\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6014 - loss: 1.8684\n",
            "Epoch 11: val_accuracy improved from 0.67000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6016 - loss: 1.8653 - val_accuracy: 0.7500 - val_loss: 1.6283\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6409 - loss: 1.6592\n",
            "Epoch 12: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6408 - loss: 1.6575 - val_accuracy: 0.7200 - val_loss: 1.4782\n",
            "Epoch 13/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6692 - loss: 1.4928\n",
            "Epoch 13: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6699 - loss: 1.4904 - val_accuracy: 0.7700 - val_loss: 1.3393\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6931 - loss: 1.3547\n",
            "Epoch 14: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6933 - loss: 1.3534 - val_accuracy: 0.7100 - val_loss: 1.2788\n",
            "Epoch 15/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6690 - loss: 1.2575\n",
            "Epoch 15: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6700 - loss: 1.2549 - val_accuracy: 0.7500 - val_loss: 1.1524\n",
            "Epoch 16/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7276 - loss: 1.1353\n",
            "Epoch 16: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7268 - loss: 1.1349 - val_accuracy: 0.7300 - val_loss: 1.0584\n",
            "Epoch 17/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7129 - loss: 1.0678\n",
            "Epoch 17: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7136 - loss: 1.0643 - val_accuracy: 0.7200 - val_loss: 0.9906\n",
            "Epoch 18/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7328 - loss: 0.9786\n",
            "Epoch 18: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7325 - loss: 0.9778 - val_accuracy: 0.6300 - val_loss: 0.9993\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7169 - loss: 0.9443\n",
            "Epoch 19: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7171 - loss: 0.9436 - val_accuracy: 0.7500 - val_loss: 0.8963\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7277 - loss: 0.9064\n",
            "Epoch 20: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7280 - loss: 0.9055 - val_accuracy: 0.7300 - val_loss: 0.8574\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7200 - loss: 0.8533\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7201 - loss: 0.8528 - val_accuracy: 0.7600 - val_loss: 0.8283\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7492 - loss: 0.7962\n",
            "Epoch 22: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7487 - loss: 0.7965 - val_accuracy: 0.7000 - val_loss: 0.8049\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7325 - loss: 0.7800\n",
            "Epoch 23: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7328 - loss: 0.7796 - val_accuracy: 0.7200 - val_loss: 0.7910\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7391 - loss: 0.7565\n",
            "Epoch 24: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7388 - loss: 0.7566 - val_accuracy: 0.7300 - val_loss: 0.7829\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7519 - loss: 0.7256\n",
            "Epoch 25: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7518 - loss: 0.7253 - val_accuracy: 0.7300 - val_loss: 0.7421\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7430 - loss: 0.7222\n",
            "Epoch 26: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7427 - loss: 0.7222 - val_accuracy: 0.6600 - val_loss: 0.7781\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7528 - loss: 0.6987\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7529 - loss: 0.6985 - val_accuracy: 0.6900 - val_loss: 0.7415\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7464 - loss: 0.7023\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7463 - loss: 0.7019 - val_accuracy: 0.7100 - val_loss: 0.7307\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7591 - loss: 0.6726\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7586 - loss: 0.6727 - val_accuracy: 0.7000 - val_loss: 0.7106\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7455 - loss: 0.6634\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7449 - loss: 0.6643 - val_accuracy: 0.7400 - val_loss: 0.7233\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7546 - loss: 0.6654\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7546 - loss: 0.6655 - val_accuracy: 0.6800 - val_loss: 0.7281\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7645 - loss: 0.6416\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7647 - loss: 0.6416 - val_accuracy: 0.7100 - val_loss: 0.7205\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7572 - loss: 0.6438\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7571 - loss: 0.6438 - val_accuracy: 0.7500 - val_loss: 0.6587\n",
            "Epoch 33: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "32 / 50\n",
            "\n",
            "--- Fold 33 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4953 - loss: 17.0929\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 146ms/step - accuracy: 0.4953 - loss: 16.9992 - val_accuracy: 0.5100 - val_loss: 9.3886\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5110 - loss: 8.9831 \n",
            "Epoch 2: val_accuracy improved from 0.51000 to 0.58000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5108 - loss: 8.9512 - val_accuracy: 0.5800 - val_loss: 7.7551\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5043 - loss: 7.4332\n",
            "Epoch 3: val_accuracy improved from 0.58000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5049 - loss: 7.4209 - val_accuracy: 0.6200 - val_loss: 6.4888\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5183 - loss: 6.2371\n",
            "Epoch 4: val_accuracy did not improve from 0.62000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5183 - loss: 6.2275 - val_accuracy: 0.5800 - val_loss: 5.4883\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5408 - loss: 5.2869\n",
            "Epoch 5: val_accuracy did not improve from 0.62000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5407 - loss: 5.2792 - val_accuracy: 0.5600 - val_loss: 4.6884\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5559 - loss: 4.5201\n",
            "Epoch 6: val_accuracy did not improve from 0.62000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5564 - loss: 4.5138 - val_accuracy: 0.6100 - val_loss: 4.0188\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5713 - loss: 3.8977\n",
            "Epoch 7: val_accuracy improved from 0.62000 to 0.69000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5710 - loss: 3.8928 - val_accuracy: 0.6900 - val_loss: 3.5034\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5928 - loss: 3.3873\n",
            "Epoch 8: val_accuracy did not improve from 0.69000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5933 - loss: 3.3829 - val_accuracy: 0.6900 - val_loss: 3.0293\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6266 - loss: 2.9564\n",
            "Epoch 9: val_accuracy did not improve from 0.69000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6263 - loss: 2.9531 - val_accuracy: 0.6700 - val_loss: 2.6527\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6736 - loss: 2.5947\n",
            "Epoch 10: val_accuracy improved from 0.69000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6734 - loss: 2.5919 - val_accuracy: 0.7400 - val_loss: 2.3172\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6805 - loss: 2.3005\n",
            "Epoch 11: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6804 - loss: 2.2981 - val_accuracy: 0.6900 - val_loss: 2.1095\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6851 - loss: 2.0554\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6853 - loss: 2.0536 - val_accuracy: 0.6900 - val_loss: 1.9141\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7131 - loss: 1.8334\n",
            "Epoch 13: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7132 - loss: 1.8317 - val_accuracy: 0.7400 - val_loss: 1.6832\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7033 - loss: 1.6695\n",
            "Epoch 14: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7039 - loss: 1.6669 - val_accuracy: 0.6200 - val_loss: 1.5987\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7046 - loss: 1.5521\n",
            "Epoch 15: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7054 - loss: 1.5497 - val_accuracy: 0.7100 - val_loss: 1.4422\n",
            "Epoch 16/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7342 - loss: 1.3758\n",
            "Epoch 16: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7339 - loss: 1.3739 - val_accuracy: 0.7100 - val_loss: 1.3039\n",
            "Epoch 17/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7300 - loss: 1.2775\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7300 - loss: 1.2772 - val_accuracy: 0.6700 - val_loss: 1.2473\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7332 - loss: 1.1865\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7328 - loss: 1.1858 - val_accuracy: 0.6000 - val_loss: 1.2026\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7115 - loss: 1.1404\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7119 - loss: 1.1392 - val_accuracy: 0.7000 - val_loss: 1.0774\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7392 - loss: 1.0430\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7394 - loss: 1.0423 - val_accuracy: 0.6900 - val_loss: 0.9982\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7435 - loss: 0.9766\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7431 - loss: 0.9769 - val_accuracy: 0.6200 - val_loss: 1.0179\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7258 - loss: 0.9496\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7260 - loss: 0.9492 - val_accuracy: 0.5800 - val_loss: 0.9961\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7298 - loss: 0.9008\n",
            "Epoch 23: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7298 - loss: 0.9003 - val_accuracy: 0.6700 - val_loss: 0.8939\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7479 - loss: 0.8562\n",
            "Epoch 24: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7478 - loss: 0.8561 - val_accuracy: 0.7300 - val_loss: 0.8463\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7609 - loss: 0.8134\n",
            "Epoch 25: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.8142 - val_accuracy: 0.7000 - val_loss: 0.8677\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7350 - loss: 0.8068\n",
            "Epoch 26: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7352 - loss: 0.8063 - val_accuracy: 0.7100 - val_loss: 0.7918\n",
            "Epoch 27/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7471 - loss: 0.7708\n",
            "Epoch 27: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7468 - loss: 0.7707 - val_accuracy: 0.7400 - val_loss: 0.7747\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7547 - loss: 0.7485\n",
            "Epoch 28: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7547 - loss: 0.7485 - val_accuracy: 0.7300 - val_loss: 0.7776\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7516 - loss: 0.7472\n",
            "Epoch 29: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7521 - loss: 0.7466 - val_accuracy: 0.7000 - val_loss: 0.7456\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7627 - loss: 0.7098\n",
            "Epoch 30: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7620 - loss: 0.7105 - val_accuracy: 0.7100 - val_loss: 0.7479\n",
            "Epoch 30: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "33 / 50\n",
            "\n",
            "--- Fold 34 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5280 - loss: 19.8603\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 154ms/step - accuracy: 0.5275 - loss: 19.7330 - val_accuracy: 0.5300 - val_loss: 9.6017\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4969 - loss: 9.2655 \n",
            "Epoch 2: val_accuracy improved from 0.53000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4964 - loss: 9.2386 - val_accuracy: 0.6000 - val_loss: 8.2239\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4857 - loss: 7.9465\n",
            "Epoch 3: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4858 - loss: 7.9359 - val_accuracy: 0.5400 - val_loss: 7.1203\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5124 - loss: 6.8911\n",
            "Epoch 4: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5120 - loss: 6.8824 - val_accuracy: 0.5300 - val_loss: 6.2102\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5015 - loss: 6.0189\n",
            "Epoch 5: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5020 - loss: 6.0116 - val_accuracy: 0.6000 - val_loss: 5.4500\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5075 - loss: 5.2894\n",
            "Epoch 6: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5077 - loss: 5.2833 - val_accuracy: 0.5300 - val_loss: 4.8093\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5115 - loss: 4.6724\n",
            "Epoch 7: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5119 - loss: 4.6671 - val_accuracy: 0.5300 - val_loss: 4.2645\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5303 - loss: 4.1476\n",
            "Epoch 8: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5301 - loss: 4.1432 - val_accuracy: 0.5200 - val_loss: 3.7988\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5398 - loss: 3.6969\n",
            "Epoch 9: val_accuracy improved from 0.60000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5395 - loss: 3.6931 - val_accuracy: 0.6100 - val_loss: 3.3981\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5518 - loss: 3.3100\n",
            "Epoch 10: val_accuracy improved from 0.61000 to 0.68000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5516 - loss: 3.3068 - val_accuracy: 0.6800 - val_loss: 3.0505\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5592 - loss: 2.9741\n",
            "Epoch 11: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5593 - loss: 2.9713 - val_accuracy: 0.5700 - val_loss: 2.7492\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 2.6719\n",
            "Epoch 12: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6098 - loss: 2.6697 - val_accuracy: 0.6200 - val_loss: 2.4841\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6332 - loss: 2.4175\n",
            "Epoch 13: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6334 - loss: 2.4154 - val_accuracy: 0.5700 - val_loss: 2.2735\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6742 - loss: 2.1793\n",
            "Epoch 14: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6740 - loss: 2.1770 - val_accuracy: 0.5400 - val_loss: 2.0917\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6531 - loss: 2.0159\n",
            "Epoch 15: val_accuracy improved from 0.68000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6533 - loss: 2.0141 - val_accuracy: 0.7600 - val_loss: 1.8271\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6912 - loss: 1.8325\n",
            "Epoch 16: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6912 - loss: 1.8312 - val_accuracy: 0.7000 - val_loss: 1.7044\n",
            "Epoch 17/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7197 - loss: 1.6511\n",
            "Epoch 17: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7192 - loss: 1.6496 - val_accuracy: 0.7600 - val_loss: 1.5882\n",
            "Epoch 18/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7161 - loss: 1.5462\n",
            "Epoch 18: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7162 - loss: 1.5455 - val_accuracy: 0.7300 - val_loss: 1.4738\n",
            "Epoch 19/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7035 - loss: 1.4502\n",
            "Epoch 19: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7043 - loss: 1.4456 - val_accuracy: 0.7700 - val_loss: 1.3461\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7095 - loss: 1.3519\n",
            "Epoch 20: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7101 - loss: 1.3501 - val_accuracy: 0.7300 - val_loss: 1.2957\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7311 - loss: 1.2408\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7307 - loss: 1.2404 - val_accuracy: 0.7000 - val_loss: 1.2205\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7331 - loss: 1.1561\n",
            "Epoch 22: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7331 - loss: 1.1556 - val_accuracy: 0.7100 - val_loss: 1.1519\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7104 - loss: 1.1381\n",
            "Epoch 23: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7110 - loss: 1.1364 - val_accuracy: 0.6700 - val_loss: 1.1118\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7614 - loss: 1.0318\n",
            "Epoch 24: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7606 - loss: 1.0322 - val_accuracy: 0.7600 - val_loss: 1.0134\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7509 - loss: 0.9867\n",
            "Epoch 25: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7504 - loss: 0.9866 - val_accuracy: 0.7200 - val_loss: 0.9941\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 0.9237\n",
            "Epoch 26: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7545 - loss: 0.9244 - val_accuracy: 0.7500 - val_loss: 0.9397\n",
            "Epoch 27/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7525 - loss: 0.9032\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7508 - loss: 0.9040 - val_accuracy: 0.6500 - val_loss: 0.9550\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7364 - loss: 0.8767\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7366 - loss: 0.8760 - val_accuracy: 0.6600 - val_loss: 0.9222\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7602 - loss: 0.8375\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7601 - loss: 0.8369 - val_accuracy: 0.7300 - val_loss: 0.8728\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7433 - loss: 0.8183\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7433 - loss: 0.8180 - val_accuracy: 0.7500 - val_loss: 0.8270\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7569 - loss: 0.7873\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7568 - loss: 0.7872 - val_accuracy: 0.5500 - val_loss: 0.9719\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7317 - loss: 0.8099\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7318 - loss: 0.8092 - val_accuracy: 0.7700 - val_loss: 0.7793\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7601 - loss: 0.7398\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7598 - loss: 0.7400 - val_accuracy: 0.7200 - val_loss: 0.7750\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7722 - loss: 0.7041\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7717 - loss: 0.7048 - val_accuracy: 0.7500 - val_loss: 0.7336\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7435 - loss: 0.7366\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7437 - loss: 0.7363 - val_accuracy: 0.7600 - val_loss: 0.7306\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - loss: 0.7281\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7499 - loss: 0.7272 - val_accuracy: 0.7100 - val_loss: 0.7983\n",
            "Epoch 37/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7716 - loss: 0.6853\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7709 - loss: 0.6854 - val_accuracy: 0.7200 - val_loss: 0.7372\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7705 - loss: 0.6933\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7705 - loss: 0.6928 - val_accuracy: 0.7000 - val_loss: 0.7635\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7580 - loss: 0.6926\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7581 - loss: 0.6922 - val_accuracy: 0.6600 - val_loss: 0.8292\n",
            "Epoch 39: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "34 / 50\n",
            "\n",
            "--- Fold 35 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5191 - loss: 14.4106\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 142ms/step - accuracy: 0.5189 - loss: 14.3483 - val_accuracy: 0.5100 - val_loss: 8.7403\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5282 - loss: 8.2609 \n",
            "Epoch 2: val_accuracy did not improve from 0.51000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5268 - loss: 8.2136 - val_accuracy: 0.4900 - val_loss: 6.8288\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5206 - loss: 6.4718\n",
            "Epoch 3: val_accuracy did not improve from 0.51000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5209 - loss: 6.4585 - val_accuracy: 0.5100 - val_loss: 5.4604\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5232 - loss: 5.1954\n",
            "Epoch 4: val_accuracy improved from 0.51000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5237 - loss: 5.1855 - val_accuracy: 0.6100 - val_loss: 4.4379\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5673 - loss: 4.2319\n",
            "Epoch 5: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5670 - loss: 4.2245 - val_accuracy: 0.5200 - val_loss: 3.6640\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5500 - loss: 3.5094\n",
            "Epoch 6: val_accuracy improved from 0.61000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5508 - loss: 3.5034 - val_accuracy: 0.7000 - val_loss: 3.0254\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5910 - loss: 2.9373\n",
            "Epoch 7: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5920 - loss: 2.9302 - val_accuracy: 0.6800 - val_loss: 2.5478\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6333 - loss: 2.4772\n",
            "Epoch 8: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6336 - loss: 2.4735 - val_accuracy: 0.6500 - val_loss: 2.2016\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6599 - loss: 2.1298\n",
            "Epoch 9: val_accuracy improved from 0.70000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6603 - loss: 2.1268 - val_accuracy: 0.7200 - val_loss: 1.8814\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7004 - loss: 1.8287\n",
            "Epoch 10: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7003 - loss: 1.8267 - val_accuracy: 0.6700 - val_loss: 1.6657\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6956 - loss: 1.6222\n",
            "Epoch 11: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6956 - loss: 1.6206 - val_accuracy: 0.6800 - val_loss: 1.4936\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7086 - loss: 1.4355\n",
            "Epoch 12: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7087 - loss: 1.4340 - val_accuracy: 0.6700 - val_loss: 1.3620\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6957 - loss: 1.3031\n",
            "Epoch 13: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6964 - loss: 1.3016 - val_accuracy: 0.6600 - val_loss: 1.2453\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7325 - loss: 1.1609\n",
            "Epoch 14: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7323 - loss: 1.1604 - val_accuracy: 0.7100 - val_loss: 1.1108\n",
            "Epoch 15/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7168 - loss: 1.0902\n",
            "Epoch 15: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7158 - loss: 1.0889 - val_accuracy: 0.7100 - val_loss: 1.0320\n",
            "Epoch 16/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7252 - loss: 0.9963\n",
            "Epoch 16: val_accuracy improved from 0.72000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7253 - loss: 0.9959 - val_accuracy: 0.7300 - val_loss: 0.9794\n",
            "Epoch 17/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7298 - loss: 0.9330\n",
            "Epoch 17: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7301 - loss: 0.9319 - val_accuracy: 0.7100 - val_loss: 0.9326\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7198 - loss: 0.8861\n",
            "Epoch 18: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7199 - loss: 0.8857 - val_accuracy: 0.6700 - val_loss: 0.8807\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7521 - loss: 0.8228\n",
            "Epoch 19: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7516 - loss: 0.8231 - val_accuracy: 0.7200 - val_loss: 0.8326\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7418 - loss: 0.7912\n",
            "Epoch 20: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7415 - loss: 0.7912 - val_accuracy: 0.6800 - val_loss: 0.8079\n",
            "Epoch 21/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7328 - loss: 0.7734\n",
            "Epoch 21: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7326 - loss: 0.7737 - val_accuracy: 0.7100 - val_loss: 0.7865\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7292 - loss: 0.7561\n",
            "Epoch 22: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7295 - loss: 0.7558 - val_accuracy: 0.6700 - val_loss: 0.7980\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7493 - loss: 0.7149\n",
            "Epoch 23: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7492 - loss: 0.7150 - val_accuracy: 0.6700 - val_loss: 0.7753\n",
            "Epoch 24/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7455 - loss: 0.7050\n",
            "Epoch 24: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7456 - loss: 0.7051 - val_accuracy: 0.7200 - val_loss: 0.7509\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.6924\n",
            "Epoch 25: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 0.6923 - val_accuracy: 0.6000 - val_loss: 0.7928\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7155 - loss: 0.7062\n",
            "Epoch 26: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7160 - loss: 0.7059 - val_accuracy: 0.7300 - val_loss: 0.7294\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7357 - loss: 0.6750\n",
            "Epoch 27: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7360 - loss: 0.6746 - val_accuracy: 0.7100 - val_loss: 0.7178\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7508 - loss: 0.6631\n",
            "Epoch 28: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7505 - loss: 0.6633 - val_accuracy: 0.7400 - val_loss: 0.6847\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7405 - loss: 0.6614\n",
            "Epoch 29: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7405 - loss: 0.6614 - val_accuracy: 0.6700 - val_loss: 0.7089\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7514 - loss: 0.6483\n",
            "Epoch 30: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7510 - loss: 0.6486 - val_accuracy: 0.7000 - val_loss: 0.6940\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7397 - loss: 0.6652\n",
            "Epoch 31: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7395 - loss: 0.6651 - val_accuracy: 0.6800 - val_loss: 0.6925\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7568 - loss: 0.6374\n",
            "Epoch 32: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7567 - loss: 0.6375 - val_accuracy: 0.6900 - val_loss: 0.6818\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7723 - loss: 0.6225\n",
            "Epoch 33: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7715 - loss: 0.6230 - val_accuracy: 0.7500 - val_loss: 0.6812\n",
            "Epoch 34/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7537 - loss: 0.6265\n",
            "Epoch 34: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7535 - loss: 0.6271 - val_accuracy: 0.7500 - val_loss: 0.6608\n",
            "Epoch 35/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7547 - loss: 0.6172\n",
            "Epoch 35: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7550 - loss: 0.6172 - val_accuracy: 0.7000 - val_loss: 0.7219\n",
            "Epoch 36/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7657 - loss: 0.6287\n",
            "Epoch 36: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7641 - loss: 0.6295 - val_accuracy: 0.7000 - val_loss: 0.6785\n",
            "Epoch 37/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7573 - loss: 0.6333\n",
            "Epoch 37: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7564 - loss: 0.6343 - val_accuracy: 0.7100 - val_loss: 0.7009\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7696 - loss: 0.6315\n",
            "Epoch 38: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7693 - loss: 0.6315 - val_accuracy: 0.7100 - val_loss: 0.6981\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7711 - loss: 0.6179\n",
            "Epoch 39: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7706 - loss: 0.6182 - val_accuracy: 0.7100 - val_loss: 0.6769\n",
            "Epoch 40/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7659 - loss: 0.6174\n",
            "Epoch 40: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7658 - loss: 0.6177 - val_accuracy: 0.7200 - val_loss: 0.6979\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7822 - loss: 0.6025\n",
            "Epoch 41: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7815 - loss: 0.6032 - val_accuracy: 0.7100 - val_loss: 0.6908\n",
            "Epoch 42/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7810 - loss: 0.6060\n",
            "Epoch 42: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7794 - loss: 0.6075 - val_accuracy: 0.7200 - val_loss: 0.7096\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.6215\n",
            "Epoch 43: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7660 - loss: 0.6217 - val_accuracy: 0.7500 - val_loss: 0.6808\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7691 - loss: 0.6260\n",
            "Epoch 44: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7690 - loss: 0.6260 - val_accuracy: 0.7400 - val_loss: 0.6690\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7597 - loss: 0.6110\n",
            "Epoch 45: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7593 - loss: 0.6116 - val_accuracy: 0.5900 - val_loss: 0.7373\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7630 - loss: 0.6206\n",
            "Epoch 46: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7631 - loss: 0.6205 - val_accuracy: 0.7200 - val_loss: 0.6704\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7626 - loss: 0.6145\n",
            "Epoch 47: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7624 - loss: 0.6151 - val_accuracy: 0.7200 - val_loss: 0.6886\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7733 - loss: 0.5985\n",
            "Epoch 48: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7730 - loss: 0.5988 - val_accuracy: 0.7700 - val_loss: 0.7516\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7693 - loss: 0.6293\n",
            "Epoch 49: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7691 - loss: 0.6289 - val_accuracy: 0.7400 - val_loss: 0.6982\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7680 - loss: 0.5988\n",
            "Epoch 50: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7678 - loss: 0.5996 - val_accuracy: 0.7600 - val_loss: 0.6864\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "35 / 50\n",
            "\n",
            "--- Fold 36 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.4964 - loss: 15.7069\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 0.4964 - loss: 15.6295 - val_accuracy: 0.4600 - val_loss: 9.0220\n",
            "Epoch 2/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5409 - loss: 8.5505\n",
            "Epoch 2: val_accuracy improved from 0.46000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.5400 - loss: 8.5333 - val_accuracy: 0.6500 - val_loss: 7.2350\n",
            "Epoch 3/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5236 - loss: 6.9272\n",
            "Epoch 3: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5231 - loss: 6.8815 - val_accuracy: 0.4900 - val_loss: 5.9197\n",
            "Epoch 4/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5436 - loss: 5.6681\n",
            "Epoch 4: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5432 - loss: 5.6484 - val_accuracy: 0.4800 - val_loss: 4.9154\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5384 - loss: 4.7128\n",
            "Epoch 5: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5386 - loss: 4.7053 - val_accuracy: 0.4500 - val_loss: 4.1368\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5470 - loss: 3.9723\n",
            "Epoch 6: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5474 - loss: 3.9663 - val_accuracy: 0.4800 - val_loss: 3.5164\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5915 - loss: 3.3812\n",
            "Epoch 7: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5911 - loss: 3.3765 - val_accuracy: 0.6200 - val_loss: 3.0037\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5732 - loss: 2.9172\n",
            "Epoch 8: val_accuracy improved from 0.65000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5735 - loss: 2.9133 - val_accuracy: 0.7000 - val_loss: 2.5725\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6386 - loss: 2.5096\n",
            "Epoch 9: val_accuracy improved from 0.70000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6392 - loss: 2.5063 - val_accuracy: 0.7200 - val_loss: 2.2309\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6849 - loss: 2.1891\n",
            "Epoch 10: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6850 - loss: 2.1866 - val_accuracy: 0.7100 - val_loss: 1.9860\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6985 - loss: 1.9405\n",
            "Epoch 11: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6972 - loss: 1.9396 - val_accuracy: 0.6300 - val_loss: 1.8192\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7098 - loss: 1.7297\n",
            "Epoch 12: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7100 - loss: 1.7278 - val_accuracy: 0.6200 - val_loss: 1.6541\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7298 - loss: 1.5456\n",
            "Epoch 13: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7291 - loss: 1.5445 - val_accuracy: 0.7200 - val_loss: 1.4465\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7239 - loss: 1.4011\n",
            "Epoch 14: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7236 - loss: 1.4000 - val_accuracy: 0.6100 - val_loss: 1.3672\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7211 - loss: 1.2846\n",
            "Epoch 15: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7213 - loss: 1.2835 - val_accuracy: 0.6300 - val_loss: 1.2705\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7035 - loss: 1.2081\n",
            "Epoch 16: val_accuracy improved from 0.72000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7038 - loss: 1.2070 - val_accuracy: 0.7400 - val_loss: 1.1176\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7411 - loss: 1.0893\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7410 - loss: 1.0888 - val_accuracy: 0.7200 - val_loss: 1.0510\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7322 - loss: 1.0317\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7320 - loss: 1.0309 - val_accuracy: 0.6600 - val_loss: 1.0104\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7427 - loss: 0.9669\n",
            "Epoch 19: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7426 - loss: 0.9666 - val_accuracy: 0.7500 - val_loss: 0.9574\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7481 - loss: 0.9257\n",
            "Epoch 20: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7474 - loss: 0.9256 - val_accuracy: 0.7400 - val_loss: 0.8632\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7526 - loss: 0.8767\n",
            "Epoch 21: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7527 - loss: 0.8760 - val_accuracy: 0.7300 - val_loss: 0.8587\n",
            "Epoch 22/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7588 - loss: 0.8324\n",
            "Epoch 22: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7577 - loss: 0.8320 - val_accuracy: 0.7100 - val_loss: 0.8221\n",
            "Epoch 23/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7449 - loss: 0.7973\n",
            "Epoch 23: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7448 - loss: 0.7986 - val_accuracy: 0.7200 - val_loss: 0.7824\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7567 - loss: 0.7604\n",
            "Epoch 24: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7564 - loss: 0.7608 - val_accuracy: 0.7400 - val_loss: 0.7643\n",
            "Epoch 25/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7484 - loss: 0.7512\n",
            "Epoch 25: val_accuracy improved from 0.75000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7485 - loss: 0.7511 - val_accuracy: 0.7600 - val_loss: 0.7388\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7339 - loss: 0.7499\n",
            "Epoch 26: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7343 - loss: 0.7497 - val_accuracy: 0.7300 - val_loss: 0.7429\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7707 - loss: 0.7161\n",
            "Epoch 27: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7703 - loss: 0.7159 - val_accuracy: 0.7100 - val_loss: 0.7240\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7477 - loss: 0.7045\n",
            "Epoch 28: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7478 - loss: 0.7047 - val_accuracy: 0.7700 - val_loss: 0.7100\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7478 - loss: 0.7010\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7479 - loss: 0.7008 - val_accuracy: 0.7200 - val_loss: 0.6962\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7781 - loss: 0.6532\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7773 - loss: 0.6541 - val_accuracy: 0.6900 - val_loss: 0.7205\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7632 - loss: 0.6571\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7629 - loss: 0.6577 - val_accuracy: 0.7200 - val_loss: 0.7039\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7541 - loss: 0.6680\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7540 - loss: 0.6681 - val_accuracy: 0.7400 - val_loss: 0.7046\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7617 - loss: 0.6560\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7618 - loss: 0.6558 - val_accuracy: 0.7300 - val_loss: 0.6755\n",
            "Epoch 34/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7794 - loss: 0.6327\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7783 - loss: 0.6336 - val_accuracy: 0.7300 - val_loss: 0.6753\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7444 - loss: 0.6549\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7447 - loss: 0.6545 - val_accuracy: 0.7400 - val_loss: 0.6859\n",
            "Epoch 36/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7726 - loss: 0.6246\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7726 - loss: 0.6246 - val_accuracy: 0.7500 - val_loss: 0.6667\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7666 - loss: 0.6335\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.6334 - val_accuracy: 0.7200 - val_loss: 0.6674\n",
            "Epoch 38/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7738 - loss: 0.6210\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7732 - loss: 0.6214 - val_accuracy: 0.7300 - val_loss: 0.6803\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7616 - loss: 0.6377\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7615 - loss: 0.6377 - val_accuracy: 0.7500 - val_loss: 0.6746\n",
            "Epoch 40/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7664 - loss: 0.6415\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7668 - loss: 0.6404 - val_accuracy: 0.7400 - val_loss: 0.6488\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7732 - loss: 0.6211\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7734 - loss: 0.6211 - val_accuracy: 0.7000 - val_loss: 0.6678\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7529 - loss: 0.6549\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7535 - loss: 0.6542 - val_accuracy: 0.7200 - val_loss: 0.6704\n",
            "Epoch 43/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7805 - loss: 0.5996\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7785 - loss: 0.6026 - val_accuracy: 0.7200 - val_loss: 0.6652\n",
            "Epoch 44/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7786 - loss: 0.6067\n",
            "Epoch 44: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7775 - loss: 0.6077 - val_accuracy: 0.7100 - val_loss: 0.7053\n",
            "Epoch 45/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7725 - loss: 0.6156\n",
            "Epoch 45: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7715 - loss: 0.6175 - val_accuracy: 0.6800 - val_loss: 0.7258\n",
            "Epoch 46/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.6037\n",
            "Epoch 46: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7910 - loss: 0.6054 - val_accuracy: 0.6900 - val_loss: 0.6981\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7646 - loss: 0.6161\n",
            "Epoch 47: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7648 - loss: 0.6161 - val_accuracy: 0.7200 - val_loss: 0.6799\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7844 - loss: 0.5928\n",
            "Epoch 48: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7839 - loss: 0.5937 - val_accuracy: 0.6800 - val_loss: 0.6999\n",
            "Epoch 48: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "36 / 50\n",
            "\n",
            "--- Fold 37 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5143 - loss: 15.5771\n",
            "Epoch 1: val_accuracy improved from -inf to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - accuracy: 0.5144 - loss: 15.5082 - val_accuracy: 0.6200 - val_loss: 9.4346\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5035 - loss: 9.0689 \n",
            "Epoch 2: val_accuracy did not improve from 0.62000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5029 - loss: 9.0313 - val_accuracy: 0.5500 - val_loss: 7.9027\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5180 - loss: 7.5955\n",
            "Epoch 3: val_accuracy did not improve from 0.62000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5180 - loss: 7.5839 - val_accuracy: 0.5400 - val_loss: 6.6887\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5297 - loss: 6.4428\n",
            "Epoch 4: val_accuracy improved from 0.62000 to 0.67000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5299 - loss: 6.4334 - val_accuracy: 0.6700 - val_loss: 5.7084\n",
            "Epoch 5/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5415 - loss: 5.5144\n",
            "Epoch 5: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5412 - loss: 5.5028 - val_accuracy: 0.4800 - val_loss: 4.9086\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5350 - loss: 4.7465\n",
            "Epoch 6: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5353 - loss: 4.7402 - val_accuracy: 0.4900 - val_loss: 4.2464\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5474 - loss: 4.1152\n",
            "Epoch 7: val_accuracy did not improve from 0.67000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5479 - loss: 4.1071 - val_accuracy: 0.6000 - val_loss: 3.6796\n",
            "Epoch 8/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5843 - loss: 3.5764\n",
            "Epoch 8: val_accuracy improved from 0.67000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5845 - loss: 3.5742 - val_accuracy: 0.7000 - val_loss: 3.1935\n",
            "Epoch 9/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6259 - loss: 3.1274\n",
            "Epoch 9: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6259 - loss: 3.1256 - val_accuracy: 0.6200 - val_loss: 2.8367\n",
            "Epoch 10/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6653 - loss: 2.7508\n",
            "Epoch 10: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6650 - loss: 2.7464 - val_accuracy: 0.6300 - val_loss: 2.4983\n",
            "Epoch 11/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7032 - loss: 2.4162\n",
            "Epoch 11: val_accuracy improved from 0.70000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7025 - loss: 2.4116 - val_accuracy: 0.7800 - val_loss: 2.1986\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6964 - loss: 2.1709\n",
            "Epoch 12: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6964 - loss: 2.1688 - val_accuracy: 0.7000 - val_loss: 1.9975\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7115 - loss: 1.9416\n",
            "Epoch 13: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7115 - loss: 1.9398 - val_accuracy: 0.6600 - val_loss: 1.8143\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6905 - loss: 1.7716\n",
            "Epoch 14: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: 1.7698 - val_accuracy: 0.7600 - val_loss: 1.5903\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7238 - loss: 1.5834\n",
            "Epoch 15: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7234 - loss: 1.5828 - val_accuracy: 0.7500 - val_loss: 1.4683\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7168 - loss: 1.4692\n",
            "Epoch 16: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7167 - loss: 1.4680 - val_accuracy: 0.7500 - val_loss: 1.3468\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7120 - loss: 1.3363\n",
            "Epoch 17: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7123 - loss: 1.3355 - val_accuracy: 0.7000 - val_loss: 1.2972\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7301 - loss: 1.2329\n",
            "Epoch 18: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7299 - loss: 1.2323 - val_accuracy: 0.7200 - val_loss: 1.1811\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7372 - loss: 1.1408\n",
            "Epoch 19: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7368 - loss: 1.1406 - val_accuracy: 0.7700 - val_loss: 1.0710\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7170 - loss: 1.0801\n",
            "Epoch 20: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7174 - loss: 1.0794 - val_accuracy: 0.7000 - val_loss: 1.0525\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7446 - loss: 1.0142\n",
            "Epoch 21: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7446 - loss: 1.0134 - val_accuracy: 0.7600 - val_loss: 0.9778\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7444 - loss: 0.9543\n",
            "Epoch 22: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7441 - loss: 0.9544 - val_accuracy: 0.6900 - val_loss: 0.9596\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7473 - loss: 0.9098\n",
            "Epoch 23: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7467 - loss: 0.9098 - val_accuracy: 0.7800 - val_loss: 0.9052\n",
            "Epoch 24/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7460 - loss: 0.8618\n",
            "Epoch 24: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7458 - loss: 0.8616 - val_accuracy: 0.7900 - val_loss: 0.8514\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7532 - loss: 0.8194\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7530 - loss: 0.8193 - val_accuracy: 0.7800 - val_loss: 0.8235\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7442 - loss: 0.7877\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7441 - loss: 0.7883 - val_accuracy: 0.7100 - val_loss: 0.8199\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7432 - loss: 0.7743\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7429 - loss: 0.7746 - val_accuracy: 0.6900 - val_loss: 0.8072\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7458 - loss: 0.7475\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7458 - loss: 0.7476 - val_accuracy: 0.7100 - val_loss: 0.7891\n",
            "Epoch 29/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7441 - loss: 0.7365\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7434 - loss: 0.7372 - val_accuracy: 0.7100 - val_loss: 0.7769\n",
            "Epoch 30/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7666 - loss: 0.7182\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7647 - loss: 0.7190 - val_accuracy: 0.7600 - val_loss: 0.7643\n",
            "Epoch 31/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7355 - loss: 0.7123\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7364 - loss: 0.7119 - val_accuracy: 0.6200 - val_loss: 0.8257\n",
            "Epoch 32/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7505 - loss: 0.6919\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7506 - loss: 0.6920 - val_accuracy: 0.7400 - val_loss: 0.7294\n",
            "Epoch 33/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7432 - loss: 0.6896\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7438 - loss: 0.6890 - val_accuracy: 0.7600 - val_loss: 0.7235\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7603 - loss: 0.6718\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7603 - loss: 0.6717 - val_accuracy: 0.7300 - val_loss: 0.7076\n",
            "Epoch 35/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7651 - loss: 0.6630\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7641 - loss: 0.6637 - val_accuracy: 0.7400 - val_loss: 0.6999\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7667 - loss: 0.6580\n",
            "Epoch 36: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7664 - loss: 0.6581 - val_accuracy: 0.7500 - val_loss: 0.7073\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7606 - loss: 0.6427\n",
            "Epoch 37: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7604 - loss: 0.6431 - val_accuracy: 0.7300 - val_loss: 0.7031\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7422 - loss: 0.6608\n",
            "Epoch 38: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7426 - loss: 0.6604 - val_accuracy: 0.7300 - val_loss: 0.7082\n",
            "Epoch 39/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7620 - loss: 0.6445\n",
            "Epoch 39: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7617 - loss: 0.6454 - val_accuracy: 0.7500 - val_loss: 0.6919\n",
            "Epoch 40/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7570 - loss: 0.6441\n",
            "Epoch 40: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7579 - loss: 0.6438 - val_accuracy: 0.7600 - val_loss: 0.6897\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7630 - loss: 0.6376\n",
            "Epoch 41: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7629 - loss: 0.6377 - val_accuracy: 0.7100 - val_loss: 0.7060\n",
            "Epoch 42/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7811 - loss: 0.6214\n",
            "Epoch 42: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7804 - loss: 0.6222 - val_accuracy: 0.7300 - val_loss: 0.6785\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7728 - loss: 0.6154\n",
            "Epoch 43: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7723 - loss: 0.6159 - val_accuracy: 0.7500 - val_loss: 0.6895\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7575 - loss: 0.6482\n",
            "Epoch 44: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7578 - loss: 0.6476 - val_accuracy: 0.7400 - val_loss: 0.6679\n",
            "Epoch 44: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "37 / 50\n",
            "\n",
            "--- Fold 38 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4964 - loss: 17.6523\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 163ms/step - accuracy: 0.4962 - loss: 17.5533 - val_accuracy: 0.5500 - val_loss: 9.4076\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4889 - loss: 9.0512\n",
            "Epoch 2: val_accuracy improved from 0.55000 to 0.58000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.4911 - loss: 9.0057 - val_accuracy: 0.5800 - val_loss: 7.8879\n",
            "Epoch 3/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5312 - loss: 7.6077\n",
            "Epoch 3: val_accuracy did not improve from 0.58000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5297 - loss: 7.5728 - val_accuracy: 0.5300 - val_loss: 6.7011\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5127 - loss: 6.4658\n",
            "Epoch 4: val_accuracy did not improve from 0.58000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5129 - loss: 6.4519 - val_accuracy: 0.4900 - val_loss: 5.7462\n",
            "Epoch 5/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5278 - loss: 5.5460\n",
            "Epoch 5: val_accuracy did not improve from 0.58000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5279 - loss: 5.5423 - val_accuracy: 0.5500 - val_loss: 4.9646\n",
            "Epoch 6/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5292 - loss: 4.8135\n",
            "Epoch 6: val_accuracy improved from 0.58000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5300 - loss: 4.7975 - val_accuracy: 0.6400 - val_loss: 4.3148\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5655 - loss: 4.1803\n",
            "Epoch 7: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5656 - loss: 4.1752 - val_accuracy: 0.6400 - val_loss: 3.7782\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5852 - loss: 3.6610\n",
            "Epoch 8: val_accuracy improved from 0.64000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5859 - loss: 3.6563 - val_accuracy: 0.7400 - val_loss: 3.2733\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6373 - loss: 3.2242\n",
            "Epoch 9: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6374 - loss: 3.2203 - val_accuracy: 0.6900 - val_loss: 2.9239\n",
            "Epoch 10/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6354 - loss: 2.8569\n",
            "Epoch 10: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6365 - loss: 2.8517 - val_accuracy: 0.6900 - val_loss: 2.5947\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6646 - loss: 2.5383\n",
            "Epoch 11: val_accuracy improved from 0.74000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6651 - loss: 2.5354 - val_accuracy: 0.7500 - val_loss: 2.3316\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6889 - loss: 2.2741\n",
            "Epoch 12: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6889 - loss: 2.2718 - val_accuracy: 0.7200 - val_loss: 2.0696\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6922 - loss: 2.0386\n",
            "Epoch 13: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6927 - loss: 2.0364 - val_accuracy: 0.7400 - val_loss: 1.8959\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7060 - loss: 1.8478\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7051 - loss: 1.8471 - val_accuracy: 0.7500 - val_loss: 1.7469\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7282 - loss: 1.6674\n",
            "Epoch 15: val_accuracy improved from 0.75000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7277 - loss: 1.6664 - val_accuracy: 0.7800 - val_loss: 1.5706\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7206 - loss: 1.5369\n",
            "Epoch 16: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7200 - loss: 1.5362 - val_accuracy: 0.7100 - val_loss: 1.4744\n",
            "Epoch 17/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7249 - loss: 1.4087\n",
            "Epoch 17: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7243 - loss: 1.4081 - val_accuracy: 0.5700 - val_loss: 1.4126\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6740 - loss: 1.3549\n",
            "Epoch 18: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6754 - loss: 1.3532 - val_accuracy: 0.7700 - val_loss: 1.2601\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7141 - loss: 1.2381\n",
            "Epoch 19: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7144 - loss: 1.2365 - val_accuracy: 0.7600 - val_loss: 1.1609\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7437 - loss: 1.1266\n",
            "Epoch 20: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7432 - loss: 1.1265 - val_accuracy: 0.6800 - val_loss: 1.1558\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7208 - loss: 1.0909\n",
            "Epoch 21: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7214 - loss: 1.0900 - val_accuracy: 0.7600 - val_loss: 1.0604\n",
            "Epoch 22/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7362 - loss: 1.0119\n",
            "Epoch 22: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7360 - loss: 1.0118 - val_accuracy: 0.7100 - val_loss: 1.0286\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7087 - loss: 1.0047\n",
            "Epoch 23: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7102 - loss: 1.0022 - val_accuracy: 0.6900 - val_loss: 0.9805\n",
            "Epoch 24/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7398 - loss: 0.9143\n",
            "Epoch 24: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7396 - loss: 0.9146 - val_accuracy: 0.7200 - val_loss: 0.9522\n",
            "Epoch 25/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7386 - loss: 0.8943\n",
            "Epoch 25: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7397 - loss: 0.8921 - val_accuracy: 0.7400 - val_loss: 0.8765\n",
            "Epoch 26/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7449 - loss: 0.8489\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7447 - loss: 0.8486 - val_accuracy: 0.6800 - val_loss: 0.8914\n",
            "Epoch 27/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7335 - loss: 0.8304\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7338 - loss: 0.8310 - val_accuracy: 0.7000 - val_loss: 0.8614\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7533 - loss: 0.7979\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7530 - loss: 0.7979 - val_accuracy: 0.7800 - val_loss: 0.8233\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7367 - loss: 0.7892\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7370 - loss: 0.7888 - val_accuracy: 0.7800 - val_loss: 0.7890\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7485 - loss: 0.7560\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7482 - loss: 0.7565 - val_accuracy: 0.7100 - val_loss: 0.8227\n",
            "Epoch 31/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7430 - loss: 0.7433\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7430 - loss: 0.7436 - val_accuracy: 0.7400 - val_loss: 0.7593\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7509 - loss: 0.7293\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7506 - loss: 0.7297 - val_accuracy: 0.7300 - val_loss: 0.7691\n",
            "Epoch 33/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7624 - loss: 0.7131\n",
            "Epoch 33: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7623 - loss: 0.7131 - val_accuracy: 0.6900 - val_loss: 0.7668\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7538 - loss: 0.6994\n",
            "Epoch 34: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7537 - loss: 0.6995 - val_accuracy: 0.7100 - val_loss: 0.7565\n",
            "Epoch 35/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7485 - loss: 0.7121\n",
            "Epoch 35: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7489 - loss: 0.7115 - val_accuracy: 0.7600 - val_loss: 0.7282\n",
            "Epoch 35: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "38 / 50\n",
            "\n",
            "--- Fold 39 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4848 - loss: 19.1223\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - accuracy: 0.4849 - loss: 18.9996 - val_accuracy: 0.5600 - val_loss: 9.2333\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4884 - loss: 8.8586\n",
            "Epoch 2: val_accuracy did not improve from 0.56000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4895 - loss: 8.8209 - val_accuracy: 0.5600 - val_loss: 7.7024\n",
            "Epoch 3/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5072 - loss: 7.4286\n",
            "Epoch 3: val_accuracy improved from 0.56000 to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5068 - loss: 7.3940 - val_accuracy: 0.5700 - val_loss: 6.5338\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5065 - loss: 6.2984\n",
            "Epoch 4: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5065 - loss: 6.2895 - val_accuracy: 0.5700 - val_loss: 5.6060\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5217 - loss: 5.4152\n",
            "Epoch 5: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5213 - loss: 5.4080 - val_accuracy: 0.5700 - val_loss: 4.8552\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5142 - loss: 4.6990\n",
            "Epoch 6: val_accuracy improved from 0.57000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5141 - loss: 4.6931 - val_accuracy: 0.6200 - val_loss: 4.2382\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5290 - loss: 4.1098\n",
            "Epoch 7: val_accuracy improved from 0.62000 to 0.66000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5291 - loss: 4.1049 - val_accuracy: 0.6600 - val_loss: 3.7262\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5157 - loss: 3.6205\n",
            "Epoch 8: val_accuracy improved from 0.66000 to 0.69000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5162 - loss: 3.6164 - val_accuracy: 0.6900 - val_loss: 3.2907\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5224 - loss: 3.2133\n",
            "Epoch 9: val_accuracy improved from 0.69000 to 0.71000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5232 - loss: 3.2096 - val_accuracy: 0.7100 - val_loss: 2.9077\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 2.8521\n",
            "Epoch 10: val_accuracy improved from 0.71000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5939 - loss: 2.8492 - val_accuracy: 0.7200 - val_loss: 2.5769\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5786 - loss: 2.5828\n",
            "Epoch 11: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5794 - loss: 2.5798 - val_accuracy: 0.7200 - val_loss: 2.3293\n",
            "Epoch 12/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5826 - loss: 2.3201\n",
            "Epoch 12: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5839 - loss: 2.3167 - val_accuracy: 0.6300 - val_loss: 2.1377\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6329 - loss: 2.0926\n",
            "Epoch 13: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6331 - loss: 2.0907 - val_accuracy: 0.7000 - val_loss: 1.9127\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6488 - loss: 1.9030\n",
            "Epoch 14: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6496 - loss: 1.9012 - val_accuracy: 0.5400 - val_loss: 1.8299\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6594 - loss: 1.7571\n",
            "Epoch 15: val_accuracy did not improve from 0.72000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6601 - loss: 1.7550 - val_accuracy: 0.5700 - val_loss: 1.6834\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6457 - loss: 1.6484\n",
            "Epoch 16: val_accuracy improved from 0.72000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6464 - loss: 1.6463 - val_accuracy: 0.7900 - val_loss: 1.5045\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7100 - loss: 1.4705\n",
            "Epoch 17: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7102 - loss: 1.4692 - val_accuracy: 0.7300 - val_loss: 1.3792\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7250 - loss: 1.3376\n",
            "Epoch 18: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7246 - loss: 1.3374 - val_accuracy: 0.7600 - val_loss: 1.3150\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6956 - loss: 1.2806\n",
            "Epoch 19: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6960 - loss: 1.2799 - val_accuracy: 0.7300 - val_loss: 1.2172\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7347 - loss: 1.1719\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7336 - loss: 1.1719 - val_accuracy: 0.7500 - val_loss: 1.1454\n",
            "Epoch 21/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7344 - loss: 1.1160\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7342 - loss: 1.1154 - val_accuracy: 0.7100 - val_loss: 1.0985\n",
            "Epoch 22/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7091 - loss: 1.0710\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7092 - loss: 1.0708 - val_accuracy: 0.7400 - val_loss: 1.0181\n",
            "Epoch 23/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7242 - loss: 1.0130\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7245 - loss: 1.0111 - val_accuracy: 0.6800 - val_loss: 1.0123\n",
            "Epoch 24/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7538 - loss: 0.9476\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7535 - loss: 0.9476 - val_accuracy: 0.7400 - val_loss: 0.9434\n",
            "Epoch 25/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7386 - loss: 0.9138\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7382 - loss: 0.9138 - val_accuracy: 0.6500 - val_loss: 0.9669\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7530 - loss: 0.8710\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7524 - loss: 0.8711 - val_accuracy: 0.6700 - val_loss: 0.9352\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7326 - loss: 0.8606\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7328 - loss: 0.8600 - val_accuracy: 0.7400 - val_loss: 0.8675\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7345 - loss: 0.8269\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7342 - loss: 0.8272 - val_accuracy: 0.7600 - val_loss: 0.8444\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7476 - loss: 0.8151\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7474 - loss: 0.8147 - val_accuracy: 0.7400 - val_loss: 0.8108\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7420 - loss: 0.7733\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7417 - loss: 0.7738 - val_accuracy: 0.7400 - val_loss: 0.8094\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7450 - loss: 0.7547\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7448 - loss: 0.7552 - val_accuracy: 0.7600 - val_loss: 0.7767\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7463 - loss: 0.7462\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7461 - loss: 0.7463 - val_accuracy: 0.7600 - val_loss: 0.7542\n",
            "Epoch 33/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7446 - loss: 0.7330\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7449 - loss: 0.7324 - val_accuracy: 0.7500 - val_loss: 0.7596\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7496 - loss: 0.7047\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7495 - loss: 0.7051 - val_accuracy: 0.7300 - val_loss: 0.7425\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7525 - loss: 0.6943\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7523 - loss: 0.6947 - val_accuracy: 0.7300 - val_loss: 0.7355\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7331 - loss: 0.7314\n",
            "Epoch 36: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.7309 - val_accuracy: 0.7100 - val_loss: 0.7406\n",
            "Epoch 36: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "39 / 50\n",
            "\n",
            "--- Fold 40 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5122 - loss: 15.1429\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 0.5123 - loss: 15.0702 - val_accuracy: 0.5300 - val_loss: 8.8511\n",
            "Epoch 2/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5141 - loss: 8.3792\n",
            "Epoch 2: val_accuracy improved from 0.53000 to 0.57000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.5137 - loss: 8.3619 - val_accuracy: 0.5700 - val_loss: 7.0583\n",
            "Epoch 3/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5219 - loss: 6.7373\n",
            "Epoch 3: val_accuracy did not improve from 0.57000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5219 - loss: 6.7049 - val_accuracy: 0.5400 - val_loss: 5.7413\n",
            "Epoch 4/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5134 - loss: 5.4993\n",
            "Epoch 4: val_accuracy improved from 0.57000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5140 - loss: 5.4744 - val_accuracy: 0.6400 - val_loss: 4.7363\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5355 - loss: 4.5351\n",
            "Epoch 5: val_accuracy improved from 0.64000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5356 - loss: 4.5276 - val_accuracy: 0.7000 - val_loss: 3.9454\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5634 - loss: 3.7947\n",
            "Epoch 6: val_accuracy improved from 0.70000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5638 - loss: 3.7888 - val_accuracy: 0.7300 - val_loss: 3.3182\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6189 - loss: 3.1981\n",
            "Epoch 7: val_accuracy improved from 0.73000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6192 - loss: 3.1933 - val_accuracy: 0.7500 - val_loss: 2.7943\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6425 - loss: 2.7276\n",
            "Epoch 8: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6425 - loss: 2.7243 - val_accuracy: 0.7500 - val_loss: 2.3976\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6407 - loss: 2.3640\n",
            "Epoch 9: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6412 - loss: 2.3609 - val_accuracy: 0.7200 - val_loss: 2.0707\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6666 - loss: 2.0648\n",
            "Epoch 10: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6673 - loss: 2.0619 - val_accuracy: 0.6800 - val_loss: 1.8435\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7018 - loss: 1.7866\n",
            "Epoch 11: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7019 - loss: 1.7848 - val_accuracy: 0.7500 - val_loss: 1.6187\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7044 - loss: 1.5964\n",
            "Epoch 12: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7046 - loss: 1.5950 - val_accuracy: 0.7500 - val_loss: 1.4452\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6995 - loss: 1.4274\n",
            "Epoch 13: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7000 - loss: 1.4260 - val_accuracy: 0.6100 - val_loss: 1.3785\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7078 - loss: 1.2998\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7081 - loss: 1.2987 - val_accuracy: 0.7500 - val_loss: 1.2159\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7323 - loss: 1.1967\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7320 - loss: 1.1958 - val_accuracy: 0.7400 - val_loss: 1.0964\n",
            "Epoch 16/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7258 - loss: 1.1038\n",
            "Epoch 16: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7262 - loss: 1.1019 - val_accuracy: 0.7100 - val_loss: 1.0319\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7303 - loss: 1.0076\n",
            "Epoch 17: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7303 - loss: 1.0074 - val_accuracy: 0.6500 - val_loss: 1.0074\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7266 - loss: 0.9616\n",
            "Epoch 18: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7269 - loss: 0.9608 - val_accuracy: 0.7000 - val_loss: 0.9232\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7308 - loss: 0.9097\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7310 - loss: 0.9093 - val_accuracy: 0.7400 - val_loss: 0.8785\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7525 - loss: 0.8381\n",
            "Epoch 20: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7524 - loss: 0.8380 - val_accuracy: 0.7700 - val_loss: 0.7986\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7549 - loss: 0.8119\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7543 - loss: 0.8126 - val_accuracy: 0.6600 - val_loss: 0.8445\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.7943\n",
            "Epoch 22: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7340 - loss: 0.7941 - val_accuracy: 0.7300 - val_loss: 0.7548\n",
            "Epoch 23/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7565 - loss: 0.7500\n",
            "Epoch 23: val_accuracy improved from 0.77000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7560 - loss: 0.7501 - val_accuracy: 0.7800 - val_loss: 0.7268\n",
            "Epoch 24/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7690 - loss: 0.7037\n",
            "Epoch 24: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7686 - loss: 0.7041 - val_accuracy: 0.7200 - val_loss: 0.7384\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7693 - loss: 0.7001\n",
            "Epoch 25: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7684 - loss: 0.7012 - val_accuracy: 0.7600 - val_loss: 0.7188\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7458 - loss: 0.7088\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7460 - loss: 0.7085 - val_accuracy: 0.7300 - val_loss: 0.7107\n",
            "Epoch 27/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7486 - loss: 0.6870\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7483 - loss: 0.6876 - val_accuracy: 0.7200 - val_loss: 0.7061\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7458 - loss: 0.7049\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7461 - loss: 0.7040 - val_accuracy: 0.7100 - val_loss: 0.7071\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7377 - loss: 0.6912\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7378 - loss: 0.6911 - val_accuracy: 0.7200 - val_loss: 0.6869\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7668 - loss: 0.6474\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7666 - loss: 0.6476 - val_accuracy: 0.7100 - val_loss: 0.6931\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7841 - loss: 0.6338\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7832 - loss: 0.6347 - val_accuracy: 0.7700 - val_loss: 0.6647\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7553 - loss: 0.6616\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7550 - loss: 0.6618 - val_accuracy: 0.6800 - val_loss: 0.7423\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7390 - loss: 0.6711\n",
            "Epoch 33: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7395 - loss: 0.6706 - val_accuracy: 0.7500 - val_loss: 0.6522\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7710 - loss: 0.6307\n",
            "Epoch 34: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7708 - loss: 0.6311 - val_accuracy: 0.7800 - val_loss: 0.6636\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7566 - loss: 0.6443\n",
            "Epoch 35: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7566 - loss: 0.6444 - val_accuracy: 0.7100 - val_loss: 0.6656\n",
            "Epoch 36/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7631 - loss: 0.6315\n",
            "Epoch 36: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7632 - loss: 0.6315 - val_accuracy: 0.7300 - val_loss: 0.6492\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7842 - loss: 0.6180\n",
            "Epoch 37: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7838 - loss: 0.6183 - val_accuracy: 0.7500 - val_loss: 0.6512\n",
            "Epoch 38/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7625 - loss: 0.6198\n",
            "Epoch 38: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7627 - loss: 0.6199 - val_accuracy: 0.7800 - val_loss: 0.6444\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7551 - loss: 0.6297\n",
            "Epoch 39: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7549 - loss: 0.6301 - val_accuracy: 0.7100 - val_loss: 0.6551\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7830 - loss: 0.6213\n",
            "Epoch 40: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7824 - loss: 0.6215 - val_accuracy: 0.7400 - val_loss: 0.6477\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7765 - loss: 0.6155\n",
            "Epoch 41: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7764 - loss: 0.6157 - val_accuracy: 0.7200 - val_loss: 0.6571\n",
            "Epoch 42/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7577 - loss: 0.6317\n",
            "Epoch 42: val_accuracy improved from 0.78000 to 0.81000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7580 - loss: 0.6318 - val_accuracy: 0.8100 - val_loss: 0.6295\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7805 - loss: 0.5996\n",
            "Epoch 43: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7802 - loss: 0.6000 - val_accuracy: 0.6500 - val_loss: 0.7391\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7625 - loss: 0.6258\n",
            "Epoch 44: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7629 - loss: 0.6255 - val_accuracy: 0.7500 - val_loss: 0.6452\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.6195\n",
            "Epoch 45: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7687 - loss: 0.6195 - val_accuracy: 0.7600 - val_loss: 0.6454\n",
            "Epoch 46/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7885 - loss: 0.5989\n",
            "Epoch 46: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7879 - loss: 0.5995 - val_accuracy: 0.7800 - val_loss: 0.6365\n",
            "Epoch 47/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7667 - loss: 0.6279\n",
            "Epoch 47: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.6276 - val_accuracy: 0.7600 - val_loss: 0.6243\n",
            "Epoch 48/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7770 - loss: 0.6032\n",
            "Epoch 48: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7767 - loss: 0.6039 - val_accuracy: 0.7800 - val_loss: 0.6331\n",
            "Epoch 49/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7705 - loss: 0.6229\n",
            "Epoch 49: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7707 - loss: 0.6227 - val_accuracy: 0.7800 - val_loss: 0.6336\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7773 - loss: 0.6099\n",
            "Epoch 50: val_accuracy did not improve from 0.81000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7771 - loss: 0.6101 - val_accuracy: 0.8100 - val_loss: 0.6142\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "40 / 50\n",
            "\n",
            "--- Fold 41 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5060 - loss: 17.3481\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - accuracy: 0.5060 - loss: 17.2498 - val_accuracy: 0.4700 - val_loss: 9.2251\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5397 - loss: 8.8152 \n",
            "Epoch 2: val_accuracy improved from 0.47000 to 0.48000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5384 - loss: 8.7835 - val_accuracy: 0.4800 - val_loss: 7.6049\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5104 - loss: 7.2870\n",
            "Epoch 3: val_accuracy improved from 0.48000 to 0.52000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5101 - loss: 7.2752 - val_accuracy: 0.5200 - val_loss: 6.3701\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5148 - loss: 6.1272\n",
            "Epoch 4: val_accuracy improved from 0.52000 to 0.68000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5155 - loss: 6.1129 - val_accuracy: 0.6800 - val_loss: 5.3956\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5301 - loss: 5.1968\n",
            "Epoch 5: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5302 - loss: 5.1894 - val_accuracy: 0.6400 - val_loss: 4.6148\n",
            "Epoch 6/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5467 - loss: 4.4580\n",
            "Epoch 6: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5468 - loss: 4.4487 - val_accuracy: 0.6400 - val_loss: 3.9651\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5493 - loss: 3.8491\n",
            "Epoch 7: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5503 - loss: 3.8440 - val_accuracy: 0.6200 - val_loss: 3.4480\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6212 - loss: 3.3267\n",
            "Epoch 8: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6211 - loss: 3.3230 - val_accuracy: 0.6700 - val_loss: 3.0279\n",
            "Epoch 9/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6549 - loss: 2.9257\n",
            "Epoch 9: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6561 - loss: 2.9129 - val_accuracy: 0.6500 - val_loss: 2.6753\n",
            "Epoch 10/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6586 - loss: 2.5822\n",
            "Epoch 10: val_accuracy improved from 0.68000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6597 - loss: 2.5763 - val_accuracy: 0.7200 - val_loss: 2.3365\n",
            "Epoch 11/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7158 - loss: 2.2617\n",
            "Epoch 11: val_accuracy improved from 0.72000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7152 - loss: 2.2575 - val_accuracy: 0.7300 - val_loss: 2.1086\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6565 - loss: 2.0753\n",
            "Epoch 12: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6580 - loss: 2.0721 - val_accuracy: 0.6200 - val_loss: 1.9171\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6955 - loss: 1.8419\n",
            "Epoch 13: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6962 - loss: 1.8400 - val_accuracy: 0.6300 - val_loss: 1.7427\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 1.6428\n",
            "Epoch 14: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7371 - loss: 1.6417 - val_accuracy: 0.5200 - val_loss: 1.6699\n",
            "Epoch 15/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7204 - loss: 1.5339\n",
            "Epoch 15: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7209 - loss: 1.5314 - val_accuracy: 0.7000 - val_loss: 1.4328\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7353 - loss: 1.3762\n",
            "Epoch 16: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7350 - loss: 1.3754 - val_accuracy: 0.6600 - val_loss: 1.3360\n",
            "Epoch 17/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 1.2733\n",
            "Epoch 17: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7412 - loss: 1.2724 - val_accuracy: 0.7300 - val_loss: 1.2477\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7545 - loss: 1.1790\n",
            "Epoch 18: val_accuracy improved from 0.73000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7540 - loss: 1.1784 - val_accuracy: 0.7500 - val_loss: 1.1442\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7716 - loss: 1.0870\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7711 - loss: 1.0866 - val_accuracy: 0.7500 - val_loss: 1.0924\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7420 - loss: 1.0394\n",
            "Epoch 20: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7418 - loss: 1.0394 - val_accuracy: 0.7100 - val_loss: 1.0254\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7527 - loss: 0.9757\n",
            "Epoch 21: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7523 - loss: 0.9752 - val_accuracy: 0.7200 - val_loss: 0.9648\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7634 - loss: 0.9059\n",
            "Epoch 22: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7628 - loss: 0.9064 - val_accuracy: 0.7100 - val_loss: 0.9601\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 0.8931\n",
            "Epoch 23: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7479 - loss: 0.8931 - val_accuracy: 0.6700 - val_loss: 0.9426\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7657 - loss: 0.8527\n",
            "Epoch 24: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7656 - loss: 0.8524 - val_accuracy: 0.7000 - val_loss: 0.8499\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7803 - loss: 0.7979\n",
            "Epoch 25: val_accuracy improved from 0.75000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7794 - loss: 0.7985 - val_accuracy: 0.7600 - val_loss: 0.8465\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7757 - loss: 0.7666\n",
            "Epoch 26: val_accuracy improved from 0.76000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7753 - loss: 0.7669 - val_accuracy: 0.7700 - val_loss: 0.7998\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7721 - loss: 0.7486\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7718 - loss: 0.7489 - val_accuracy: 0.7500 - val_loss: 0.8151\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7657 - loss: 0.7475\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7655 - loss: 0.7474 - val_accuracy: 0.7200 - val_loss: 0.8180\n",
            "Epoch 29/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.7224\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7674 - loss: 0.7236 - val_accuracy: 0.7400 - val_loss: 0.7761\n",
            "Epoch 30/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7584 - loss: 0.7261\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7585 - loss: 0.7254 - val_accuracy: 0.6900 - val_loss: 0.7743\n",
            "Epoch 31/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7612 - loss: 0.7028\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7630 - loss: 0.7008 - val_accuracy: 0.7300 - val_loss: 0.7674\n",
            "Epoch 32/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7623 - loss: 0.7010\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7615 - loss: 0.7008 - val_accuracy: 0.7400 - val_loss: 0.7222\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7668 - loss: 0.6801\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7667 - loss: 0.6804 - val_accuracy: 0.7000 - val_loss: 0.7451\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7811 - loss: 0.6614\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7811 - loss: 0.6612 - val_accuracy: 0.6900 - val_loss: 0.7489\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7699 - loss: 0.6482\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7698 - loss: 0.6486 - val_accuracy: 0.6600 - val_loss: 0.7227\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7849 - loss: 0.6333\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7843 - loss: 0.6342 - val_accuracy: 0.7000 - val_loss: 0.7138\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7790 - loss: 0.6499\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7790 - loss: 0.6498 - val_accuracy: 0.7200 - val_loss: 0.7479\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7776 - loss: 0.6380\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7773 - loss: 0.6384 - val_accuracy: 0.7200 - val_loss: 0.6997\n",
            "Epoch 39/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7934 - loss: 0.6178\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7925 - loss: 0.6191 - val_accuracy: 0.7500 - val_loss: 0.6810\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7696 - loss: 0.6289\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7693 - loss: 0.6293 - val_accuracy: 0.7400 - val_loss: 0.6891\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7740 - loss: 0.6364\n",
            "Epoch 41: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7738 - loss: 0.6363 - val_accuracy: 0.7200 - val_loss: 0.7169\n",
            "Epoch 42/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7921 - loss: 0.6305\n",
            "Epoch 42: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7915 - loss: 0.6311 - val_accuracy: 0.7200 - val_loss: 0.7046\n",
            "Epoch 43/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.6270\n",
            "Epoch 43: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7712 - loss: 0.6277 - val_accuracy: 0.7500 - val_loss: 0.6924\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7906 - loss: 0.6083\n",
            "Epoch 44: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7904 - loss: 0.6089 - val_accuracy: 0.7400 - val_loss: 0.6769\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7844 - loss: 0.6123\n",
            "Epoch 45: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7841 - loss: 0.6125 - val_accuracy: 0.7500 - val_loss: 0.6893\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.6401\n",
            "Epoch 46: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7716 - loss: 0.6398 - val_accuracy: 0.7400 - val_loss: 0.6697\n",
            "Epoch 46: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "41 / 50\n",
            "\n",
            "--- Fold 42 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4946 - loss: 21.1362\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 145ms/step - accuracy: 0.4946 - loss: 20.9910 - val_accuracy: 0.4800 - val_loss: 9.6090\n",
            "Epoch 2/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5108 - loss: 9.2651\n",
            "Epoch 2: val_accuracy improved from 0.48000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.5108 - loss: 9.2588 - val_accuracy: 0.5400 - val_loss: 8.2856\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5100 - loss: 8.0179\n",
            "Epoch 3: val_accuracy did not improve from 0.54000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5100 - loss: 8.0077 - val_accuracy: 0.4800 - val_loss: 7.2222\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5053 - loss: 7.0039\n",
            "Epoch 4: val_accuracy improved from 0.54000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5053 - loss: 6.9910 - val_accuracy: 0.5500 - val_loss: 6.3364\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5339 - loss: 6.1475\n",
            "Epoch 5: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5335 - loss: 6.1404 - val_accuracy: 0.5300 - val_loss: 5.5926\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5287 - loss: 5.4334\n",
            "Epoch 6: val_accuracy improved from 0.55000 to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5289 - loss: 5.4274 - val_accuracy: 0.5900 - val_loss: 4.9612\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5386 - loss: 4.8283\n",
            "Epoch 7: val_accuracy improved from 0.59000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5384 - loss: 4.8205 - val_accuracy: 0.6100 - val_loss: 4.4204\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5395 - loss: 4.3054\n",
            "Epoch 8: val_accuracy improved from 0.61000 to 0.68000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5399 - loss: 4.3009 - val_accuracy: 0.6800 - val_loss: 3.9448\n",
            "Epoch 9/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5672 - loss: 3.8578\n",
            "Epoch 9: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5671 - loss: 3.8521 - val_accuracy: 0.5500 - val_loss: 3.5550\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 3.4711\n",
            "Epoch 10: val_accuracy improved from 0.68000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5632 - loss: 3.4676 - val_accuracy: 0.7500 - val_loss: 3.1878\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5957 - loss: 3.1236\n",
            "Epoch 11: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5959 - loss: 3.1206 - val_accuracy: 0.6900 - val_loss: 2.8895\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6431 - loss: 2.8224\n",
            "Epoch 12: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6433 - loss: 2.8198 - val_accuracy: 0.6800 - val_loss: 2.5922\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6619 - loss: 2.5577\n",
            "Epoch 13: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6618 - loss: 2.5556 - val_accuracy: 0.5900 - val_loss: 2.3944\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6894 - loss: 2.3260\n",
            "Epoch 14: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6895 - loss: 2.3230 - val_accuracy: 0.6500 - val_loss: 2.2159\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6820 - loss: 2.1423\n",
            "Epoch 15: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6822 - loss: 2.1405 - val_accuracy: 0.6700 - val_loss: 1.9866\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7066 - loss: 1.9454\n",
            "Epoch 16: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7064 - loss: 1.9442 - val_accuracy: 0.6900 - val_loss: 1.8380\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6832 - loss: 1.8228\n",
            "Epoch 17: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6840 - loss: 1.8212 - val_accuracy: 0.6500 - val_loss: 1.7387\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 1.6669\n",
            "Epoch 18: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7184 - loss: 1.6660 - val_accuracy: 0.6900 - val_loss: 1.5955\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7261 - loss: 1.5537\n",
            "Epoch 19: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7261 - loss: 1.5526 - val_accuracy: 0.7100 - val_loss: 1.4843\n",
            "Epoch 20/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7221 - loss: 1.4420\n",
            "Epoch 20: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7216 - loss: 1.4408 - val_accuracy: 0.7200 - val_loss: 1.3877\n",
            "Epoch 21/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7182 - loss: 1.3769\n",
            "Epoch 21: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 1.3726 - val_accuracy: 0.6600 - val_loss: 1.3408\n",
            "Epoch 22/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7245 - loss: 1.2742\n",
            "Epoch 22: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7245 - loss: 1.2729 - val_accuracy: 0.7000 - val_loss: 1.2403\n",
            "Epoch 23/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7461 - loss: 1.1922\n",
            "Epoch 23: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7445 - loss: 1.1919 - val_accuracy: 0.7200 - val_loss: 1.1781\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7373 - loss: 1.1375\n",
            "Epoch 24: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7371 - loss: 1.1373 - val_accuracy: 0.7100 - val_loss: 1.1236\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7585 - loss: 1.0650\n",
            "Epoch 25: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7575 - loss: 1.0651 - val_accuracy: 0.7100 - val_loss: 1.0796\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7524 - loss: 1.0237\n",
            "Epoch 26: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7520 - loss: 1.0239 - val_accuracy: 0.7000 - val_loss: 1.0281\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7485 - loss: 0.9791\n",
            "Epoch 27: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7483 - loss: 0.9790 - val_accuracy: 0.7000 - val_loss: 0.9927\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7282 - loss: 0.9601\n",
            "Epoch 28: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7282 - loss: 0.9597 - val_accuracy: 0.6700 - val_loss: 0.9849\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7403 - loss: 0.9191\n",
            "Epoch 29: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7401 - loss: 0.9189 - val_accuracy: 0.6900 - val_loss: 0.9448\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7464 - loss: 0.8901\n",
            "Epoch 30: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7457 - loss: 0.8903 - val_accuracy: 0.7100 - val_loss: 0.9143\n",
            "Epoch 30: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "42 / 50\n",
            "\n",
            "--- Fold 43 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4910 - loss: 18.5872\n",
            "Epoch 1: val_accuracy improved from -inf to 0.44000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - accuracy: 0.4912 - loss: 18.4729 - val_accuracy: 0.4400 - val_loss: 9.2918\n",
            "Epoch 2/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5422 - loss: 8.9111\n",
            "Epoch 2: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5408 - loss: 8.8738 - val_accuracy: 0.4400 - val_loss: 7.7687\n",
            "Epoch 3/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5137 - loss: 7.4837\n",
            "Epoch 3: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5153 - loss: 7.4547 - val_accuracy: 0.4400 - val_loss: 6.5976\n",
            "Epoch 4/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5101 - loss: 6.3789\n",
            "Epoch 4: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5141 - loss: 6.3461 - val_accuracy: 0.4400 - val_loss: 5.6601\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5435 - loss: 5.4582\n",
            "Epoch 5: val_accuracy did not improve from 0.44000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5435 - loss: 5.4509 - val_accuracy: 0.4300 - val_loss: 4.8936\n",
            "Epoch 6/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5387 - loss: 4.7455\n",
            "Epoch 6: val_accuracy improved from 0.44000 to 0.60000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5394 - loss: 4.7263 - val_accuracy: 0.6000 - val_loss: 4.2450\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5991 - loss: 4.1175\n",
            "Epoch 7: val_accuracy did not improve from 0.60000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5988 - loss: 4.1126 - val_accuracy: 0.4800 - val_loss: 3.7389\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5562 - loss: 3.6275\n",
            "Epoch 8: val_accuracy improved from 0.60000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5578 - loss: 3.6227 - val_accuracy: 0.7600 - val_loss: 3.2224\n",
            "Epoch 9/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6276 - loss: 3.1758\n",
            "Epoch 9: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6269 - loss: 3.1711 - val_accuracy: 0.6600 - val_loss: 2.9215\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6558 - loss: 2.8309\n",
            "Epoch 10: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6554 - loss: 2.8278 - val_accuracy: 0.7200 - val_loss: 2.5661\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6566 - loss: 2.5114\n",
            "Epoch 11: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6561 - loss: 2.5081 - val_accuracy: 0.7300 - val_loss: 2.2951\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6524 - loss: 2.2626\n",
            "Epoch 12: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6526 - loss: 2.2606 - val_accuracy: 0.7400 - val_loss: 2.0616\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6601 - loss: 2.0475\n",
            "Epoch 13: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6603 - loss: 2.0455 - val_accuracy: 0.7400 - val_loss: 1.8827\n",
            "Epoch 14/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6931 - loss: 1.8661\n",
            "Epoch 14: val_accuracy improved from 0.76000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6930 - loss: 1.8634 - val_accuracy: 0.7800 - val_loss: 1.7145\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6861 - loss: 1.6964\n",
            "Epoch 15: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6860 - loss: 1.6951 - val_accuracy: 0.7400 - val_loss: 1.5409\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6934 - loss: 1.5558\n",
            "Epoch 16: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6931 - loss: 1.5547 - val_accuracy: 0.6400 - val_loss: 1.4969\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6972 - loss: 1.4333\n",
            "Epoch 17: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6972 - loss: 1.4324 - val_accuracy: 0.7300 - val_loss: 1.3301\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7030 - loss: 1.3208\n",
            "Epoch 18: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7029 - loss: 1.3204 - val_accuracy: 0.7700 - val_loss: 1.2503\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6778 - loss: 1.2748\n",
            "Epoch 19: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6785 - loss: 1.2734 - val_accuracy: 0.7400 - val_loss: 1.1326\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7064 - loss: 1.1558\n",
            "Epoch 20: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7059 - loss: 1.1558 - val_accuracy: 0.7000 - val_loss: 1.1355\n",
            "Epoch 21/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7128 - loss: 1.1042\n",
            "Epoch 21: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7118 - loss: 1.1039 - val_accuracy: 0.7300 - val_loss: 1.0556\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7190 - loss: 1.0320\n",
            "Epoch 22: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7187 - loss: 1.0318 - val_accuracy: 0.7400 - val_loss: 1.0151\n",
            "Epoch 23/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 0.9872\n",
            "Epoch 23: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7184 - loss: 0.9868 - val_accuracy: 0.7900 - val_loss: 0.9316\n",
            "Epoch 24/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6915 - loss: 0.9600\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6923 - loss: 0.9589 - val_accuracy: 0.6700 - val_loss: 0.9379\n",
            "Epoch 25/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6988 - loss: 0.9240\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6989 - loss: 0.9235 - val_accuracy: 0.7500 - val_loss: 0.8561\n",
            "Epoch 26/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7180 - loss: 0.8669\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7180 - loss: 0.8671 - val_accuracy: 0.7400 - val_loss: 0.8400\n",
            "Epoch 27/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7207 - loss: 0.8324\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7208 - loss: 0.8323 - val_accuracy: 0.7700 - val_loss: 0.7939\n",
            "Epoch 28/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7360 - loss: 0.8021\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7352 - loss: 0.8022 - val_accuracy: 0.7500 - val_loss: 0.7565\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7216 - loss: 0.7812\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7216 - loss: 0.7815 - val_accuracy: 0.7400 - val_loss: 0.7826\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7539 - loss: 0.7524\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7529 - loss: 0.7530 - val_accuracy: 0.6800 - val_loss: 0.8286\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7207 - loss: 0.7639\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7210 - loss: 0.7635 - val_accuracy: 0.7500 - val_loss: 0.7384\n",
            "Epoch 32/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7165 - loss: 0.7485\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7168 - loss: 0.7482 - val_accuracy: 0.7300 - val_loss: 0.7505\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7306 - loss: 0.7378\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7306 - loss: 0.7372 - val_accuracy: 0.7500 - val_loss: 0.7275\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7351 - loss: 0.7066\n",
            "Epoch 34: val_accuracy improved from 0.79000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7349 - loss: 0.7069 - val_accuracy: 0.8000 - val_loss: 0.6838\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7488 - loss: 0.6834\n",
            "Epoch 35: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7484 - loss: 0.6840 - val_accuracy: 0.7500 - val_loss: 0.7111\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7298 - loss: 0.6977\n",
            "Epoch 36: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7299 - loss: 0.6975 - val_accuracy: 0.7200 - val_loss: 0.7122\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7504 - loss: 0.6734\n",
            "Epoch 37: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7499 - loss: 0.6739 - val_accuracy: 0.6600 - val_loss: 0.7442\n",
            "Epoch 38/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7363 - loss: 0.6815\n",
            "Epoch 38: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7362 - loss: 0.6815 - val_accuracy: 0.7900 - val_loss: 0.6714\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7502 - loss: 0.6642\n",
            "Epoch 39: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7495 - loss: 0.6648 - val_accuracy: 0.7800 - val_loss: 0.6595\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7391 - loss: 0.6599\n",
            "Epoch 40: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7389 - loss: 0.6603 - val_accuracy: 0.7800 - val_loss: 0.6441\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 0.6711\n",
            "Epoch 41: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7346 - loss: 0.6712 - val_accuracy: 0.7300 - val_loss: 0.6985\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7494 - loss: 0.6506\n",
            "Epoch 42: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7488 - loss: 0.6508 - val_accuracy: 0.7600 - val_loss: 0.6260\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7441 - loss: 0.6425\n",
            "Epoch 43: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7436 - loss: 0.6431 - val_accuracy: 0.7900 - val_loss: 0.6289\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7396 - loss: 0.6448\n",
            "Epoch 44: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7397 - loss: 0.6447 - val_accuracy: 0.7500 - val_loss: 0.6484\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7440 - loss: 0.6586\n",
            "Epoch 45: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7438 - loss: 0.6586 - val_accuracy: 0.7300 - val_loss: 0.6935\n",
            "Epoch 46/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7556 - loss: 0.6343\n",
            "Epoch 46: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7553 - loss: 0.6343 - val_accuracy: 0.7800 - val_loss: 0.6317\n",
            "Epoch 47/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7453 - loss: 0.6324\n",
            "Epoch 47: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7447 - loss: 0.6340 - val_accuracy: 0.7600 - val_loss: 0.6347\n",
            "Epoch 48/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7345 - loss: 0.6410\n",
            "Epoch 48: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7345 - loss: 0.6412 - val_accuracy: 0.8000 - val_loss: 0.6186\n",
            "Epoch 49/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7393 - loss: 0.6416\n",
            "Epoch 49: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7390 - loss: 0.6424 - val_accuracy: 0.7900 - val_loss: 0.6358\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7481 - loss: 0.6287\n",
            "Epoch 50: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7480 - loss: 0.6287 - val_accuracy: 0.6800 - val_loss: 0.7114\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
            "43 / 50\n",
            "\n",
            "--- Fold 44 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5172 - loss: 15.6067\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - accuracy: 0.5170 - loss: 15.5334 - val_accuracy: 0.5200 - val_loss: 9.3054\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5094 - loss: 8.9072 \n",
            "Epoch 2: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5093 - loss: 8.8757 - val_accuracy: 0.5200 - val_loss: 7.6982\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4993 - loss: 7.3789\n",
            "Epoch 3: val_accuracy did not improve from 0.52000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4996 - loss: 7.3668 - val_accuracy: 0.5200 - val_loss: 6.4445\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5221 - loss: 6.1896\n",
            "Epoch 4: val_accuracy improved from 0.52000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5222 - loss: 6.1800 - val_accuracy: 0.5500 - val_loss: 5.4446\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5151 - loss: 5.2428\n",
            "Epoch 5: val_accuracy improved from 0.55000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5154 - loss: 5.2350 - val_accuracy: 0.6100 - val_loss: 4.6402\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5465 - loss: 4.4730\n",
            "Epoch 6: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5460 - loss: 4.4668 - val_accuracy: 0.5800 - val_loss: 3.9844\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5484 - loss: 3.8469\n",
            "Epoch 7: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5489 - loss: 3.8417 - val_accuracy: 0.6000 - val_loss: 3.4395\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5720 - loss: 3.3325\n",
            "Epoch 8: val_accuracy improved from 0.61000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5725 - loss: 3.3280 - val_accuracy: 0.7500 - val_loss: 2.9587\n",
            "Epoch 9/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6176 - loss: 2.8897\n",
            "Epoch 9: val_accuracy improved from 0.75000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6187 - loss: 2.8828 - val_accuracy: 0.7900 - val_loss: 2.5708\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6576 - loss: 2.5352\n",
            "Epoch 10: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6580 - loss: 2.5320 - val_accuracy: 0.6300 - val_loss: 2.3013\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6809 - loss: 2.2330\n",
            "Epoch 11: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6810 - loss: 2.2303 - val_accuracy: 0.7400 - val_loss: 1.9843\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6872 - loss: 1.9928\n",
            "Epoch 12: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6876 - loss: 1.9906 - val_accuracy: 0.6700 - val_loss: 1.8130\n",
            "Epoch 13/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7121 - loss: 1.7807\n",
            "Epoch 13: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7123 - loss: 1.7778 - val_accuracy: 0.7400 - val_loss: 1.6271\n",
            "Epoch 14/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7104 - loss: 1.5988\n",
            "Epoch 14: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7107 - loss: 1.5979 - val_accuracy: 0.7300 - val_loss: 1.4537\n",
            "Epoch 15/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7264 - loss: 1.4563\n",
            "Epoch 15: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7269 - loss: 1.4525 - val_accuracy: 0.6700 - val_loss: 1.3684\n",
            "Epoch 16/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7438 - loss: 1.3040\n",
            "Epoch 16: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7435 - loss: 1.3017 - val_accuracy: 0.7400 - val_loss: 1.2395\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7211 - loss: 1.2265\n",
            "Epoch 17: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7212 - loss: 1.2256 - val_accuracy: 0.7000 - val_loss: 1.1401\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7446 - loss: 1.1211\n",
            "Epoch 18: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7442 - loss: 1.1208 - val_accuracy: 0.7200 - val_loss: 1.0715\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7429 - loss: 1.0470\n",
            "Epoch 19: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7428 - loss: 1.0466 - val_accuracy: 0.7500 - val_loss: 1.0106\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7392 - loss: 0.9982\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7388 - loss: 0.9981 - val_accuracy: 0.7500 - val_loss: 0.9695\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7355 - loss: 0.9427\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7361 - loss: 0.9418 - val_accuracy: 0.7500 - val_loss: 0.8983\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7610 - loss: 0.8670\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7605 - loss: 0.8675 - val_accuracy: 0.7000 - val_loss: 0.8868\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7586 - loss: 0.8331\n",
            "Epoch 23: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7579 - loss: 0.8336 - val_accuracy: 0.7900 - val_loss: 0.8320\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7659 - loss: 0.7986\n",
            "Epoch 24: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7658 - loss: 0.7985 - val_accuracy: 0.6800 - val_loss: 0.8484\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7664 - loss: 0.7694\n",
            "Epoch 25: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7660 - loss: 0.7697 - val_accuracy: 0.7700 - val_loss: 0.7806\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7655 - loss: 0.7361\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7646 - loss: 0.7371 - val_accuracy: 0.6000 - val_loss: 0.8232\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7530 - loss: 0.7363\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7530 - loss: 0.7360 - val_accuracy: 0.7100 - val_loss: 0.7554\n",
            "Epoch 28/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7516 - loss: 0.7277\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7524 - loss: 0.7270 - val_accuracy: 0.7900 - val_loss: 0.7370\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7585 - loss: 0.6980\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7585 - loss: 0.6982 - val_accuracy: 0.7200 - val_loss: 0.7281\n",
            "Epoch 29: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "44 / 50\n",
            "\n",
            "--- Fold 45 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.4962 - loss: 19.6334\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 159ms/step - accuracy: 0.4963 - loss: 19.5058 - val_accuracy: 0.5300 - val_loss: 9.4619\n",
            "Epoch 2/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5055 - loss: 9.1055\n",
            "Epoch 2: val_accuracy did not improve from 0.53000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.5059 - loss: 9.0846 - val_accuracy: 0.5100 - val_loss: 8.0360\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4886 - loss: 7.7500\n",
            "Epoch 3: val_accuracy improved from 0.53000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4893 - loss: 7.7390 - val_accuracy: 0.5500 - val_loss: 6.9011\n",
            "Epoch 4/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5391 - loss: 6.6831\n",
            "Epoch 4: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5387 - loss: 6.6557 - val_accuracy: 0.5400 - val_loss: 5.9746\n",
            "Epoch 5/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5487 - loss: 5.7823\n",
            "Epoch 5: val_accuracy did not improve from 0.55000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5483 - loss: 5.7712 - val_accuracy: 0.5500 - val_loss: 5.2112\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5242 - loss: 5.0528\n",
            "Epoch 6: val_accuracy improved from 0.55000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5248 - loss: 5.0466 - val_accuracy: 0.6400 - val_loss: 4.5682\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 4.4362\n",
            "Epoch 7: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5668 - loss: 4.4310 - val_accuracy: 0.6200 - val_loss: 4.0216\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5870 - loss: 3.9197\n",
            "Epoch 8: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5866 - loss: 3.9155 - val_accuracy: 0.6400 - val_loss: 3.5762\n",
            "Epoch 9/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6255 - loss: 3.4686\n",
            "Epoch 9: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6260 - loss: 3.4629 - val_accuracy: 0.6300 - val_loss: 3.1574\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6705 - loss: 3.0826\n",
            "Epoch 10: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6702 - loss: 3.0797 - val_accuracy: 0.6300 - val_loss: 2.8496\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6934 - loss: 2.7640\n",
            "Epoch 11: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6933 - loss: 2.7614 - val_accuracy: 0.5800 - val_loss: 2.5838\n",
            "Epoch 12/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6691 - loss: 2.5145\n",
            "Epoch 12: val_accuracy improved from 0.64000 to 0.68000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6698 - loss: 2.5107 - val_accuracy: 0.6800 - val_loss: 2.3055\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6895 - loss: 2.2668\n",
            "Epoch 13: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6891 - loss: 2.2653 - val_accuracy: 0.6300 - val_loss: 2.1391\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6978 - loss: 2.0639\n",
            "Epoch 14: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6979 - loss: 2.0620 - val_accuracy: 0.6400 - val_loss: 1.9488\n",
            "Epoch 15/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6842 - loss: 1.8994\n",
            "Epoch 15: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6846 - loss: 1.8968 - val_accuracy: 0.6700 - val_loss: 1.7820\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7082 - loss: 1.7323\n",
            "Epoch 16: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7082 - loss: 1.7309 - val_accuracy: 0.6700 - val_loss: 1.6398\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7212 - loss: 1.5877\n",
            "Epoch 17: val_accuracy did not improve from 0.68000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7211 - loss: 1.5868 - val_accuracy: 0.6100 - val_loss: 1.5602\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7146 - loss: 1.4905\n",
            "Epoch 18: val_accuracy improved from 0.68000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7144 - loss: 1.4897 - val_accuracy: 0.7300 - val_loss: 1.3999\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7117 - loss: 1.3762\n",
            "Epoch 19: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7113 - loss: 1.3759 - val_accuracy: 0.6900 - val_loss: 1.3380\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7352 - loss: 1.2761\n",
            "Epoch 20: val_accuracy improved from 0.73000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7346 - loss: 1.2756 - val_accuracy: 0.7700 - val_loss: 1.2399\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 1.2079\n",
            "Epoch 21: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7342 - loss: 1.2076 - val_accuracy: 0.7100 - val_loss: 1.1879\n",
            "Epoch 22/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7136 - loss: 1.1559\n",
            "Epoch 22: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7142 - loss: 1.1542 - val_accuracy: 0.6300 - val_loss: 1.1426\n",
            "Epoch 23/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7415 - loss: 1.0716\n",
            "Epoch 23: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7413 - loss: 1.0715 - val_accuracy: 0.7000 - val_loss: 1.0430\n",
            "Epoch 24/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7439 - loss: 1.0141\n",
            "Epoch 24: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7416 - loss: 1.0152 - val_accuracy: 0.7700 - val_loss: 1.0108\n",
            "Epoch 25/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7197 - loss: 0.9928\n",
            "Epoch 25: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 0.9912 - val_accuracy: 0.7200 - val_loss: 0.9588\n",
            "Epoch 26/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7412 - loss: 0.9290\n",
            "Epoch 26: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7408 - loss: 0.9285 - val_accuracy: 0.7000 - val_loss: 0.9093\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7223 - loss: 0.9195\n",
            "Epoch 27: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7224 - loss: 0.9191 - val_accuracy: 0.6100 - val_loss: 0.9424\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7400 - loss: 0.8749\n",
            "Epoch 28: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7399 - loss: 0.8745 - val_accuracy: 0.7400 - val_loss: 0.8817\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7292 - loss: 0.8624\n",
            "Epoch 29: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7297 - loss: 0.8614 - val_accuracy: 0.6600 - val_loss: 0.8503\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7351 - loss: 0.8145\n",
            "Epoch 30: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7353 - loss: 0.8145 - val_accuracy: 0.6900 - val_loss: 0.8373\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7367 - loss: 0.7965\n",
            "Epoch 31: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7366 - loss: 0.7962 - val_accuracy: 0.7500 - val_loss: 0.8072\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.7787\n",
            "Epoch 32: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7335 - loss: 0.7783 - val_accuracy: 0.7400 - val_loss: 0.7987\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7282 - loss: 0.7665\n",
            "Epoch 33: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7284 - loss: 0.7663 - val_accuracy: 0.6800 - val_loss: 0.8007\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7263 - loss: 0.7502\n",
            "Epoch 34: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7266 - loss: 0.7499 - val_accuracy: 0.6400 - val_loss: 0.8020\n",
            "Epoch 35/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7387 - loss: 0.7325\n",
            "Epoch 35: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7382 - loss: 0.7327 - val_accuracy: 0.6800 - val_loss: 0.7681\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7849 - loss: 0.6827\n",
            "Epoch 36: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7842 - loss: 0.6833 - val_accuracy: 0.6400 - val_loss: 0.8005\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7309 - loss: 0.7212\n",
            "Epoch 37: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7311 - loss: 0.7210 - val_accuracy: 0.6500 - val_loss: 0.7783\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7335 - loss: 0.7119\n",
            "Epoch 38: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7337 - loss: 0.7115 - val_accuracy: 0.6700 - val_loss: 0.7514\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7477 - loss: 0.6837\n",
            "Epoch 39: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7475 - loss: 0.6840 - val_accuracy: 0.7300 - val_loss: 0.7235\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7490 - loss: 0.6643\n",
            "Epoch 40: val_accuracy did not improve from 0.77000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7489 - loss: 0.6647 - val_accuracy: 0.7300 - val_loss: 0.6999\n",
            "Epoch 40: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
            "45 / 50\n",
            "\n",
            "--- Fold 46 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.4941 - loss: 21.1031\n",
            "Epoch 1: val_accuracy improved from -inf to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 146ms/step - accuracy: 0.4940 - loss: 20.9577 - val_accuracy: 0.5900 - val_loss: 9.6743\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5091 - loss: 9.3552\n",
            "Epoch 2: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5086 - loss: 9.3149 - val_accuracy: 0.5200 - val_loss: 8.3142\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4924 - loss: 8.0384\n",
            "Epoch 3: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4930 - loss: 8.0278 - val_accuracy: 0.5500 - val_loss: 7.2146\n",
            "Epoch 4/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5144 - loss: 6.9895\n",
            "Epoch 4: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5143 - loss: 6.9763 - val_accuracy: 0.5700 - val_loss: 6.3038\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5229 - loss: 6.1115\n",
            "Epoch 5: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5228 - loss: 6.1042 - val_accuracy: 0.5800 - val_loss: 5.5413\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5235 - loss: 5.3791\n",
            "Epoch 6: val_accuracy improved from 0.59000 to 0.63000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5234 - loss: 5.3729 - val_accuracy: 0.6300 - val_loss: 4.8968\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5394 - loss: 4.7591\n",
            "Epoch 7: val_accuracy improved from 0.63000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5393 - loss: 4.7538 - val_accuracy: 0.7000 - val_loss: 4.3460\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5641 - loss: 4.2271\n",
            "Epoch 8: val_accuracy improved from 0.70000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5639 - loss: 4.2227 - val_accuracy: 0.7400 - val_loss: 3.8578\n",
            "Epoch 9/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5903 - loss: 3.7707\n",
            "Epoch 9: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5904 - loss: 3.7629 - val_accuracy: 0.7400 - val_loss: 3.4114\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5939 - loss: 3.3829\n",
            "Epoch 10: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5941 - loss: 3.3795 - val_accuracy: 0.7400 - val_loss: 3.0715\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6281 - loss: 3.0237\n",
            "Epoch 11: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6276 - loss: 3.0200 - val_accuracy: 0.6800 - val_loss: 2.7774\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6276 - loss: 2.7444\n",
            "Epoch 12: val_accuracy improved from 0.74000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6279 - loss: 2.7419 - val_accuracy: 0.7800 - val_loss: 2.4841\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6628 - loss: 2.4747\n",
            "Epoch 13: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6631 - loss: 2.4725 - val_accuracy: 0.7300 - val_loss: 2.2517\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6844 - loss: 2.2645\n",
            "Epoch 14: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6845 - loss: 2.2627 - val_accuracy: 0.7400 - val_loss: 2.0640\n",
            "Epoch 15/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7110 - loss: 2.0475\n",
            "Epoch 15: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7108 - loss: 2.0456 - val_accuracy: 0.7100 - val_loss: 1.9161\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6903 - loss: 1.8959\n",
            "Epoch 16: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6904 - loss: 1.8945 - val_accuracy: 0.7400 - val_loss: 1.7413\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7166 - loss: 1.7449\n",
            "Epoch 17: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7161 - loss: 1.7439 - val_accuracy: 0.7300 - val_loss: 1.6124\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7239 - loss: 1.6162\n",
            "Epoch 18: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7237 - loss: 1.6143 - val_accuracy: 0.7500 - val_loss: 1.4924\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7096 - loss: 1.5103\n",
            "Epoch 19: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7100 - loss: 1.5089 - val_accuracy: 0.7500 - val_loss: 1.3967\n",
            "Epoch 20/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7219 - loss: 1.4033\n",
            "Epoch 20: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7219 - loss: 1.4009 - val_accuracy: 0.7200 - val_loss: 1.3217\n",
            "Epoch 21/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7261 - loss: 1.3005\n",
            "Epoch 21: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7260 - loss: 1.3005 - val_accuracy: 0.7000 - val_loss: 1.2298\n",
            "Epoch 22/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7046 - loss: 1.2670\n",
            "Epoch 22: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7071 - loss: 1.2618 - val_accuracy: 0.7300 - val_loss: 1.1494\n",
            "Epoch 23/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7314 - loss: 1.1620\n",
            "Epoch 23: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7308 - loss: 1.1616 - val_accuracy: 0.7700 - val_loss: 1.1086\n",
            "Epoch 24/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7305 - loss: 1.1037\n",
            "Epoch 24: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7310 - loss: 1.1028 - val_accuracy: 0.7000 - val_loss: 1.0524\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7278 - loss: 1.0501\n",
            "Epoch 25: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7278 - loss: 1.0499 - val_accuracy: 0.6100 - val_loss: 1.0717\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7132 - loss: 1.0177\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7138 - loss: 1.0169 - val_accuracy: 0.7100 - val_loss: 0.9379\n",
            "Epoch 27/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7464 - loss: 0.9539\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7465 - loss: 0.9536 - val_accuracy: 0.7300 - val_loss: 0.9184\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7545 - loss: 0.9099\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7543 - loss: 0.9098 - val_accuracy: 0.7400 - val_loss: 0.9008\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7343 - loss: 0.9056\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7344 - loss: 0.9049 - val_accuracy: 0.7500 - val_loss: 0.8816\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7437 - loss: 0.8705\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7435 - loss: 0.8701 - val_accuracy: 0.7600 - val_loss: 0.8234\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7495 - loss: 0.8280\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7493 - loss: 0.8279 - val_accuracy: 0.7000 - val_loss: 0.8503\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7564 - loss: 0.8015\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7558 - loss: 0.8018 - val_accuracy: 0.6600 - val_loss: 0.8806\n",
            "Epoch 32: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "46 / 50\n",
            "\n",
            "--- Fold 47 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4878 - loss: 18.3054\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 0.4879 - loss: 18.1940 - val_accuracy: 0.5100 - val_loss: 9.2815\n",
            "Epoch 2/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5139 - loss: 8.8803 \n",
            "Epoch 2: val_accuracy improved from 0.51000 to 0.54000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5134 - loss: 8.8488 - val_accuracy: 0.5400 - val_loss: 7.6771\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5143 - loss: 7.3635\n",
            "Epoch 3: val_accuracy improved from 0.54000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5144 - loss: 7.3518 - val_accuracy: 0.6100 - val_loss: 6.4574\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5280 - loss: 6.2123\n",
            "Epoch 4: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5281 - loss: 6.2031 - val_accuracy: 0.5500 - val_loss: 5.4994\n",
            "Epoch 5/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5337 - loss: 5.2989\n",
            "Epoch 5: val_accuracy improved from 0.61000 to 0.65000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5337 - loss: 5.2954 - val_accuracy: 0.6500 - val_loss: 4.7297\n",
            "Epoch 6/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5399 - loss: 4.5848\n",
            "Epoch 6: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5395 - loss: 4.5666 - val_accuracy: 0.5700 - val_loss: 4.1029\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5666 - loss: 3.9720\n",
            "Epoch 7: val_accuracy did not improve from 0.65000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5670 - loss: 3.9670 - val_accuracy: 0.5000 - val_loss: 3.5889\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5553 - loss: 3.4947\n",
            "Epoch 8: val_accuracy improved from 0.65000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5560 - loss: 3.4904 - val_accuracy: 0.7600 - val_loss: 3.1264\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5961 - loss: 3.0694\n",
            "Epoch 9: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5963 - loss: 3.0660 - val_accuracy: 0.7200 - val_loss: 2.7513\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6463 - loss: 2.7006\n",
            "Epoch 10: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6462 - loss: 2.6979 - val_accuracy: 0.7400 - val_loss: 2.4531\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6571 - loss: 2.4253\n",
            "Epoch 11: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6577 - loss: 2.4227 - val_accuracy: 0.6900 - val_loss: 2.2108\n",
            "Epoch 12/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6917 - loss: 2.1676\n",
            "Epoch 12: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6919 - loss: 2.1647 - val_accuracy: 0.7500 - val_loss: 2.0020\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6974 - loss: 1.9620\n",
            "Epoch 13: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6976 - loss: 1.9601 - val_accuracy: 0.7300 - val_loss: 1.7775\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7123 - loss: 1.7783\n",
            "Epoch 14: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7121 - loss: 1.7772 - val_accuracy: 0.7200 - val_loss: 1.6575\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7242 - loss: 1.6256\n",
            "Epoch 15: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7237 - loss: 1.6247 - val_accuracy: 0.7600 - val_loss: 1.5151\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6914 - loss: 1.5178\n",
            "Epoch 16: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6920 - loss: 1.5162 - val_accuracy: 0.7400 - val_loss: 1.4132\n",
            "Epoch 17/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7125 - loss: 1.3936\n",
            "Epoch 17: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7122 - loss: 1.3928 - val_accuracy: 0.6200 - val_loss: 1.3499\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7369 - loss: 1.2753\n",
            "Epoch 18: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7363 - loss: 1.2747 - val_accuracy: 0.6900 - val_loss: 1.2637\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7168 - loss: 1.2223\n",
            "Epoch 19: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7169 - loss: 1.2214 - val_accuracy: 0.7600 - val_loss: 1.1375\n",
            "Epoch 20/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7093 - loss: 1.1489\n",
            "Epoch 20: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7099 - loss: 1.1475 - val_accuracy: 0.7400 - val_loss: 1.1126\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7365 - loss: 1.0673\n",
            "Epoch 21: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7363 - loss: 1.0669 - val_accuracy: 0.7500 - val_loss: 1.0344\n",
            "Epoch 22/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7294 - loss: 1.0132\n",
            "Epoch 22: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7295 - loss: 1.0130 - val_accuracy: 0.7600 - val_loss: 1.0080\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 0.9585\n",
            "Epoch 23: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7479 - loss: 0.9586 - val_accuracy: 0.6000 - val_loss: 1.0300\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7193 - loss: 0.9518\n",
            "Epoch 24: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7200 - loss: 0.9505 - val_accuracy: 0.7400 - val_loss: 0.8945\n",
            "Epoch 25/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7505 - loss: 0.8771\n",
            "Epoch 25: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7489 - loss: 0.8778 - val_accuracy: 0.7300 - val_loss: 0.8994\n",
            "Epoch 26/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7421 - loss: 0.8520\n",
            "Epoch 26: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7417 - loss: 0.8517 - val_accuracy: 0.7200 - val_loss: 0.8426\n",
            "Epoch 27/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7577 - loss: 0.8124\n",
            "Epoch 27: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7554 - loss: 0.8142 - val_accuracy: 0.7300 - val_loss: 0.8433\n",
            "Epoch 28/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7232 - loss: 0.8231\n",
            "Epoch 28: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7251 - loss: 0.8210 - val_accuracy: 0.7100 - val_loss: 0.8401\n",
            "Epoch 28: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "47 / 50\n",
            "\n",
            "--- Fold 48 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5034 - loss: 18.0705\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - accuracy: 0.5033 - loss: 17.9651 - val_accuracy: 0.4500 - val_loss: 9.4108\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5115 - loss: 9.0499\n",
            "Epoch 2: val_accuracy improved from 0.45000 to 0.46000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5109 - loss: 9.0050 - val_accuracy: 0.4600 - val_loss: 7.8952\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4908 - loss: 7.5921\n",
            "Epoch 3: val_accuracy improved from 0.46000 to 0.49000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4911 - loss: 7.5806 - val_accuracy: 0.4900 - val_loss: 6.7035\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4990 - loss: 6.4611\n",
            "Epoch 4: val_accuracy did not improve from 0.49000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4994 - loss: 6.4518 - val_accuracy: 0.4500 - val_loss: 5.7434\n",
            "Epoch 5/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5273 - loss: 5.5467\n",
            "Epoch 5: val_accuracy did not improve from 0.49000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5272 - loss: 5.5353 - val_accuracy: 0.4700 - val_loss: 4.9586\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5367 - loss: 4.7935\n",
            "Epoch 6: val_accuracy improved from 0.49000 to 0.50000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5365 - loss: 4.7874 - val_accuracy: 0.5000 - val_loss: 4.3109\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5302 - loss: 4.1752\n",
            "Epoch 7: val_accuracy improved from 0.50000 to 0.64000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5297 - loss: 4.1674 - val_accuracy: 0.6400 - val_loss: 3.7700\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5341 - loss: 3.6588\n",
            "Epoch 8: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5344 - loss: 3.6545 - val_accuracy: 0.6200 - val_loss: 3.3162\n",
            "Epoch 9/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5744 - loss: 3.2254\n",
            "Epoch 9: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5741 - loss: 3.2197 - val_accuracy: 0.5900 - val_loss: 2.9243\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5829 - loss: 2.8556\n",
            "Epoch 10: val_accuracy did not improve from 0.64000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5826 - loss: 2.8526 - val_accuracy: 0.5200 - val_loss: 2.6278\n",
            "Epoch 11/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 2.5437\n",
            "Epoch 11: val_accuracy improved from 0.64000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6030 - loss: 2.5408 - val_accuracy: 0.7400 - val_loss: 2.2896\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6565 - loss: 2.2555\n",
            "Epoch 12: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6567 - loss: 2.2533 - val_accuracy: 0.6700 - val_loss: 2.0803\n",
            "Epoch 13/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6884 - loss: 2.0233\n",
            "Epoch 13: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6877 - loss: 2.0207 - val_accuracy: 0.7200 - val_loss: 1.8715\n",
            "Epoch 14/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6858 - loss: 1.8412\n",
            "Epoch 14: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6860 - loss: 1.8404 - val_accuracy: 0.6000 - val_loss: 1.7701\n",
            "Epoch 15/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7052 - loss: 1.6757\n",
            "Epoch 15: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7049 - loss: 1.6742 - val_accuracy: 0.6900 - val_loss: 1.5984\n",
            "Epoch 16/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7051 - loss: 1.5326\n",
            "Epoch 16: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7054 - loss: 1.5304 - val_accuracy: 0.5900 - val_loss: 1.4983\n",
            "Epoch 17/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7227 - loss: 1.4046\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7227 - loss: 1.4027 - val_accuracy: 0.5900 - val_loss: 1.3837\n",
            "Epoch 18/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7373 - loss: 1.2992\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7368 - loss: 1.2986 - val_accuracy: 0.6700 - val_loss: 1.3080\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7293 - loss: 1.2150\n",
            "Epoch 19: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7291 - loss: 1.2143 - val_accuracy: 0.6800 - val_loss: 1.1981\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7401 - loss: 1.1297\n",
            "Epoch 20: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7398 - loss: 1.1296 - val_accuracy: 0.5700 - val_loss: 1.1738\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7397 - loss: 1.0734\n",
            "Epoch 21: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7396 - loss: 1.0729 - val_accuracy: 0.6800 - val_loss: 1.0508\n",
            "Epoch 22/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7354 - loss: 1.0163\n",
            "Epoch 22: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7354 - loss: 1.0156 - val_accuracy: 0.6700 - val_loss: 1.0072\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7271 - loss: 0.9644\n",
            "Epoch 23: val_accuracy improved from 0.74000 to 0.76000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7270 - loss: 0.9644 - val_accuracy: 0.7600 - val_loss: 0.9751\n",
            "Epoch 24/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7318 - loss: 0.9272\n",
            "Epoch 24: val_accuracy did not improve from 0.76000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7324 - loss: 0.9261 - val_accuracy: 0.7200 - val_loss: 0.9285\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7232 - loss: 0.8897\n",
            "Epoch 25: val_accuracy improved from 0.76000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7237 - loss: 0.8893 - val_accuracy: 0.7900 - val_loss: 0.8662\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7578 - loss: 0.8234\n",
            "Epoch 26: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7574 - loss: 0.8239 - val_accuracy: 0.6800 - val_loss: 0.8733\n",
            "Epoch 27/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7506 - loss: 0.8118\n",
            "Epoch 27: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7504 - loss: 0.8117 - val_accuracy: 0.7400 - val_loss: 0.8435\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7517 - loss: 0.7879\n",
            "Epoch 28: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7512 - loss: 0.7881 - val_accuracy: 0.7000 - val_loss: 0.8514\n",
            "Epoch 29/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7582 - loss: 0.7652\n",
            "Epoch 29: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7576 - loss: 0.7654 - val_accuracy: 0.6300 - val_loss: 0.8643\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7572 - loss: 0.7508\n",
            "Epoch 30: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7570 - loss: 0.7509 - val_accuracy: 0.6100 - val_loss: 0.8348\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7356 - loss: 0.7450\n",
            "Epoch 31: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7360 - loss: 0.7444 - val_accuracy: 0.7800 - val_loss: 0.7600\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7533 - loss: 0.7215\n",
            "Epoch 32: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7532 - loss: 0.7214 - val_accuracy: 0.5200 - val_loss: 0.8808\n",
            "Epoch 33/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7580 - loss: 0.6990\n",
            "Epoch 33: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7577 - loss: 0.6995 - val_accuracy: 0.7600 - val_loss: 0.7173\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7399 - loss: 0.7133\n",
            "Epoch 34: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7400 - loss: 0.7131 - val_accuracy: 0.6400 - val_loss: 0.7756\n",
            "Epoch 35/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7448 - loss: 0.7042\n",
            "Epoch 35: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7454 - loss: 0.7031 - val_accuracy: 0.6400 - val_loss: 0.7680\n",
            "Epoch 36/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7525 - loss: 0.6756\n",
            "Epoch 36: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7531 - loss: 0.6755 - val_accuracy: 0.6400 - val_loss: 0.7877\n",
            "Epoch 37/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7747 - loss: 0.6446\n",
            "Epoch 37: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7739 - loss: 0.6455 - val_accuracy: 0.7700 - val_loss: 0.6944\n",
            "Epoch 38/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7559 - loss: 0.6501\n",
            "Epoch 38: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7553 - loss: 0.6509 - val_accuracy: 0.6700 - val_loss: 0.7483\n",
            "Epoch 39/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7587 - loss: 0.6442\n",
            "Epoch 39: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7584 - loss: 0.6451 - val_accuracy: 0.7200 - val_loss: 0.7044\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7697 - loss: 0.6431\n",
            "Epoch 40: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7693 - loss: 0.6436 - val_accuracy: 0.7200 - val_loss: 0.7089\n",
            "Epoch 41/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.6387\n",
            "Epoch 41: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7706 - loss: 0.6394 - val_accuracy: 0.7200 - val_loss: 0.7033\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7767 - loss: 0.6366\n",
            "Epoch 42: val_accuracy improved from 0.79000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7762 - loss: 0.6369 - val_accuracy: 0.8000 - val_loss: 0.6700\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.6491\n",
            "Epoch 43: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7656 - loss: 0.6492 - val_accuracy: 0.6400 - val_loss: 0.7440\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7611 - loss: 0.6477\n",
            "Epoch 44: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7610 - loss: 0.6476 - val_accuracy: 0.7400 - val_loss: 0.6849\n",
            "Epoch 45/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7719 - loss: 0.6241\n",
            "Epoch 45: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7716 - loss: 0.6246 - val_accuracy: 0.7200 - val_loss: 0.6855\n",
            "Epoch 46/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7784 - loss: 0.6313\n",
            "Epoch 46: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7775 - loss: 0.6314 - val_accuracy: 0.6600 - val_loss: 0.7168\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7865 - loss: 0.6019\n",
            "Epoch 47: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7856 - loss: 0.6028 - val_accuracy: 0.7800 - val_loss: 0.6664\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7567 - loss: 0.6403\n",
            "Epoch 48: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7570 - loss: 0.6397 - val_accuracy: 0.7500 - val_loss: 0.6897\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7663 - loss: 0.6210\n",
            "Epoch 49: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7662 - loss: 0.6208 - val_accuracy: 0.7600 - val_loss: 0.6982\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7853 - loss: 0.6147\n",
            "Epoch 50: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7845 - loss: 0.6154 - val_accuracy: 0.6400 - val_loss: 0.7830\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "48 / 50\n",
            "\n",
            "--- Fold 49 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5221 - loss: 16.5951\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 159ms/step - accuracy: 0.5221 - loss: 16.5080 - val_accuracy: 0.5200 - val_loss: 9.2331\n",
            "Epoch 2/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5214 - loss: 8.8608\n",
            "Epoch 2: val_accuracy improved from 0.52000 to 0.55000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5211 - loss: 8.8143 - val_accuracy: 0.5500 - val_loss: 7.6647\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5054 - loss: 7.3553\n",
            "Epoch 3: val_accuracy improved from 0.55000 to 0.58000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5060 - loss: 7.3436 - val_accuracy: 0.5800 - val_loss: 6.4446\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5366 - loss: 6.2008\n",
            "Epoch 4: val_accuracy improved from 0.58000 to 0.59000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5366 - loss: 6.1915 - val_accuracy: 0.5900 - val_loss: 5.4712\n",
            "Epoch 5/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5484 - loss: 5.2833\n",
            "Epoch 5: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5485 - loss: 5.2678 - val_accuracy: 0.5300 - val_loss: 4.6741\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5651 - loss: 4.5169\n",
            "Epoch 6: val_accuracy did not improve from 0.59000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5660 - loss: 4.5104 - val_accuracy: 0.5600 - val_loss: 4.0151\n",
            "Epoch 7/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 3.8983\n",
            "Epoch 7: val_accuracy improved from 0.59000 to 0.72000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6100 - loss: 3.8900 - val_accuracy: 0.7200 - val_loss: 3.4501\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6488 - loss: 3.3593\n",
            "Epoch 8: val_accuracy improved from 0.72000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6491 - loss: 3.3552 - val_accuracy: 0.7300 - val_loss: 3.0027\n",
            "Epoch 9/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6784 - loss: 2.9376\n",
            "Epoch 9: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6784 - loss: 2.9342 - val_accuracy: 0.7200 - val_loss: 2.6329\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6992 - loss: 2.5690\n",
            "Epoch 10: val_accuracy improved from 0.73000 to 0.75000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.6990 - loss: 2.5664 - val_accuracy: 0.7500 - val_loss: 2.3110\n",
            "Epoch 11/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7097 - loss: 2.2880 \n",
            "Epoch 11: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7095 - loss: 2.2825 - val_accuracy: 0.7500 - val_loss: 2.0472\n",
            "Epoch 12/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7245 - loss: 2.0141\n",
            "Epoch 12: val_accuracy did not improve from 0.75000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7240 - loss: 2.0115 - val_accuracy: 0.7500 - val_loss: 1.8260\n",
            "Epoch 13/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 1.8332\n",
            "Epoch 13: val_accuracy improved from 0.75000 to 0.77000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7190 - loss: 1.8295 - val_accuracy: 0.7700 - val_loss: 1.6563\n",
            "Epoch 14/50\n",
            "\u001b[1m46/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6996 - loss: 1.6665\n",
            "Epoch 14: val_accuracy improved from 0.77000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7013 - loss: 1.6606 - val_accuracy: 0.7800 - val_loss: 1.5143\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7116 - loss: 1.5225\n",
            "Epoch 15: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7119 - loss: 1.5209 - val_accuracy: 0.7600 - val_loss: 1.3824\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7318 - loss: 1.3715\n",
            "Epoch 16: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7316 - loss: 1.3707 - val_accuracy: 0.7600 - val_loss: 1.2645\n",
            "Epoch 17/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 1.2565\n",
            "Epoch 17: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7474 - loss: 1.2557 - val_accuracy: 0.7600 - val_loss: 1.1568\n",
            "Epoch 18/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7528 - loss: 1.1559\n",
            "Epoch 18: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7526 - loss: 1.1555 - val_accuracy: 0.7000 - val_loss: 1.1053\n",
            "Epoch 19/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 1.0762\n",
            "Epoch 19: val_accuracy improved from 0.78000 to 0.79000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7545 - loss: 1.0761 - val_accuracy: 0.7900 - val_loss: 1.0221\n",
            "Epoch 20/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7270 - loss: 1.0546\n",
            "Epoch 20: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7276 - loss: 1.0534 - val_accuracy: 0.6500 - val_loss: 1.0561\n",
            "Epoch 21/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7525 - loss: 0.9677\n",
            "Epoch 21: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7523 - loss: 0.9673 - val_accuracy: 0.7800 - val_loss: 0.9097\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7497 - loss: 0.9147\n",
            "Epoch 22: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7498 - loss: 0.9143 - val_accuracy: 0.7700 - val_loss: 0.8700\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7400 - loss: 0.8974\n",
            "Epoch 23: val_accuracy improved from 0.79000 to 0.80000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7402 - loss: 0.8966 - val_accuracy: 0.8000 - val_loss: 0.8408\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7490 - loss: 0.8517\n",
            "Epoch 24: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7492 - loss: 0.8508 - val_accuracy: 0.7600 - val_loss: 0.8209\n",
            "Epoch 25/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7553 - loss: 0.8035\n",
            "Epoch 25: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7551 - loss: 0.8035 - val_accuracy: 0.7600 - val_loss: 0.7884\n",
            "Epoch 26/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7577 - loss: 0.7832\n",
            "Epoch 26: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7574 - loss: 0.7830 - val_accuracy: 0.7500 - val_loss: 0.7731\n",
            "Epoch 27/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7587 - loss: 0.7494\n",
            "Epoch 27: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7585 - loss: 0.7496 - val_accuracy: 0.7700 - val_loss: 0.7500\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7662 - loss: 0.7237\n",
            "Epoch 28: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7658 - loss: 0.7242 - val_accuracy: 0.6600 - val_loss: 0.7967\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7685 - loss: 0.6976\n",
            "Epoch 29: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7678 - loss: 0.6985 - val_accuracy: 0.6400 - val_loss: 0.7947\n",
            "Epoch 30/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 0.7225\n",
            "Epoch 30: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7487 - loss: 0.7223 - val_accuracy: 0.7600 - val_loss: 0.6851\n",
            "Epoch 31/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7580 - loss: 0.6855\n",
            "Epoch 31: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7580 - loss: 0.6859 - val_accuracy: 0.7000 - val_loss: 0.7489\n",
            "Epoch 32/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7511 - loss: 0.6823\n",
            "Epoch 32: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7511 - loss: 0.6823 - val_accuracy: 0.7600 - val_loss: 0.6910\n",
            "Epoch 33/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7615 - loss: 0.6707\n",
            "Epoch 33: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7615 - loss: 0.6708 - val_accuracy: 0.7000 - val_loss: 0.7137\n",
            "Epoch 34/50\n",
            "\u001b[1m47/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7727 - loss: 0.6540\n",
            "Epoch 34: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7711 - loss: 0.6560 - val_accuracy: 0.7700 - val_loss: 0.6779\n",
            "Epoch 35/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7690 - loss: 0.6523\n",
            "Epoch 35: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7689 - loss: 0.6524 - val_accuracy: 0.7100 - val_loss: 0.6705\n",
            "Epoch 36/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7635 - loss: 0.6524\n",
            "Epoch 36: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7628 - loss: 0.6532 - val_accuracy: 0.7800 - val_loss: 0.6429\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7518 - loss: 0.6748\n",
            "Epoch 37: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7522 - loss: 0.6742 - val_accuracy: 0.7700 - val_loss: 0.6915\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.6453\n",
            "Epoch 38: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7657 - loss: 0.6454 - val_accuracy: 0.7700 - val_loss: 0.6460\n",
            "Epoch 39/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7763 - loss: 0.6182\n",
            "Epoch 39: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7759 - loss: 0.6189 - val_accuracy: 0.7900 - val_loss: 0.6534\n",
            "Epoch 40/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7727 - loss: 0.6212\n",
            "Epoch 40: val_accuracy did not improve from 0.80000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7725 - loss: 0.6215 - val_accuracy: 0.7800 - val_loss: 0.6581\n",
            "Epoch 41/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7717 - loss: 0.6386\n",
            "Epoch 41: val_accuracy improved from 0.80000 to 0.82000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7713 - loss: 0.6389 - val_accuracy: 0.8200 - val_loss: 0.6257\n",
            "Epoch 42/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7739 - loss: 0.6202\n",
            "Epoch 42: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7737 - loss: 0.6205 - val_accuracy: 0.6800 - val_loss: 0.7115\n",
            "Epoch 43/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7926 - loss: 0.5956\n",
            "Epoch 43: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7921 - loss: 0.5965 - val_accuracy: 0.7100 - val_loss: 0.6956\n",
            "Epoch 44/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7506 - loss: 0.6511\n",
            "Epoch 44: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7510 - loss: 0.6507 - val_accuracy: 0.8000 - val_loss: 0.6353\n",
            "Epoch 45/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.6263\n",
            "Epoch 45: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7659 - loss: 0.6262 - val_accuracy: 0.7400 - val_loss: 0.6504\n",
            "Epoch 46/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7641 - loss: 0.6223\n",
            "Epoch 46: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7642 - loss: 0.6225 - val_accuracy: 0.7200 - val_loss: 0.6503\n",
            "Epoch 47/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.6310\n",
            "Epoch 47: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7679 - loss: 0.6310 - val_accuracy: 0.7900 - val_loss: 0.6705\n",
            "Epoch 48/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7878 - loss: 0.6026\n",
            "Epoch 48: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7872 - loss: 0.6036 - val_accuracy: 0.7400 - val_loss: 0.6356\n",
            "Epoch 49/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7670 - loss: 0.6279\n",
            "Epoch 49: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7677 - loss: 0.6270 - val_accuracy: 0.7900 - val_loss: 0.6824\n",
            "Epoch 50/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7708 - loss: 0.6241\n",
            "Epoch 50: val_accuracy did not improve from 0.82000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7710 - loss: 0.6239 - val_accuracy: 0.7500 - val_loss: 0.6427\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  \n",
            "49 / 50\n",
            "\n",
            "--- Fold 50 ---\n",
            "X_train shape: (640, 2500)\n",
            "X_test shape: (160, 2500)\n",
            "y_train shape: (640, 2)\n",
            "y_test shape: (160, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4917 - loss: 19.4448\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 136ms/step - accuracy: 0.4920 - loss: 19.3219 - val_accuracy: 0.4500 - val_loss: 9.6143\n",
            "Epoch 2/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4990 - loss: 9.2493\n",
            "Epoch 2: val_accuracy improved from 0.45000 to 0.49000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4998 - loss: 9.2278 - val_accuracy: 0.4900 - val_loss: 8.1461\n",
            "Epoch 3/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5079 - loss: 7.8479\n",
            "Epoch 3: val_accuracy did not improve from 0.49000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5080 - loss: 7.8367 - val_accuracy: 0.4900 - val_loss: 6.9767\n",
            "Epoch 4/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5267 - loss: 6.7314\n",
            "Epoch 4: val_accuracy improved from 0.49000 to 0.61000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5271 - loss: 6.7223 - val_accuracy: 0.6100 - val_loss: 6.0173\n",
            "Epoch 5/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5492 - loss: 5.8217\n",
            "Epoch 5: val_accuracy did not improve from 0.61000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5494 - loss: 5.8141 - val_accuracy: 0.4900 - val_loss: 5.2340\n",
            "Epoch 6/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5934 - loss: 5.0569\n",
            "Epoch 6: val_accuracy improved from 0.61000 to 0.62000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5933 - loss: 5.0507 - val_accuracy: 0.6200 - val_loss: 4.5603\n",
            "Epoch 7/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5984 - loss: 4.4313\n",
            "Epoch 7: val_accuracy improved from 0.62000 to 0.70000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5989 - loss: 4.4259 - val_accuracy: 0.7000 - val_loss: 4.0087\n",
            "Epoch 8/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6359 - loss: 3.8823\n",
            "Epoch 8: val_accuracy did not improve from 0.70000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6364 - loss: 3.8777 - val_accuracy: 0.6300 - val_loss: 3.5395\n",
            "Epoch 9/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6811 - loss: 3.4211\n",
            "Epoch 9: val_accuracy improved from 0.70000 to 0.73000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6806 - loss: 3.4161 - val_accuracy: 0.7300 - val_loss: 3.1371\n",
            "Epoch 10/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6789 - loss: 3.0423\n",
            "Epoch 10: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6791 - loss: 3.0392 - val_accuracy: 0.5700 - val_loss: 2.8419\n",
            "Epoch 11/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7090 - loss: 2.7170\n",
            "Epoch 11: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7089 - loss: 2.7129 - val_accuracy: 0.6700 - val_loss: 2.5166\n",
            "Epoch 12/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7003 - loss: 2.4380\n",
            "Epoch 12: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7003 - loss: 2.4358 - val_accuracy: 0.7100 - val_loss: 2.2794\n",
            "Epoch 13/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7119 - loss: 2.2098\n",
            "Epoch 13: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7120 - loss: 2.2078 - val_accuracy: 0.7000 - val_loss: 2.0548\n",
            "Epoch 14/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7165 - loss: 1.9931\n",
            "Epoch 14: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7166 - loss: 1.9914 - val_accuracy: 0.6900 - val_loss: 1.8740\n",
            "Epoch 15/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7254 - loss: 1.8161\n",
            "Epoch 15: val_accuracy did not improve from 0.73000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7255 - loss: 1.8145 - val_accuracy: 0.6900 - val_loss: 1.7394\n",
            "Epoch 16/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7512 - loss: 1.6580\n",
            "Epoch 16: val_accuracy improved from 0.73000 to 0.74000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7509 - loss: 1.6569 - val_accuracy: 0.7400 - val_loss: 1.5671\n",
            "Epoch 17/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7530 - loss: 1.5147\n",
            "Epoch 17: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7522 - loss: 1.5142 - val_accuracy: 0.6700 - val_loss: 1.4922\n",
            "Epoch 18/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7335 - loss: 1.4193\n",
            "Epoch 18: val_accuracy did not improve from 0.74000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7333 - loss: 1.4175 - val_accuracy: 0.6900 - val_loss: 1.3920\n",
            "Epoch 19/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7445 - loss: 1.3118\n",
            "Epoch 19: val_accuracy improved from 0.74000 to 0.78000, saving model to CNN.keras\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7447 - loss: 1.3106 - val_accuracy: 0.7800 - val_loss: 1.2750\n",
            "Epoch 20/50\n",
            "\u001b[1m45/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7281 - loss: 1.2380\n",
            "Epoch 20: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7297 - loss: 1.2341 - val_accuracy: 0.7400 - val_loss: 1.1908\n",
            "Epoch 21/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7563 - loss: 1.1530\n",
            "Epoch 21: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7558 - loss: 1.1523 - val_accuracy: 0.6000 - val_loss: 1.1905\n",
            "Epoch 22/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7371 - loss: 1.1056\n",
            "Epoch 22: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7376 - loss: 1.1046 - val_accuracy: 0.6900 - val_loss: 1.0994\n",
            "Epoch 23/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7541 - loss: 1.0260\n",
            "Epoch 23: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7539 - loss: 1.0259 - val_accuracy: 0.6800 - val_loss: 1.0547\n",
            "Epoch 24/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7475 - loss: 0.9788\n",
            "Epoch 24: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7472 - loss: 0.9789 - val_accuracy: 0.6300 - val_loss: 1.0423\n",
            "Epoch 25/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7542 - loss: 0.9367\n",
            "Epoch 25: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7539 - loss: 0.9366 - val_accuracy: 0.7000 - val_loss: 0.9542\n",
            "Epoch 26/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7636 - loss: 0.8863\n",
            "Epoch 26: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7632 - loss: 0.8863 - val_accuracy: 0.7200 - val_loss: 0.9175\n",
            "Epoch 27/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7332 - loss: 0.8792\n",
            "Epoch 27: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7345 - loss: 0.8776 - val_accuracy: 0.7200 - val_loss: 0.8787\n",
            "Epoch 28/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7450 - loss: 0.8443\n",
            "Epoch 28: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7455 - loss: 0.8434 - val_accuracy: 0.6700 - val_loss: 0.9043\n",
            "Epoch 29/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7663 - loss: 0.7886\n",
            "Epoch 29: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7658 - loss: 0.7892 - val_accuracy: 0.7300 - val_loss: 0.8512\n",
            "Epoch 30/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7708 - loss: 0.7864\n",
            "Epoch 30: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7703 - loss: 0.7867 - val_accuracy: 0.6000 - val_loss: 0.9004\n",
            "Epoch 31/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7548 - loss: 0.7620\n",
            "Epoch 31: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7547 - loss: 0.7620 - val_accuracy: 0.6500 - val_loss: 0.8801\n",
            "Epoch 32/50\n",
            "\u001b[1m49/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7599 - loss: 0.7468\n",
            "Epoch 32: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7599 - loss: 0.7467 - val_accuracy: 0.6700 - val_loss: 0.8487\n",
            "Epoch 33/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7494 - loss: 0.7400\n",
            "Epoch 33: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7498 - loss: 0.7395 - val_accuracy: 0.6700 - val_loss: 0.8448\n",
            "Epoch 34/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7675 - loss: 0.7106\n",
            "Epoch 34: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7674 - loss: 0.7107 - val_accuracy: 0.7700 - val_loss: 0.7549\n",
            "Epoch 35/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7568 - loss: 0.7130\n",
            "Epoch 35: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7570 - loss: 0.7127 - val_accuracy: 0.6800 - val_loss: 0.8073\n",
            "Epoch 36/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7842 - loss: 0.6742\n",
            "Epoch 36: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7837 - loss: 0.6743 - val_accuracy: 0.6200 - val_loss: 0.8797\n",
            "Epoch 37/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7684 - loss: 0.6667\n",
            "Epoch 37: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7682 - loss: 0.6672 - val_accuracy: 0.6300 - val_loss: 0.8583\n",
            "Epoch 38/50\n",
            "\u001b[1m50/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7652 - loss: 0.6911\n",
            "Epoch 38: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7651 - loss: 0.6908 - val_accuracy: 0.5900 - val_loss: 0.8425\n",
            "Epoch 39/50\n",
            "\u001b[1m48/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7835 - loss: 0.6502\n",
            "Epoch 39: val_accuracy did not improve from 0.78000\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7821 - loss: 0.6512 - val_accuracy: 0.7100 - val_loss: 0.7409\n",
            "Epoch 39: early stopping\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
            "50 / 50\n",
            "[[3185  815]\n",
            " [1409 2591]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Accuracy: 0.722\n",
            "CNN Precision WAT: 0.6932956029603831\n",
            "CNN Precision NAT: 0.7607163828537874\n",
            "CNN Recall WAT: 0.79625\n",
            "CNN Recall NAT: 0.64775\n",
            "CNN F1 WAT: 0.7412148010239701\n",
            "CNN F1 NAT: 0.6997029435592762\n"
          ]
        }
      ],
      "source": [
        "for train_index, test_index in kf.split(Imgs):\n",
        "  count += 1\n",
        "  print(f\"\\n--- Fold {count} ---\") #to test\n",
        "  trainX, testX = Imgs[train_index], Imgs[test_index]\n",
        "  trainY, testY = lbl[train_index], lbl[test_index]\n",
        "\n",
        "  # --- Print details of the current split ---\n",
        "  print(f\"X_train shape: {trainX.shape}\")\n",
        "  print(f\"X_test shape: {testX.shape}\")\n",
        "  print(f\"y_train shape: {trainY.shape}\")\n",
        "  print(f\"y_test shape: {testY.shape}\")\n",
        "\n",
        "# removing for test\n",
        "#  trainX = np.array(trainX)\n",
        "#  testX = np.array(testX)\n",
        "#  trainY = np.array(trainY)\n",
        "#  testY = np.array(testY)\n",
        "\n",
        "  batch_size=64\n",
        "  validation_size=int(0.25*samplesize)\n",
        "  X_train=trainX[validation_size:]\n",
        "  y_train=trainY[validation_size:]\n",
        "  X_valid=trainX[:validation_size]\n",
        "  y_valid=trainY[:validation_size]\n",
        "\n",
        "  Twodims=[] ; values = range(X_train.shape[0])\n",
        "  for x in values:\n",
        "    tst=X_train[x]\n",
        "    tst2=np.reshape(tst,(50,50))  # Reshape from 1D (2500) to 2D (50,50)\n",
        "    Twodims.append(tst2)\n",
        "    Twodims.append(np.flip(tst2,0))  # Flip along axis 0 (vertical flip)\n",
        "    Twodims.append(np.flip(tst2,1)) # Flip along axis 1 (horizontal flip)\n",
        "    Twodims.append(np.rot90(tst2,1))  # Rotate 90 degrees clockwise\n",
        "    Twodims.append(np.rot90(tst2,2))  # Rotate 180 degrees clockwise\n",
        "    Twodims.append(np.rot90(tst2,3)) # Rotate 270 degrees clockwise\n",
        "  X_train = np.array(Twodims,dtype='uint8')\n",
        "  y_train = pd.DataFrame(y_train)\n",
        "  y_train = y_train.loc[y_train.index.repeat(6)]\n",
        "\n",
        "  Twodims=[] ; values = range(X_valid.shape[0])\n",
        "  for x in values:\n",
        "    tst=X_valid[x]\n",
        "    tst2=np.reshape(tst,(50,50))\n",
        "    Twodims.append(tst2)\n",
        "  X_valid = np.array(Twodims,dtype='uint8')\n",
        "\n",
        "  Twodims=[] ; values = range(testX.shape[0])\n",
        "  for x in values:\n",
        "    tst=testX[x]\n",
        "    tst2=np.reshape(tst,(50,50))\n",
        "    Twodims.append(tst2)\n",
        "  testX = np.array(Twodims,dtype='uint8')\n",
        "\n",
        "  # Add a channel dimension for Keras Conv2D layers (grayscale images have 1 channel)\n",
        "  X_train = np.expand_dims(X_train, axis=-1)\n",
        "  X_valid = np.expand_dims(X_valid, axis=-1)\n",
        "  testX = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "  best_model_file = 'CNN.keras'\n",
        "  model=Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, 3, strides=1, activation='relu', padding='same',\n",
        "                  kernel_regularizer=regularizers.l2(0.01),  # L1 regularization\n",
        "                  input_shape=(50, 50, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(Dropout(0.50))\n",
        "\n",
        "  model.add(Conv2D(64, 3, strides=1, activation='relu', padding='same',\n",
        "                   kernel_regularizer=regularizers.l2(0.01)))  # L1 regularization\n",
        "  model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(Dropout(0.20))\n",
        "  model.add(Conv2D(64, 3, strides=1, activation='relu', padding='same',\n",
        "                   kernel_regularizer=regularizers.l2(0.01)))  # L1 regularization\n",
        "  model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(Dropout(0.20))\n",
        "  model.add(Conv2D(128, 3, strides=1, activation='relu', padding='same',\n",
        "                   kernel_regularizer=regularizers.l2(0.01)))  # L1 regularization\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(Dropout(0.20))\n",
        "\n",
        "  model.add(Conv2D(256, 3, strides=1, activation='relu', padding='same',\n",
        "                   kernel_regularizer=regularizers.l2(0.01)))  # L1 regularization\n",
        "  model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(Dropout(0.20))\n",
        "\n",
        "    # Flatten layer and dense layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu', #kernel_regularizer='l2'))\n",
        "                  kernel_regularizer=regularizers.l2(0.01)))  # L1 regularization\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  monitor=EarlyStopping(monitor='val_accuracy',min_delta=1e-4,patience=20,verbose=1,mode='auto')\n",
        "  checkpoint=ModelCheckpoint(best_model_file,monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\n",
        "  input_shape = (None,50,50,1)\n",
        "  model.build(input_shape)\n",
        "\n",
        "  model.fit(X_train,y_train,validation_data=(X_valid, y_valid),batch_size=batch_size,epochs=50,callbacks=[monitor,checkpoint])\n",
        "\n",
        "  model=load_model(best_model_file)\n",
        "  predY=model.predict(testX)\n",
        "  ConfMat=confusion_matrix(pd.DataFrame(testY).idxmax(axis=1),pd.DataFrame(predY).idxmax(axis=1))\n",
        "  ConfMat_CNN2D.append(ConfMat)\n",
        "\n",
        "  os.remove(\"CNN.keras\")\n",
        "  gc.collect()\n",
        "  tf.keras.backend.clear_session()\n",
        "  print(count,'/','50')\n",
        "\n",
        "\n",
        "CNN=np.sum(ConfMat_CNN2D,axis = 0)\n",
        "print(CNN)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=CNN)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "APR=CNN\n",
        "CNN_acc=(APR[0,0]+APR[1,1])/np.sum(APR)\n",
        "CNN_WAT_P=APR[0,0]/sum(APR[:,0])\n",
        "CNN_NAT_P=APR[1,1]/sum(APR[:,1])\n",
        "CNN_WAT_R=APR[0,0]/sum(APR[0,:])\n",
        "CNN_NAT_R=APR[1,1]/sum(APR[1,:])\n",
        "CNN_WAT_F1=2*(CNN_WAT_P*CNN_WAT_R)/(CNN_WAT_P+CNN_WAT_R)\n",
        "CNN_NAT_F1=2*(CNN_NAT_P*CNN_NAT_R)/(CNN_NAT_P+CNN_NAT_R)\n",
        "print(\"CNN Accuracy: \" + str(CNN_acc))\n",
        "print(\"CNN Precision WAT: \" + str(CNN_WAT_P))\n",
        "print(\"CNN Precision NAT: \" + str(CNN_NAT_P))\n",
        "print(\"CNN Recall WAT: \" + str(CNN_WAT_R))\n",
        "print(\"CNN Recall NAT: \" + str(CNN_NAT_R))\n",
        "print(\"CNN F1 WAT: \" + str(CNN_WAT_F1))\n",
        "print(\"CNN F1 NAT: \" + str(CNN_NAT_F1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tUHUbUEy1P5Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e3307fc-1b25-42ae-b383-aff53126485e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"vgg16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vgg16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)               \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m1,792\u001b[0m \n",
              "\n",
              " block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)         \u001b[38;5;34m36,928\u001b[0m \n",
              "\n",
              " block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,             \u001b[38;5;34m73,856\u001b[0m \n",
              "                                  \u001b[38;5;34m128\u001b[0m)                                  \n",
              "\n",
              " block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,            \u001b[38;5;34m147,584\u001b[0m \n",
              "                                  \u001b[38;5;34m128\u001b[0m)                                  \n",
              "\n",
              " block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,                  \u001b[38;5;34m0\u001b[0m \n",
              "                                  \u001b[38;5;34m128\u001b[0m)                                  \n",
              "\n",
              " block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,            \u001b[38;5;34m295,168\u001b[0m \n",
              "                                  \u001b[38;5;34m256\u001b[0m)                                  \n",
              "\n",
              " block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,            \u001b[38;5;34m590,080\u001b[0m \n",
              "                                  \u001b[38;5;34m256\u001b[0m)                                  \n",
              "\n",
              " block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,            \u001b[38;5;34m590,080\u001b[0m \n",
              "                                  \u001b[38;5;34m256\u001b[0m)                                  \n",
              "\n",
              " block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,                  \u001b[38;5;34m0\u001b[0m \n",
              "                                  \u001b[38;5;34m256\u001b[0m)                                  \n",
              "\n",
              " block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,          \u001b[38;5;34m1,180,160\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n",
              " block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,          \u001b[38;5;34m2,359,808\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n",
              " block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,          \u001b[38;5;34m2,359,808\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n",
              " block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,                  \u001b[38;5;34m0\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n",
              " block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,          \u001b[38;5;34m2,359,808\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n",
              " block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,          \u001b[38;5;34m2,359,808\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n",
              " block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,          \u001b[38;5;34m2,359,808\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n",
              " block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,                  \u001b[38;5;34m0\u001b[0m \n",
              "                                  \u001b[38;5;34m512\u001b[0m)                                  \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> \n",
              "\n",
              " block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
              "\n",
              " block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,             <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                  \n",
              "\n",
              " block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                  \n",
              "\n",
              " block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                  \n",
              "\n",
              " block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                                  \n",
              "\n",
              " block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                                  \n",
              "\n",
              " block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                                  \n",
              "\n",
              " block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                                  \n",
              "\n",
              " block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              " block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              " block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              " block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              " block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              " block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              " block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              " block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                  \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "# include top should be False to remove the softmax layer\n",
        "pretrained_model = VGG16(include_top=False, weights='imagenet')\n",
        "pretrained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "AKf9ZlSliSCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27944e75-1ba6-451d-d3a5-979aac8b65e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 132ms/step - accuracy: 0.7546 - loss: 1.2227 - val_accuracy: 0.7200 - val_loss: 1.2086\n",
            "Epoch 2/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7488 - loss: 1.1450 - val_accuracy: 0.7200 - val_loss: 1.1319\n",
            "Epoch 3/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 1.0847 - val_accuracy: 0.7000 - val_loss: 1.1076\n",
            "Epoch 4/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7657 - loss: 1.0175 - val_accuracy: 0.7300 - val_loss: 1.0413\n",
            "Epoch 5/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7574 - loss: 0.9838 - val_accuracy: 0.7500 - val_loss: 0.9867\n",
            "Epoch 6/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7418 - loss: 0.9478 - val_accuracy: 0.5000 - val_loss: 1.1172\n",
            "Epoch 7/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7348 - loss: 0.9143 - val_accuracy: 0.7000 - val_loss: 0.9286\n",
            "Epoch 8/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7405 - loss: 0.8699 - val_accuracy: 0.7200 - val_loss: 0.9030\n",
            "Epoch 9/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7690 - loss: 0.8213 - val_accuracy: 0.6900 - val_loss: 0.9126\n",
            "Epoch 10/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7590 - loss: 0.8044 - val_accuracy: 0.6500 - val_loss: 0.9074\n",
            "Epoch 11/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7704 - loss: 0.7639 - val_accuracy: 0.7300 - val_loss: 0.8228\n",
            "Epoch 12/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7642 - loss: 0.7507 - val_accuracy: 0.7400 - val_loss: 0.7911\n",
            "Epoch 13/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7575 - loss: 0.7383 - val_accuracy: 0.7200 - val_loss: 0.7900\n",
            "Epoch 14/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7615 - loss: 0.7390 - val_accuracy: 0.6800 - val_loss: 0.8289\n",
            "Epoch 15/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.7080 - val_accuracy: 0.7500 - val_loss: 0.7599\n",
            "Epoch 16/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7664 - loss: 0.7023 - val_accuracy: 0.7400 - val_loss: 0.7382\n",
            "Epoch 17/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7537 - loss: 0.6989 - val_accuracy: 0.6800 - val_loss: 0.7957\n",
            "Epoch 18/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7668 - loss: 0.6905 - val_accuracy: 0.7000 - val_loss: 0.7772\n",
            "Epoch 19/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7793 - loss: 0.6545 - val_accuracy: 0.6700 - val_loss: 0.7560\n",
            "Epoch 20/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7826 - loss: 0.6455 - val_accuracy: 0.6700 - val_loss: 0.7657\n",
            "Epoch 21/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7548 - loss: 0.6692 - val_accuracy: 0.6700 - val_loss: 0.7657\n",
            "Epoch 22/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7733 - loss: 0.6366 - val_accuracy: 0.7000 - val_loss: 0.7428\n",
            "Epoch 23/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7711 - loss: 0.6379 - val_accuracy: 0.6800 - val_loss: 0.7534\n",
            "Epoch 24/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7628 - loss: 0.6567 - val_accuracy: 0.7000 - val_loss: 0.7298\n",
            "Epoch 25/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7778 - loss: 0.6384 - val_accuracy: 0.7100 - val_loss: 0.7225\n",
            "Epoch 26/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7772 - loss: 0.6187 - val_accuracy: 0.7600 - val_loss: 0.7173\n",
            "Epoch 27/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7575 - loss: 0.6588 - val_accuracy: 0.7100 - val_loss: 0.7215\n",
            "Epoch 28/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7596 - loss: 0.6409 - val_accuracy: 0.7100 - val_loss: 0.7321\n",
            "Epoch 29/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7564 - loss: 0.6411 - val_accuracy: 0.7200 - val_loss: 0.7156\n",
            "Epoch 30/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7775 - loss: 0.6108 - val_accuracy: 0.6900 - val_loss: 0.7687\n",
            "Epoch 31/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7856 - loss: 0.6092 - val_accuracy: 0.7200 - val_loss: 0.7169\n",
            "Epoch 32/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7907 - loss: 0.5867 - val_accuracy: 0.6600 - val_loss: 0.7716\n",
            "Epoch 33/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7708 - loss: 0.6217 - val_accuracy: 0.6500 - val_loss: 0.8069\n",
            "Epoch 34/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7787 - loss: 0.6184 - val_accuracy: 0.7300 - val_loss: 0.7151\n",
            "Epoch 35/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7818 - loss: 0.6160 - val_accuracy: 0.6700 - val_loss: 0.7278\n",
            "Epoch 36/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7891 - loss: 0.6025 - val_accuracy: 0.6600 - val_loss: 0.7511\n",
            "Epoch 37/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7761 - loss: 0.6130 - val_accuracy: 0.6800 - val_loss: 0.7758\n",
            "Epoch 38/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7797 - loss: 0.6127 - val_accuracy: 0.7800 - val_loss: 0.6951\n",
            "Epoch 39/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8004 - loss: 0.6108 - val_accuracy: 0.6300 - val_loss: 0.8233\n",
            "Epoch 40/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7872 - loss: 0.6092 - val_accuracy: 0.7100 - val_loss: 0.7210\n",
            "Epoch 41/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7923 - loss: 0.5892 - val_accuracy: 0.7100 - val_loss: 0.7172\n",
            "Epoch 42/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7996 - loss: 0.5880 - val_accuracy: 0.6900 - val_loss: 0.7351\n",
            "Epoch 43/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7918 - loss: 0.5933 - val_accuracy: 0.7500 - val_loss: 0.7019\n",
            "Epoch 44/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7816 - loss: 0.6088 - val_accuracy: 0.7200 - val_loss: 0.6996\n",
            "Epoch 45/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7861 - loss: 0.6128 - val_accuracy: 0.7400 - val_loss: 0.7270\n",
            "Epoch 46/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7937 - loss: 0.6031 - val_accuracy: 0.7600 - val_loss: 0.7425\n",
            "Epoch 47/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8030 - loss: 0.5938 - val_accuracy: 0.6900 - val_loss: 0.7634\n",
            "Epoch 48/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7899 - loss: 0.6100 - val_accuracy: 0.7200 - val_loss: 0.7180\n",
            "Epoch 49/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7892 - loss: 0.5966 - val_accuracy: 0.7500 - val_loss: 0.7251\n",
            "Epoch 50/50\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8062 - loss: 0.5874 - val_accuracy: 0.7600 - val_loss: 0.6913\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    batch_size=batch_size, epochs=50, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Y9NXk3i61qGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1aa88f-c77e-4c3b-d2e1-e98d712e20e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        }
      ],
      "source": [
        "max_epoch = len(history.history['accuracy']) + 1\n",
        "print(max_epoch)\n",
        "epoch_list =  list (range(1,max_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7Y-Psf9tiUXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "eac0332d-398e-4b90-fa6b-f487b47396b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot Model Accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Subplot for Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Subplot for Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_acc = (APR[0,0]+APR[1,1])/np.sum(APR) * 100 # Multiply by 100 for percentage\n",
        "CNN_WAT_P = APR[0,0]/sum(APR[:,0]) * 100\n",
        "CNN_NAT_P = APR[1,1]/sum(APR[:,1]) * 100\n",
        "CNN_WAT_R = APR[0,0]/sum(APR[0,:]) * 100\n",
        "CNN_NAT_R = APR[1,1]/sum(APR[1,:]) * 100\n",
        "CNN_WAT_F1 = 2*( (CNN_WAT_P/100)*(CNN_WAT_R/100) ) / ( (CNN_WAT_P/100) + (CNN_WAT_R/100) ) * 100 # Convert back to ratio for F1 calc\n",
        "CNN_NAT_F1 = 2*( (CNN_NAT_P/100)*(CNN_NAT_R/100) ) / ( (CNN_NAT_P/100) + (CNN_NAT_R/100) ) * 100\n",
        "print(f\"CNN Accuracy: {CNN_acc:.2f}%\") # Use f-string for formatting to 2 decimal places\n",
        "print(f\"CNN Precision WAT: {CNN_WAT_P:.2f}%\")\n",
        "print(f\"CNN Precision NAT: {CNN_NAT_P:.2f}%\")\n",
        "print(f\"CNN Recall WAT: {CNN_WAT_R:.2f}%\")\n",
        "print(f\"CNN Recall NAT: {CNN_NAT_R:.2f}%\")\n",
        "print(f\"CNN F1 WAT: {CNN_WAT_F1:.2f}%\")\n",
        "print(f\"CNN F1 NAT: {CNN_NAT_F1:.2f}%\")"
      ],
      "metadata": {
        "id": "eTdH7h-Lnowk",
        "outputId": "b2ab228b-1a01-4058-8d70-1a52adfb9cf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Accuracy: 72.20%\n",
            "CNN Precision WAT: 69.33%\n",
            "CNN Precision NAT: 76.07%\n",
            "CNN Recall WAT: 79.62%\n",
            "CNN Recall NAT: 64.78%\n",
            "CNN F1 WAT: 74.12%\n",
            "CNN F1 NAT: 69.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vce8PrzVn-GD"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}